\documentclass[a4paper, 12pt]{report}

\usepackage[dvipsnames]{xcolor}

%%%%%%%%%%%%%%%%
% Set Variables %
%%%%%%%%%%%%%%%%

\def\useItalian{1}  % 1 = Italian, 0 = English

\def\courseName{Calcolo Differenziale}

\def\coursePrerequisites{Nessun pre-requisito}

\def\book{\curlyquotes{Analisi Matematica},\\ M. Bertsch, R. del Passo, L. Giacomelli}

\def\authorName{Simone Bianco}
\def\email{bianco.simone@outlook.it}
\def\github{https://github.com/Exyss/university-notes}
\def\linkedin{https://www.linkedin.com/in/simone-bianco}

% \def\authorName{Alessio Bandiera}
% \def\email{alessio.bandiera02@gmail.com}
% \def\github{https://github.com/aflaag-notes}
% \def\linkedin{https://www.linkedin.com/in/alessio-bandiera-a53767223}

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage{../../../packages/Nyx/nyx-packages}
\usepackage{../../../packages/Nyx/nyx-styles}
\usepackage{../../../packages/Nyx/nyx-frames}
\usepackage{../../../packages/Nyx/nyx-macros}
\usepackage{../../../packages/Nyx/nyx-title}
\usepackage{../../../packages/Nyx/nyx-intro}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{../../../packages/Nyx/logo.png}

\if\useItalian1
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} Università di Roma}
    \faculty{Ingegneria dell'Informazione,\\Informatica e Statistica}
    \department{Dipartimento di Informatica}
    \ifdefined\book
        \subtitle{Appunti integrati con il libro \book}
    \fi
    \author{\textit{Autore}\\\authorName}
\else
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} University of Rome}
    \faculty{Faculty of Information Engineering,\\Informatics and Statistics}
    \department{Department of Computer Science}
    \ifdefined\book
        \subtitle{Lecture notes integrated with the book \book}
    \fi
    \author{\textit{Author}\\\authorName}
\fi


\title{\courseName}
\date{\today}

% \supervisor{Linus \textsc{Torvalds}}
% \context{Well, I was bored\ldots}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
    \maketitle

    % The following style changes are valid only inside this scope 
    {
        \hypersetup{allcolors=black}
        \fancypagestyle{plain}{%
        \fancyhead{}        % clear all header fields
        \fancyfoot{}        % clear all header fields
        \fancyfoot[C]{\thepage}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}}

        \romantableofcontents
    }

    \introduction

    %%%%%%%%%%%%%%%%%%%%%
    
    \chapter{Richiami di matematica elementare}

    \section{Insiemistica e simboli matematici}

    Al fine di poter discutere di qualsiasi altro concetto relativo all'analisi matematica, è necessario prima discutere le fondamenta della matematica moderna, ossia la \textbf{teoria degli insiemi}. In matematica, definiamo come \textit{insieme} una collezione di elementi distinti tra loro, i quali possono non obbligatoriamente essere collegati tra loro. Ad esempio, l'insieme $\{\text{cane}, 3, \to\}$ contiene la parola \textit{cane}, il numero 3 e il simbolo $\to$, i quali non hanno alcun collegamento reciproco apparente.

    Ovviamente, nell'ambito dell'analisi siamo interessati a trattare gli \textbf{insiemi numerici}, partendo dall'insieme elementare dei \textit{numeri naturali}, ossia l'insieme $\N = \{0, 1, 2, 3, \ldots \}$. Tale insieme costituisce le fondamenta per ogni altro insieme numerico che analizzeremo. Per tanto, è richiesto che tali fondamenta siano \textit{solide e stabili}, ossia che siano \textit{rigorosamente definite}. Ad esempio, l'insieme $\{x \mid x \text{ è un numero dispari}\}$, non è definito rigorosamente.
    
    Per stipulare tali definizione rigorosa, il matematico Giuseppe Peano stabilì cinque \textbf{assiomi}, ossia delle \textit{verità} o \textit{principi} che si ammettono senza discussione e per tale motivo indimostrabili:
    
    \begin{enumerate}
        \item $0$ è un numero naturale
        \item Il successore di ogni numero naturale è anch'esso un numero naturale
        \item Se due numeri naturali sono diversi allora i loro successori sono diversi
        \item Il numero naturale $0$ non è il successore di alcun numero
        \item Ogni sottoinsieme dei numeri naturali che contenga $0$ e il successore di ogni proprio elemento coincide con l'insieme dei numeri naturali
    \end{enumerate}

    Assumendo che tali assiomi siano veri per loro natura stessa, possiamo costruire l'insieme elementare dei numeri naturali. Tuttavia, nonostante sia ben posta, tale definizione risulta  ancora informale in quanto faccia uso di \textit{parole} e non \textit{rigore matematico}.
    
    Difatti, tali parole potrebbero generare ambiguità nel lettore, il quale a seconda della propria interpretazione otterrà una definizione diversa. Per rimuovere del tutto tale ambiguità, vengono utilizzati dei \textbf{simboli matematici} che tramite il loro significato rendono tale definizione interpretabile in un unico modo:

    \begin{itemize}
        \item Il quantificatore di esistenza $\exists$, letto come \textit{"esiste"} (o \textit{"esistono"}, a seconda del contesto), e la sua negazione $\nexists$, letto come \textit{"non esiste"} (o \textit{"non esistono"})
        \item Il quantificatore di esistenza unica $\exists!$, letto come \textit{"esiste ed è unico"}
        \item Il quantificatore universale $\forall$, letto come \textit{"per ogni"}
        \item Il simbolo di appartenenza $\in$, letto come \textit{"appartiene a"}
        \item L'insieme vuoto $\varnothing$, ossia l'insieme $\{\}$ non contenente alcun elemento
    \end{itemize}

    Per comprendere meglio l'uso di tali simboli, consideriamo la seguente affermazione: \textit{"Per ogni elemento $x$ dell'insieme $S$, esiste un elemento $y$ dello stesso insieme che sia il doppio di $x$"}. Volendo tradurre tale affermazione in simboli matematici, otteniamo la seguente stringa di simboli:
    \[\forall x \in S \;\; \exists y \in S \;\; y = 2x\]

    Altri due importanti simboli matematici riguardano le \textbf{implicazioni logiche}. Ogni qualvolta sia necessario tradurre in simboli un'affermazione del tipo \textit{"se si verifica $x$ allora $y$ è vero"}, viene utilizzata la simbologia $x \to y$. È importante porre attenzione sul significato rigoroso di tali implicazioni logiche: dire che $x \implies y$ equivale a dire che ogni qualvolta $x$ sia vero allora anche $y$ deve esserlo, ma che se $x$ è falso allora anche $y$ lo sia oppure che se $y$ sia vero anche $x$ lo sia. 

    Ad esempio, affermare che \textit{"se $x$ appartiene ad $S$ allora $x$ appartiene anche a $R$"}, in simboli $x \in S \implies x \in R$, ci dice che tutti gli elementi di $S$ siano anche elementi di $R$, ma non ci dice che se un elemento non sia in $S$ allora non sia neanche in $R$ oppure che se un elemento è in $R$ allora esso sia anche in $S$. Difatti, tali due ultime affermazioni vengono descritte dall'affermazione $x \notin S \implies x \notin R$ e dall'affermazione $x \in R \implies x \in S$.

    Quanto due affermazioni si \textbf{"implicano a vicenda"}, ossia l'una è implicazione logica dell'altra e viceversa, viene utilizzato il simbolo $\iff$, letto come \textit{"se e solo se"}. Ad esempio, se volessimo affermare che \textit{"un elemento è in $S$ se e solo se è in $R$}, in simboli scriveremmo che $x \in S \iff x \in R$. Trattandosi di una doppia implicazione, in tal caso abbiamo che se $x$ appartiene ad $S$ allora $x$ deve appartenere anche ad $R$ e viceversa che se $y$ appartiene ad $R$ allora $y$ appartiene ad $S$.

    In particolare, notiamo un'equivalenza tra alcune affermazioni: dire che $x \implies y$ è equivalente a dire che $\lnot y \implies \lnot x$, dove il simbolo $\lnot$ indica la negazione dell'affermazione. In altre parole, dire che \textit{"se $x$ allora $y$"} è equivalente a dire che \textit{"se non $y$ allora non $x$"}. Analogamente, dire che $x \iff y$ è equivalente a dire che $\lnot x \iff \lnot y$.

    \newpage

    Una volta compreso il significato di tali simboli, possiamo utilizzarli per esprimere in modo rigoroso altri concetti legati all'insiemistica, come gli \textbf{operatori insiemistici}.
    \begin{itemize}
        \item Diciamo che $S$ è un \textbf{sottoinsieme improprio} di $R$, in simboli $S \subseteq R$, se ogni elemento di $S$ appartiene ad $R$, ossia:
        \[S \subseteq R \iff \forall x \in S \text{ vale che } x \in R\]
        \item Diciamo che $S$ è un \textbf{sottoinsieme proprio} di $R$, in simboli $S \subsetneq R$ oppure $S \subset R$, se ogni elemento di $S$ appartiene ad $R$ ma i due insiemi non sono uguali, ossia:
        \[S \subsetneq R \iff \forall x \in S \text{ vale che } x \in R \text{ ma } S \neq R\]
        \item L'\textbf{intersezione} tra $S$ ed $R$, in simboli $S \cap R$, è definita come:
        \[S \cap \R := \{x \mid x \in S \text{ e } x \in R\}\]
        \item L'\textbf{unione} tra $S$ ed $R$, in simboli $S \cup R$, è definita come:
        \[S \cup R := \{x \mid x \in S \text{ o } x \in R\}\]
        \item La \textbf{differenza} tra $S$ ed $R$, in simboli $S - R$ oppure $S \,\backslash\, R$, è definita come:
        \[S - R := \{x \mid x \in S \text{ e } x \notin R\}\]
        \item Il \textbf{prodotto cartesiano} tra $S$ ed $R$, in simboli $S \times R$, è definito come:
        \[S \times R := \{(x,y) \mid x \in S \text{ e } y \in R\}\]
    \end{itemize}

    Ad esempio, dati gli insiemi $S = \{1,2,3,4\}$ e $R = \{3,4,5,6\}$, abbiamo che:
    \begin{enumerate}
        \item L'insieme $Q = \{1,2\}$ è sottoinsieme di $S$, dunque $Q \subseteq S$.
        \item La loro intersezione è $S \cap R = \{3,4\}$
        \item La loro unione è $S \cup R = \{1,2,3,4,5,6\}$
        \item La differenza tra $S$ e $R$ è $S - R = \{1,2\}$
        \item La differenza tra $R$ e $S$ è $R - S = \{5,6\}$
        \item Il prodotto tra $S$ e $R$ è $S \times R = \{(1,3), (1,4), (1,5), (1,6), (2,3), (2,4), \ldots, (4,6)\}$
        \item Il prodotto tra $R$ e $S$ è $R \times S = \{(3,1), (3,2), (3,3), (3,4), (4,1), (4,2), \ldots, (6,4)\}$
    \end{enumerate}

    \newpage

    \section{Insiemi numerici}

    Una volta formalizzati i concetti e gli operatori alla base della teoria degli insiemi, possiamo definire rigorosamente i principali \textbf{insiemi numerici} che andremo ad analizzare. Prima di tutto, riformuliamo in modo rigoroso gli \textit{assiomi di Peano} accennati nella sezione precedente.

    \begin{frameddefn}{Assiomi di Peano}
        L'\textbf{insieme dei numeri naturali}, indicato con $\N$, è definito dai seguenti assiomi:
        \begin{enumerate}
            \item $0 \in \N$
            \item $n \in \N \implies \mathrm{succ}(n) \in \N$
            \item $\forall n,m \in \N$ vale che $n \neq m \implies \mathrm{succ}(n) \neq \mathrm{succ}(m)$
            \item $\nexists n \in \N$ tale che $0 = \mathrm{succ}(n)$
            \item $\forall S \subseteq \N$ vale che se $0 \in S$ e se $n \in S \implies \mathrm{succ}(n) \in S$ allora $S = \N$
        \end{enumerate}
    \end{frameddefn}

    Da tale definizione formale, notiamo che non vi sia una definizione rigorosa di \textit{successore}. Ovviamente, la matematica moderna si è evoluta con l'uso dei numeri $0,1,2,3, \ldots$, presi in eredità dagli antichi arabi, dove $\mathrm{succ}(0) = 1, \mathrm{succ}(1) = 2$ e così via. Tuttavia, se ci mettessimo tutti di comune accordo potremmo anche dire che $\mathrm{succ}(0) = \text{cane}$ o che $\mathrm{succ}(0) = 7$. Qualsiasi sia la nostra scelta per definire il successore di un numero naturale, se tale definizione rispetta gli assiomi di Peano allora l'insieme formato coinciderà comunque con i numeri naturali, nonostante la rappresentazione sia diversa (\say{I numeri sono convezioni}, Euclide).

    Ad esempio, il matematico Von Neumann stipulò la seguente definizione dei numeri naturali basata sull'insiemistica: il numero 0 corrisponde all'insieme vuoto $\varnothing$ e il successore di un numero naturale $n$ è definito come $n \cup \{n\}$. Secondo tale definizione, abbiamo che:
    \begin{itemize}
        \item $0 := \varnothing$
        \item $1 := \mathrm{succ}(0) = \varnothing \cup \{\varnothing\} = \{\varnothing\}$
        \item $2 := \mathrm{succ}(1) =  \{\varnothing\} \cup \{ \{\varnothing\}\} = \{\varnothing,  \{\varnothing\}\}$
        \item $3 := \mathrm{succ}(2) =  \{\varnothing,  \{\varnothing\}\} \cup \{\{\varnothing,  \{\varnothing\}\}\} = \{\varnothing,  \{\varnothing\}, \{\{\varnothing,  \{\varnothing\}\}\}\}$
        \item $\vdots$
    \end{itemize}

    Una volta definito il concetto di successore, possiamo anche esprimere il concetto di \textit{addizione} tramite la seguente definizione ricorsiva:
    \[n + m = \soe{ll}{
        n &\text{se } m = 0 \\
        \mathrm{succ}(n+k) & \text{se } m = \mathrm{succ}(k)
    }\]

    Ad esempio, abbiamo che:
    \[\begin{split}
        2 + 2 &= 2 + \mathrm{succ}(1) \\
        &= \mathrm{succ}(2+1) \\
        &= \mathrm{succ}(2+\mathrm{succ}(0)) \\
        &= \mathrm{succ}(\mathrm{succ}(2+0)) \\
        &= \mathrm{succ}(\mathrm{succ}(2)) \\
        &= 4
    \end{split}\]

    Per non dilungarci nelle ulteriori definizioni rigorose delle operazioni matematiche di base, assumeremo che il concetto di \textit{sottrazione}, \textit{moltiplicazione} e \textit{divisione} siano ben definiti. Definiamo quindi il secondo insieme numerico fondamentale, ossia un sottoinsieme dei numeri naturali: i \textit{numeri primi}.
    
    \begin{frameddefn}{Numeri primi}
        Definiamo l'\textbf{insieme dei numeri primi}, indicato con $\Primes$, come:
        \[\Primes := \{p \in \N -{1} \mid \nexists a,b \in \N-\{1,p\} \text{ tale che } p = ab\}\]
    \end{frameddefn}

    In altre parole, l'insieme dei numeri primi è costituito dal sottoinsieme dei numeri naturali, escluso il numero 1, che non siano rappresentabili come il prodotto di due numeri $a,b$ diversi da $1$ e il numero stesso. In particolare, abbiamo che $\Primes = \{2, 3, 5, 7, 9, \ldots\}$.
    
    Successivamente, definiamo l'insieme dei \textit{numeri interi} come l'insieme contenente tutti i numeri naturali e i loro inversi nella somma, ossia tutti i numeri che sommati al loro reciproco danno somma 0:
    \begin{frameddefn}{Numeri interi}
        Definiamo l'\textbf{insieme dei numeri interi}, indicato con $\Z$, come:
        \[\Z := \N \cup \{-n \mid n \in \N\} \]
        dove $-n$ rappresenta il numero tale che $n + (-n) = 0$
    \end{frameddefn}

    Da tale definizione, risulta evidente che $\Z = \{\ldots, -2, -1, 0, 1, 2, \ldots\}$. Passiamo ora ad insiemi numerici che richiedono una definizione più complessa, ossia i \textit{numeri razionali}. Comunemente, tale insieme è costituito dai numeri nella forma $\frac{p}{q}$, dove $p,q \in \Z$ e $q \neq 0$. Tuttavia, tale definizione non esprime a pieno il concetto di \textit{uguaglianza tra razionali}, ossia la proprietà che ci permette di dire che $2 = \frac{4}{2} = \frac{6}{3} = \ldots$.

    Formalmente, dati due numeri razionali $\frac{a}{b}$ e $\frac{c}{d}$, diciamo che $\frac{a}{b} = \frac{c}{d}$ se e solo se $ad = cd$. Ad esempio, i numeri $\frac{4}{5}$ e $\frac{20}{25}$ sono uguali poiché $4 \cdot 25 = 5 \cdot 20$.

    Tale proprietà implica a sua volta la proprietà di \textit{riduzione ai minimi termini} di un numero razionale: dato un numero razionale $\frac{p}{q}$, la sua riduzione ai minimi termini equivale al numero razionale $\frac{a}{b}$ tale che $\frac{p}{q} = \frac{a}{b}$ e tale che $\nexists c \in \Primes$ per cui $\frac{a}{c}, \frac{b}{c} \in \N$. Ad esempio, il numero $\frac{4}{5}$ è ridotto ai minimi termini, mentre $\frac{6}{15}$ no. Ovviamente, ogni numero razionale possiede una riduzione ai minimi termini, la quale nel eventualmente può coincidere col numero stesso.

    Inoltre, bisogna specificare che la rappresentazione $\frac{p}{q}$ sia anch'essa impropria. Volendo essere rigorosi, dovremmo rappresentare un numero razionale come una \textit{coppia di numeri}, ossia $(p,q)$, in modo che il loro insieme possa essere definito come un sottoinsieme di un prodotto cartesiano.

    \begin{frameddefn}{Numeri razionali}
        Definiamo l'\textbf{insieme dei numeri razionali}, indicato con $\Q$, come:
        \[\Q := \{(p,q) \mid p \in \Z \text{ e } q \in \Z-\{0\}\}\]

        dove dati $(a,b), (c,d) \in \Q$ si ha che $(a,b) = (c,d) \iff ad = cb$. Inoltre, dato $(p,q) \in \Q$, utilizziamo la notazione $\frac{p}{q}$ per rappresentarlo.
    \end{frameddefn}

    Ricordiamo inoltre che i numeri razionali possono essere rappresentati anche in \textit{forma decimale}, ossia come una serie di cifre decimali poste dopo un numero intero. Formalmente, ogni numero razionale $x \in \Q$ può essere espresso come un'\textbf{allineamento decimale}, ossia un'espressione nella forma $n.\alpha_1 \alpha_2 \ldots \alpha_k$ dove $n \in \Z$ e $\alpha_1, \ldots, \alpha_k \in \{0, \ldots, 9\}$. Ad esempio, l'allineamento decimale di $\frac{7}{4}$ equivale a $1.75$.

    Quando il numero di cifre decimali è nullo, allora il numero razionale risulta in realtà essere anche un numero intero. Ovviamente, un numero $\frac{p}{q}$ può avere allineamento decimale nullo se e solo se $q = 1$, implicando che $p \in \Z$.

    Quando invece il numero di cifre decimali è infinito ma le ultime cifre si ripetono all'infinito, tale allineamento è detto \textit{periodico} e viene espresso nella forma contratta data da $n.\alpha_1 \alpha_2 \ldots \alpha_k \overline{\beta_1 \beta_2 \ldots \beta_h}$, dove le cifre sopralineate sono quelle ripetute infinite volte. Ad esempio, il numero $\frac{212408}{9900}$ può essere espresso come $21.4553535353\ldots$ o in forma contratta come $21.45\overline{53}$.
    
    Tuttavia, nonostante la maggior parte dei numeri di uso comune rientri nei razionali, esistono dei numeri che non siano esprimibili come frazione. Esempio tipico risulta essere il numero $x$ tale che $x^2 = 2$, il quale viene solitamente comunemente come $\sqrt{2}$.

    \begin{framedlem}{Irrazionalità di $\sqrt{2}$}
        Dato $\sqrt{2}$, si ha che $\sqrt{2} \notin \Q$.
    \end{framedlem}

    \proofenv{
        Supponiamo per assurdo che $\sqrt{2} \in \Q$, ossia $\sqrt{2} = \frac{p}{q}$ per qualche numero razionale ridotto ai minimi termini. In tal caso, avremmo che:
        \[\sqrt{2} = \frac{p}{q} \implies 2 = \frac{p^2}{q^2} \implies 2q^2 = p^2\]

        Ma allora, ciò significa che $p^2$ è un multiplo di $2$, il chè è possibile solo se anche $p$ lo sia. Dunque, $\exists a \in \Z$ tale che $p = 2a$, implicando quindi che:
        \[2q^2 = p^2 \implies 2q^2 = (2a)^2 \implies q^2 = 2a^2\]

        Analogamente a prima, ciò significa che $q^2$ è un multiplo di $2$, il che è possibile solo se anche $q$ lo sia. Dunque, ne segue che $\exists b \in \Z$ tale che $q = 2b$. Tuttavia, ciò conclude che $\sqrt{2} = \frac{p}{q} = \frac{2a}{2b}$, contraddicendo l'ipotesi per cui $\frac{p}{q}$ sia già una riduzione ai minimi termini, concludendo quindi che sia impossibile che $\sqrt{2} \in \Q$

    }
    
    Nonostante tale numero sia dunque irrazionale, esso è comunque rappresentabile tramite un'allineamento decimale infinito, ossia $\sqrt{2} = 1.4142135623\ldots$. Difatti, ogni numero irrazionale può essere rappresentato come un'allineamento decimale infinito, permettendoci quindi di definire l'ulteriore insieme numerico, ossia i \textit{numeri reali}:

    \begin{frameddefn}{Numeri reali}
        Definiamo l'\textbf{insieme dei numeri reali}, indicato con $\R$, come l'insieme di tutti i possibili allineamenti decimali finiti e infiniti.
    \end{frameddefn}

    Nonostante ciò, è opportuno evidenziare che i numeri reali \underline{non} contengano tutti i numeri possibili. Ad esempio, il valore $x$ tale che $x^2+1 = 0$ non può essere reale:
    \begin{itemize}
        \item Se $x > 0$ allora $x^2 > 0$ dunque $x^2 + 1 > 0$
        \item Se $x = 0$ allora $x^2 = 0$ dunque $x^2 + 1 \neq 0$
        \item Se $x < 0$ allora $x^2 > 0$ dunque $x^2 + 1 > 0$
    \end{itemize}

    Spesso tale valore viene detto valore \textbf{immaginario}. Per sottolineare ciò, esso viene spesso denotato come $i$, anche chiamata \textit{unità immaginaria}. Tramite tale valore, possiamo definire quello che è a tutti gli effetti l'insieme numerico più grande possibile senza che si vada a perdere qualche proprietà fondamentale dell'aritmetica, ossia i cosiddetti \textbf{numeri complessi}.

    \begin{frameddefn}{Numeri complessi}
        Definiamo l'\textbf{insieme dei numeri complessi}, indicato con $\C$, come l'insieme di tutti i numeri descrivibili come somma tra un valore reale e l'unità immaginaria moltiplicata per un valore reale.
        \[\C = \{ a+ib \mid a,b \in \R\}\]
        dove $i^2 = -1$.
    \end{frameddefn}

    Una volta giunti a questo punto, abbiamo formalizzato quelli che sono tutti i principali insiemi numerici, ottenendo la seguente \textbf{gerarchia}:
    \[\Primes \subset \N \subset \Z \subset \Q \subset \R \subset \C\]

    \newpage
    
    \section{Intervalli numerici}

    Siano $a,b$ due elementi presi da un insieme numerico $S$ (dunque $S$ può essere uguale a $\Primes, \N, \Z, \Q$ o $\R$). Vogliamo formalizzare il concetto di numeri compresi tra $a$ e $b$, ossia il concetto di \textit{intervallo numerico}.

    \begin{frameddefn}{Intervallo numerico}
        Dato un insieme numerico $S$ e due numeri $a,b$, definiamo:
        \begin{itemize}
            \item L'intervallo aperto tra $a$ e $b$, indicato con $(a,b)$, come:
            \[(a,b) := \{x \in S \mid a < x < b\}\]
            \item L'intervallo chiuso tra $a$ e $b$, indicato con $[a,b]$, come:
            \[[a,b] := \{x \in S \mid a \leq x \leq b\}\]
            \item L'intervallo aperto a sinistra tra $a$ e $b$, indicato con $(a,b]$, come:
            \[(a,b] := \{x \in S \mid a < x \leq b\}\]
            \item L'intervallo aperto a destra tra $a$ e $b$, indicato con $[a,b)$, come:
            \[[a,b) := \{x \in S \mid a \leq x < b\}\]
        \end{itemize}
    \end{frameddefn}

    È opportuno porre attenzione sull'insieme numerico considerato per i numeri scelti. Ad esempio, dati i numeri $-3$ e $5$, abbiamo che:
    \begin{itemize}
        \item $[-3,5] \subseteq \Primes$ implica che $[-3,5] = \{3,5\}$
        \item $[-3,5] \subseteq \N$ implica che $[-3,5] = \{0,1,2,3,4,5\}$
        \item $[-3,5] \subseteq \Z$ implica che $[-3,5] = \{-3,-2,-1,0,1,2,3,4,5\}$
    \end{itemize}

    In particolare, se un intervallo aperto o chiuso con estremi $a$ e $b$ è un sottoinsieme di $\Z$ allora il numero di elementi dell'intervallo sarà \textbf{finito}. Formalmente, diremmo che dato un intervallo $(a,b) \subseteq \Z$ (oppure $[a,b]$) si ha che $\abs{I} \neq +\infty$, dove $\abs{I}$ indica la \textit{cardinalità} di $I$ (ossia il suo numero di elementi) e $+\infty$ indica che tale valore sia \textit{infinito}. 
     
    Per quanto riguarda i numeri razionali e reali, invece, la cardinalità degli intervalli al loro interno risulta essere \textbf{infinita}. In altre parole, in $\R$ e in $\Q$ vi sono infiniti numeri tra due valori distinti $a$ e $b$. Tale proprietà è detta \textit{densità}.

    \begin{frameddefn}{Densità di un insieme numerico}
        Dato un insieme numerico $S$, un suo sottoinsieme $I \subseteq S$ è detto \textbf{denso} se per ogni coppia di numeri $a, b \in I$ tali che $a < b$ si verifica che:
        \[\exists x \in I \;\; a < x < b\]
    \end{frameddefn}

    Notiamo facilmente quindi che sia $\Q$ che $\R$ siano densi: dati $a,b \in \Q$ (o $\R$) tali che $a < b$, esiste sempre un numero a metà tra loro:
    \[a = \frac{a+a}{2} < \frac{a+b}{2} < \frac{b+b}{2} = b\]

    Ovviamente, la proprietà di densità si propaga anche per ogni sottoinsieme di un insieme denso: se $I$ è denso allora ogni suo sottoinsieme con almeno due elementi è denso. Difatti, notiamo facilmente che:
    \[a < x_1 < b \implies a < x_2 < x_1 < b \implies a < x_n < \ldots < x_2 < x_1 < b\]
    \begin{center}
        \includegraphics[scale=0.75]{images/density.png}
    \end{center}

    Il concetto di intervallo, inoltre, può essere esteso in \textbf{intervalli limitati e illimitati}. Ad esempio, se uno dei due estremi dell'intervallo è \textit{infinito} (in modo improprio, poiché $+\infty$ non è un numero ma un concetto), otteniamo un intervallo illimitato. In particolare, quindi, abbiamo che:
    \begin{itemize}
        \item L'intervallo $[a, +\infty) = \{x \in S \mid a \leq x\}$ è illimitato a destra
        \item L'intervallo $(-\infty, b] = \{x \in S \mid x \leq b\}$ è illimitato a sinistra
        \item L'intervallo $(-\infty, +\infty) = S$ è illimitato a sinistra e destra
    \end{itemize}

    \textit{Nota:} l'estremo "$+\infty$" ovviamente non può essere incluso nell'intervallo, in quanto non sia un vero e proprio valore

    \begin{frameddefn}{Massimo e minimo}
        Dato un insieme numeri $S$ e un sottoinsieme $A \subseteq S$, definiamo come \textbf{massimo di $A$}, indicato come $\max(A)$, il valore in $A$ tale che $\forall x \in A$ valga che $x \leq \max(A)$. Analogamente, definiamo come \textbf{minimo di $A$}, indicato come $\min(A)$, il valore in $A$ tale che $\forall x \in A$ valga che $\min(A) \leq x$.
    \end{frameddefn}

    Un'importante osservazione da fare è che alcuni insiemi potrebbero non avere un massimo o un minimo. Ad esempio, per l'intervallo $[5, +\infty)$ abbiamo che $\min([5,+\infty)) = 5$ ma $\max([5,+\infty)) = \nexists$. Inoltre, è importante ricordare l'insieme numerico considerato: per l'intervallo $(5,7] \subseteq \Z$ si ha che $\min((5,7]) = 6$, mentre per $(5,7] \subseteq \Q$ si ha che $\min((5,7]) = \nexists$ per via della densità di $\Q$.

    \begin{frameddefn}{Maggiorante e minorante}
        Dato un insieme numerico $S$ e un sottoinsieme $A \subseteq S$, definiamo come \textbf{maggiorante di $I$} ogni valore $m \in S$ tale che $\forall x \in A$ valga che $x \leq m$. Analogamente,  definiamo come \textbf{minorante di $I$}, ogni valore $m \in S$ tale che $\forall x \in A$ valga che $m \leq x$.
    \end{frameddefn}

    La principale differenza tra minorante e maggiorante, dunque, è l'insieme considerato. Ad esempio, per l'intervallo $[5,7) \subseteq \R$ abbiamo che $\max([5,7)) = \nexists$ ma i suoi maggioranti sono contenuti all'interno dell'insieme $\{x \in \R \mid x \geq 7\}$.

    \begin{frameddefn}{Estremo superiore e inferiore}
        Dato un insieme numerico $S$ e un sottoinsieme $A \subseteq S$, definiamo come \textbf{estremo superiore di $I$}, indicato come $\sup(A)$, il minimo maggiorante di $A$:
        \[\sup(A) := \min \{ m \in S \mid \forall x \in A \;\; x \leq m\}\]
        e diciamo che $A$ è \textbf{limitato superiormente} da $\sup(A)$. Se non esiste un maggiorante di $A$, diciamo che $\sup(A) = +\infty$.

        Analogamente, definiamo come \textbf{estremo inferiore di $I$}, indicato come $\inf(A)$, il massimo minorante di $A$:
        \[\inf(A) := \max \{ m \in S \mid \forall x \in A \;\; m \leq x\}\]
        e diciamo che $A$ è \textbf{limitato inferiormente} da $\inf(A)$. Se non esiste un maggiorante di $A$, diciamo che $\inf(A) = -\infty$.

        Se $A$ è limitato sia superiormente che inferiormente, diciamo che $A$ è limitato.
    \end{frameddefn}

    Ricapitolando, considerando l'intervallo $(5,+\infty) \subseteq \R$, abbiamo che:
    \begin{itemize}
        \item Il minimo è $\min((5,+\infty)) = \nexists$
        \item Il massimo è $\max((5,+\infty)) = \nexists$
        \item L'insieme dei minoranti è $\{x \in \R \mid x \leq 5\}$
        \item L'insieme dei maggioranti è $\varnothing$
        \item L'estremo inferiore è $\inf((5,+\infty)) = 5$, dunque $A$ è limitato inferiormente
        \item L'estremo superiore è $\sup((5,+\infty)) = +\infty$, dunque $A$ è illimitato superiormente
    \end{itemize}

    \newpage

    \section{Operatori elementari}

    Una volta definito tutto ciò che riguarda gli insiemi numerici, siamo pronti per affrontare i principali \textit{operatori elementari}. Abbiamo visto come l'operazione di addizione sia definita tramite l'operatore di successore e come la moltiplicazione risulta definibile  tramite l'addizione. Procedendo analogamente, definiamo l'operatore di \textbf{potenza} ricorsivamente tramite la moltiplicazione:
    \[x^a = \soe{ll}{
        1 & \text{se } a = 0 \\
        a \cdot x^{a-1} &\text{se a > 0} \\
        \rbk{\frac{1}{x}}^{-a} &\text{se a < 0} \\
    }\]

    dove il numero $a$ viene detto \textit{esponente} della potenza.

    Ad esempio, abbiamo che:
    \begin{itemize}
        \item $2^0 = 1$
        \item $2^3 = 2 \cdot 2^2 = 2 \cdot 2 \cdot 2^1 = 2 \cdot 2 \cdot 2 \cdot 2 \cdot 2^0 = 2 \cdot 2 \cdot 2 \cdot 2 \cdot 1 = 8$
        \item $2^{-3} = \rbk{\frac{1}{2}}^{3} = \frac{1}{8}$
    \end{itemize} 

    Da tale definizione risultano, evidenti le seguenti proprietà:
    \begin{itemize}
        \item $x^ax^b = x^{a+b}$
        \item $x^ay^a = (xy)^a$
        \item $(x^a)^b = x^{ab}$
        \item $x^{-a} = \rbk{\dfrac{1}{x}}^a = \dfrac{1}{x^a}$
    \end{itemize}

    Inoltre, risulta abbastanza evidente il funzionamento dell'operatore nel caso in cui l'esponente sia \textit{intero}. Rimane quindi da chiedersi cosa accada nel caso di esponenti \textit{razionali} e \textit{reali}.
    
    Analizziamo quindi prima il caso razionale: dato $x^\frac{1}{2}$, notiamo ad esempio che:
    \[x^{\frac{1}{2}} \cdot x^{\frac{1}{2}} = x^{\frac{2}{2}} = x\]

    Tale comportamento risulta essere identico al comportamento delle \textbf{radici}:
    \[\sqrt{x} \cdot \sqrt{x} = \sqrt{x^2} = x\]

    Difatti, per il caso razionale in linea generale abbiamo che:
    \[x^{\frac{a}{b}} = \sqrt[b]{x^a}\]

    Per quanto riguarda il caso \textit{reale}, consideriamo ad esempio la potenza $2^\pi$. Sappiamo che $\pi = 3.1415926535\ldots$. Di conseguenza, poiché $3 \leq \pi \leq 4$ abbiamo che:
    \[8 = 2^3 \leq 2^\pi \leq 2^4 = 16\]

    Continuando ad "avvicinare" i due estremi, migliorerà l'approssimazione:
    \[8.5741877 \approx 2^{3.1} \leq 2^\pi \leq 2^{3.2} \approx 9.1895868 \]
    \[8.8152409 \approx 2^{3.14} \leq 2^\pi \leq 2^{3.15} \approx 8.8765557 \]
    \[8.8213533 \approx 2^{3.141} \leq 2^\pi \leq 2^{3.142} \approx 8.8274699 \]
    \[8.824411 \approx 2^{3.1415} \leq 2^\pi \leq 2^{3.1416} \approx 8.8250227 \]
    \[\vdots\]

    Procedendo in tale modo, otteniamo che:
    \[\sup\{2^a \mid a \in \R \text{ e } a < \pi\} = 2^\pi = \inf\{2^a \mid a \in \R \text{ e } x > \pi\}\]

    Difatti, nel caso reale in linea generale abbiamo che:
    \[x^y = \sup\{x^a \mid a \in \R \text{ e } a < y\} = \inf\{x^a \mid a \in \R \text{ e } a > y\}\]

    A questo punto, consideriamo quindi l'equazione generica $a^b = c$. Fino ad ora, abbiamo visto due operatori relativi ad essa, ossia la \textit{potenza} e la \textit{radice} (che in realtà è un sottoinsieme della potenza). Vediamo ora una terza operazione, ossia il \textit{logaritmo}.

    Data l'equazione $a^b = c$, diciamo che $b$ sia il \textbf{logaritmo in base $a$ di $c$}, indicato come $\log_a(c) = b$.

    In altre parole, abbiamo il seguente \textbf{triangolo delle operazioni} relative all'equazione $a^b = c$:
    \begin{itemize}
        \item \textbf{Potenza}: sapendo il valore di $a$ e $b$, quanto vale $c$? 
        \item \textbf{Radice}: sapendo il valore di $c$ e $b$, quanto vale $a$?
        \item \textbf{Logaritmo}: sapendo il valore di $a$ e $c$, quanto vale $b$? 
    \end{itemize}
    
    Dalla stessa definizione di logaritmo, risulta evidente che:
    \[a^{\log_a(c)} = c\]

    Inoltre, unendo tale definizione alle proprietà delle potenze, otteniamo anche delle proprietà valide per i logaritmi. In particolare, se $\log_{a}(x) = b$ e $\log_{a}(y) = d$ allora per definizione $a^b = x$ e $a^d = y$, dunque $a^{b+d} = a^b a^d = xy$ e quindi $\log_a(xy) = b+d$. In altre parole, vale che:
    \[\log_a(xy) = \log_a(x) + \log_a(y)\]

    In modo analogo, abbiamo che $a^{b-d} = a^{b} a^{-d} = \frac{a^b}{a^d} = \frac{x}{y}$, dunque
    \[\log_a \rbk{\frac{x}{y}} = \log_a(x) - \log_a(y)\]

    Inoltre, tramite la prima proprietà otteniamo che:
    \[\log_a(x^y) = \log_a(x \cdot x^{y-1}) = \log_a(x) + \log_a(x^{y-1}) = \ldots = y \log_a(x)\]

    Infine, i logaritmi godono anche di una proprietà insolita, ossia il \textit{cambio di base}. Se $\log_{a}(x) = b$ e $\log_{c}(x) = d$ allora per definizione $a^b = x$ e $c^d = x$, dunque abbiamo che:
    \[\log_a(x) = \log_a(c^d) = d \log_a(c) = \log_c(x) \log_a(c)\]
    da cui deriva che:
    \[\log_c(x) = \frac{\log_a(x)}{\log_a(c)}\]

    Ricapitolando, quindi, abbiamo che:
    \begin{itemize}
        \item $a^{\log_a(x)} = x$
        \item $\log_a(xy) = \log_a(x) + \log_a(y)$
        \item $\log_a \rbk{\frac{x}{y}} = \log_a(x) - \log_a(y)$
        \item $\log_a(x^y) = y \log_a(x)$
        \item $\log_b(x) = \dfrac{\log_a(x)}{\log_a(b)}$
    \end{itemize}
    
    \quad

    Proviamo quindi a semplificare un'espressione complessa che utilizzi tutte e tre le operazioni appena discusse:
    \[\log_{10}(a^2) + \log_{10}(2b^2) + 5 \log_{10} \rbk{\frac{1}{\sqrt[5]{2c^2}}} - \log_{100} (a^4b^4)\]

    Prima di tutto, convertiamo ogni radice e frazione in termini di potenze:
    \[\log_{10}(a^2) + \log_{10}(2b^2) + 5 \log_{10} ((2c^2)^{-\frac{1}{5}}) - \log_{100} (a^4b^4)\]

    A questo punto, utilizziamo le proprietà dei logaritmi:
    \[2\log_{10}(a) + \log_{10}(2) + 2\log_{10}(b) + \rbk{-\frac{5}{5}} \log_{10} (2c^2) - \frac{\log_{10}(a^4b^4)}{\log_{10} (100)}=\]
    \[2\log_{10}(a) + \log_{10}(2) + 2\log_{10}(b) - \log_{10} (2) - 2\log_{10}(c) - \frac{4\log_{10}(a) + 4\log_{10}(b)}{2}=\]
    \[2\log_{10}(a) + \log_{10}(2) + 2\log_{10}(b) - \log_{10} (2) - 2\log_{10}(c) - 2\log_{10}(a) - 2\log_{10}(b)\]

    Semplificando tra loro i termini rimanenti, otteniamo il risultato $-2\log_{10}(c)$.
    
    Nelle potenze, viene fissato un esponente $\alpha$ e viene fatta variare la base $x$, ottenendo $x^\alpha$. Negli \textbf{esponenziali}, invece, viene fissata la base $\alpha$ e viene fatto variare l'esponente $x$, ottenendo $\alpha^x$. Ad esempio, dato $2^x$ al variare di $x$ abbiamo $2^0 = 1, 2^1 = 2, 2^2 = 4, \ldots$.
    
    Gli esponenziali risultano essere il concetto direttamente inverso a quello di logaritmo: fissata la base $\alpha$, al variare di $x$ nei logaritmi ci chiediamo quale sia l'esponente $y$ tale che $a^y = x$, mentre negli esponenziali al variare di $x$ ci chiediamo quale sia il valore $y$ tale che $a^x = y$.

    Un particolare numero interessante nell'ambito degli esponenziali risulta essere il numero $e \approx 2.7182818284$, detto \textbf{numero di Nepero}, il quale è definito come l'unico numero reale per cui per ogni $x \in \R$ valga che:
    \[e^x \geq 1+x\]

    Quando la base dell'operatore logaritmo corrisponde a $e$, ciò viene indicato anche come l'operatore $\ln(x)$, detto \textit{logaritmo naturale}. In altre parole, abbiamo che $\ln(x) := \log_e(x)$. Similmente, quando la base del logaritmo è omessa, viene implicitamente assunto che essa sia dieci. In altre parole, $\log(x) := \log_{10}(x)$.

    Infine, l'ultimo operatore elementare che discuteremo è l'operatore di \textit{valore assoluto}. In particolare, dato il valore $x$, il suo \textbf{valore assoluto} corrisponde a:
    \[\abs{x} := \soe{rl}{
        x & \text{se } x \geq 0 \\
        -x & \text{se } x < 0
    }\]

    Ad esempio, data l'espressione $x-3y$, il suo valore assoluto è dato da:
    \[\abs{x-3y} = \soe{rl}{
        x-3y & \text{se } x-3y \geq 0 \\
        -x+3y & \text{se } x-3y < 0
    }\]

    È opportuno notare che, anche se sia in realtà scollegato da esso, possiamo comunque ricondurre l'operatore di valore assoluto al concetto di potenza. Difatti, notiamo che:
    \[\sqrt{x^2} = \soe{rl}{
        x & \text{se } x \geq 0 \\
        -x & \text{se } x < 0
    }\]

    In altre parole, per qualsiasi valore $x$ abbiamo che $\abs{x} = \sqrt{x^2}$.

    \newpage

    \section{Polinomi}

    Una volta discusse le operazioni fondamentali definite attorno al concetto di elevamento a potenza, possiamo ora considerare una struttura algebrica che ne faccia uso, ossia i \textit{polinomi}. In particolare, discuteremo i polinomi a singola variabile.

    Scelto un insieme numerico $S$, un \textbf{monomio} in $S$ è costituito dal prodotto tra una costante $a \in S$ e una potenza $x^\alpha$, dove la costante $c$ viene detta \textit{coefficiente} e l'esponente $\alpha \geq 0$ viene detto \textit{grado del monomio}. Ad esempio, il monomio $5x^3$ è un monomio di terzo grado.

    Un \textbf{polinomio} in $S$, invece, è costituito dalla somma tra più monomi in $S$, ognuno definito sulla stessa variabile $x$. Il \textbf{grado del polinomio} corrisponde ad grado del monomio di grado maggiore presente al suo interno. Ad esempio, il polinomio $x+2x^3+5x^5$ è un polinomio di quinto grado. Notiamo che se $n$ è il grado di un polinomio allora esso possa essere riscritto sempre come una somma di $n+1$ monomi. Ad esempio, abbiamo che:
    \[x+2x^3+5x^5 = 0 + x + 0x^2 + 3x^3 + 0x^4 + 5x^5\]

    In generale, dati i coefficienti $c_0, c_1, c_2, \ldots, c_n$ con $c_n \neq 0$, un polinomio $p(x)$ di grado $n$ è descritto da:
    \[p(x) = c_0 + c_1x + c_2x^2 + \ldots + c_n x^n\]

    Nel caso dei polinomi, le operazioni di somma e prodotto assumono due comportamenti diversi per quanto riguarda il grado dello stesso. Ad esempio, consideriamo il polinomio $p(x) = x+2x^3+5x^5$ e il polinomio $q(x) = 4+x^2+3x^3$. Notiamo che:
    \[\begin{split}
        p(x) + q(x) &= x+2x^3+5x^5 + 4+x^2+3x^3 \\
        &= 4+x+x^2+5x^3+5x^5
    \end{split}\]

    dunque otteniamo un polinomio di quinto grado. Per quanto riguarda il loro prodotto, invece, notiamo che:
    \[\begin{split}
        p(x)q(x) &= (x+2x^3+5x^5)(4+x^2+3x^3) \\
        &= 4x+x^3+3x^4+8x^3+4x^5+6x^6+20x^5+5x^7+15x^8 \\
        &= 4x + 9x^3 + 3x^4 + 24x^5+6x^6+5x^7+15x^8
    \end{split}\]
    dunque otteniamo un polinomio di ottavo grado.
    
    In linea generale, sia $p(x) = a_0 + a_1x + a_2x^2 + \ldots + a_n x^n$ un polinomio di grado $n$ e sia $q(x) = b_0 + b_1x + b_2x^2 + \ldots + b_m x^m$ un polinomio di grado $m$, dove $m \leq n$. La somma tra $p(x)$ e $q(x)$ equivale a:
    \[\begin{split}
        p(x) + q(x) & = a_0 + a_1x + a_2x^2 + \ldots + a_n x^n + b_0 + b_1x + b_2x^2 + \ldots + b_m x^m \\
        &= (a_0+b_0) + (a_1+b_1)x + (a_2+b_2)x^2 + \ldots + (a_m+b_m) x^m + a_{m+1} x^{m+1} +\ldots + a_nx^n
    \end{split}\]

    Notiamo quindi che $\deg(p(x) + q(x)) = n$, dove l'operatore $\deg$ indica il grado del polinomio. In altre parole, una somma tra due polinomi corrisponde ad un polinomio il cui grado è il massimo tra i due gradi dei polinomi sommati.
    \[\deg(p(x) + q(x)) = \max(\deg(p(x)), \deg(q(x)))\]

    Per quanto riguarda il prodotto tra due polinomi, invece, abbiamo che:
    \[\begin{split}
        p(x)q(x) &= ( a_0 + a_1x + a_2x^2 + \ldots + a_n x^n)(b_0 + b_1x + b_2x^2 + \ldots + b_m x^m) \\
        &= a_0b_0+a_0b_1x+a_0b_2x^2+\ldots a_0b_m^m + \ldots + a_nb_0x^n+a_nb_1x^{n+1}+a_nb_2x^{n+2}+\ldots a_nb_mx^{n+m} \\
    \end{split}\]

    Notiamo quindi che $\deg(p(x)q(x)) = n + m$. In altre parole, un prodotto tra due polinomi corrisponde ad un polinomio il cui grado è la somma tra i due gradi dei polinomi moltiplicati.
    \[\deg(p(x) + q(x)) = \deg(p(x)) + \deg(q(x))\]

    Oltre al grado di un polinomio, siamo interessati ai valori che \textit{annullano} tali polinomi, ossia i valori di $x$ che una volta sostituiti all'interno di esso restituiscono il valore 0. Tali valori vengono detti \textbf{radici} del polinomio.

    Ad esempio, consideriamo il polinomio $p(x) = x^3-2x^2+x$. Notiamo facilmente che:
    $p(0) = 0^3-2 \cdot 0^2 + 0 = 0$ e che $p(1) = 1^3 - 2 \cdot 1^2 + 1 = 0$, dunque i valori $0$ e $1$ sono due radici di tale polinomio.

    Il motivo per cui siamo interessati a trovare le radici di un polinomio, deriva dal seguente teorema:
    \begin{framedthm}{Radici di un polinomio}
        Dato un polinomio $p(x) = c_0 + c_1x + c_2x^2 + \ldots + c_n x^n$ e un valore $\alpha$, abbiamo che:
        \[p(\alpha) = 0 \iff \exists q(x) \text{ tale che } p(x) = (x-\alpha) q(x)  \]

        In altre parole, il valore $\alpha$ è radice di $p(x)$ se e solo se $p(x)$ è un multiplo di $(x-\alpha)$

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    Considerando ancora il polinomio $p(x) = x^3-2x^2+x$, sappiamo che $0$ e $1$ siano due sue radici. Per il teorema, esistono due polinomi $q_0(x)$ e $q_1(x)$ tali che:
    \[p(x) = (x-0) q_0(x) = (x-1) q_1(x)\]

    Difatti, tali polinomi corrispondono a $q_0(x) = x^2-2x+1$ e $q_1(x) = x^2-x$:
    \[x^3-2x^2+x = (x-0)(x^2-2x+1) = (x-1)(x^2-x)\]

    Ovviamente, il teorema varrà anche per i due polinomi appena ottenuti. Infatti, abbiamo che $q_0(1) = 0$ e che $q_1(0) = 0$, ottenendo che $q_0(x) = (x-1)(x-1)$ e che $q_1(x) = (x-0)(x-1)$. Dunque, entrambe le ultime due \textit{scomposizioni} ci portano ad una comune \textbf{scomposizione in polinomi di primo grado} del polinomio originale:
    \[p(x) = (x-0)(x-1)(x-1) = (x-1)(x-0)(x-1)\]

    concludendo che $p(x) = x(x-1)^2$. Notiamo inoltre che la radice $1$ compaia quindi due volte all'interno di $p(x)$. Il numero di volte che una radice è presente all'interno di un polinomio viene detta \textbf{molteplicità algebrica} della radice.

    Tuttavia, la possibilità di un polinomio di essere scomposto in polinomi di primo grado dipende solo ed esclusivamente dall'insieme numerico di riferimento. Ad esempio, consideriamo il polinomio $p(x) = 2 x^2 + 3 x - 2$. Supponiamo di voler considerare solo ed esclusivamente le \textit{radici intere} di tale polinomio. In tal caso, notiamo che:
    \[p(-2) = 2(-2)^2 + 3(-2) -2 = 0 \implies p(x) = (x-2)\rbk{x-\frac{1}{2}}\]

    Otteniamo quindi che $p(x)$ abbia due radici: una intera ed una razionale. Tuttavia, abbiamo assunto di voler considerare solo ed esclusivamente le radici intere di tale polinomio. Per tanto, $p(x)$ risulta in realtà essere \textbf{irriducibile} in $\Z$, ossia non scomponibile in polinomi di primo grado con coefficiente costante pari in $\Z$. Ovviamente tale risultato ci dice anche che $p(x)$ sia \textbf{riducibile} in $\Q$ (e di conseguenza anche in $\R$).

    Dopo aver discusso l'importanza della scomposizione di polinomi, possiamo ora discutere quali siano i metodi efficaci per poter svolgere tali scomposizioni. Sorprendentemente, il metodo più efficiente risulta coincidere con la banale \textit{divisione in colonna}.

    Supponiamo ad esempio di voler dividere $a(x) = 2x^4+3x^3-2x^2+x-4$ per $b(x) = x^2-x+1$. Effettuando la divisione in colonna come se fosse una normalissima divisione a più cifre, otteniamo che:

    \begin{center}
        \begin{tabular}{c|c}
            \begin{tabular}{c c c c c}
                $+2x^4$ & $+3x^3$ & $-2x^2$ & $+x$ & $-4$\\ 
                $-2x^4$ & $+2x^3$ & $-2x^2$ &      &     \\
                \hline
                        & $+5x^3$ & $-4x^2$ & $+x$  & $-4$\\
                        & $-5x^3$ & $+5x^2$ & $-5x$ &    \\
                \hline
                        &         & $x^2$   & $-4x$ & $-4$ \\
                        &         & $-x^2$  & $+x$  & $-1$ \\
                \hline
                        &         &         & $+3x$ & $-5$
                    
            \end{tabular}
            &
            \begin{tabular}{c c c }
                $+x^2$ & $-x$ & $+1$ \\
                \hline
                $2x^2$ & $+5x$ & $+1$
                \\\\\\\\\\\\
            \end{tabular}
            \\
        \end{tabular}
    \end{center}
    
    Quindi concludiamo che:
    \[ 2x^4+3x^3-2x^2+x-4 = (x^2-x+1)(2x^2+5x+1)+3x-5\]

    dove $r(x) = 3x-5$ è il \textbf{resto} di tale divisione. In linea generale, dunque, la divisione tra due polinomi $a(x)$ e $b(x)$ ci permette di trovare i polinomi $q(x)$ ed $r(x)$ tali che $a(x) = b(x) q(x) + r(x)$. Quando il resto di una divisione tra $a(x)$ e $b(x)$ è nullo, otteniamo che $a(x)$ sia un multiplo di $b(x)$.

    Calcolare tali divisioni può essere tuttavia molto tedioso per via del numero di passaggi da effettuare. Nel caso in cui il quoziente $b(x)$ della divisione sia un polinomio di primo grado, possiamo utilizzare la \textbf{regola di Ruffini} per velocizzare i calcoli.

    \newpage

    Ad esempio, supponiamo di voler calcolare la divisione tra  $a(x)=x^4-3x^3+2x-5$ e $b(x)=x+2$. La regola di Ruffini procede come segue:
    \begin{enumerate}
        \item Disponiamo i coefficienti di $a(x)$ e la radice di $b(x)$ nel seguente formato tabellare:
        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-3$ & $0$ & $2$ & $-5$\\
            $-2$ &       &  &  & & \\
            \hline
                &  &  &  &  & \\
            \end{tabular}
        \end{center}

        \textit{Nota}: ricordiamo che $b(x) = (x+2) = (x-(-2))$, dunque $-2$ è la radice

        \item Copiamo il primo coefficiente di $a(x)$ nell'ultima riga della tabella:

        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-3$ & $0$ & $2$ & $-5$\\
            $-2$ &       &  &  & & \\
            \hline
                &  $1$ &  &  &  & \\
            \end{tabular}
        \end{center}

        \item Calcoliamo il prodotto $1 \cdot (-2) = -2$, ponendo il risultato al centro della seconda colonna interna:
        
        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-3$ & $0$ & $2$ & $-5$\\
            $-2$ &       & $-2$ &  & & \\
            \hline
                &  $1$ &  &  &  & \\
            \end{tabular}
        \end{center}

        \item Sommiamo il risultato ottenuto con il coefficiente di $a(x)$ presente all'interno della stessa colonna su cui abbiamo appena scritto, scrivendo il risultato della somma nell'ultima riga della tabella:
        
        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-3$ & $0$ & $2$ & $-5$\\
            $-2$ &       & $-2$ &  & & \\
            \hline
                &  $1$ & $-5$ &  &  & \\
            \end{tabular}
        \end{center}

        \item Ripetiamo i due passaggi precedenti, questa volta considerando $-5$ e $-2$
        
        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-3$ & $0$ & $2$ & $-5$\\
            $-2$ &       & $-2$ & $10$ & & \\
            \hline
                &  $1$ & $-5$ & $10$ &  & \\
            \end{tabular}
        \end{center}

        \item Ripetendo il procedimento fino alla fine, otteniamo la seguente tabella:
        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-3$ & $0$ & $2$ & $-5$\\
            $-2$ &       & $-2$ & $10$ & $-20$ & $36$\\
            \hline
                & $1$ & $-5$ & $10$ & $-18$ & $31$\\
            \end{tabular}
        \end{center}

        \item Il quoziente $q(x)$ sarà un polinomio di grado $\deg(a(x)) - 1$ i cui coefficienti sono descritti dalle celle dell'ultima riga, esclusa la cella più a destra la quale invece corrisponde al resto $r(x)$. In altre parole, abbiamo che $q(x) = x^3-5x^2+10x-18$ e che $r(x) = 31$, concludendo che:
        \[ x^4-3x^3+2x-5 = (x+2)(x^3-5x^2+10x-18)+31\]
    \end{enumerate}

    \newpage

    L'uso della regola di Ruffini risulta \underline{estremamente} comodo nel caso di calcoli di \textbf{scomposizioni in polinomi di primo grado}. Ad esempio, consideriamo il polinomio $p(x) = x^3 - 2 x^2 - 5 x + 6$. Notiamo che $p(1) = 0$, dunque per il teorema delle radici sappiamo che il polinomio $(x-1)$ deve necessariamente dividere $p(x)$. Applichiamo quindi la regola di Ruffini:
    \begin{center}
        \begin{tabular}{c | c c c | c}
             & $1$ & $-2$ & $-5$ & $6$\\
        $1$ &       & $1$ & $-1$ & $-6$\\
        \hline
            & $1$ & $-1$ & $-6$ & $0$ \\
        \end{tabular}
    \end{center}

    concludendo che $p(x) = (x-1)(x^2-x-6)$. A questo punto, posto $q(x) = x^2-x-6$, notiamo che $q(3) = 0$. Applicando ancora la regola di Ruffini otteniamo che:
    
    \begin{center}
        \begin{tabular}{c | c c | c}
             & $1$ & $-1$ & $-6$\\
        $3$ &       & $3$ & $6$\\
        \hline
            & $1$ & $2$ & $0$ \\
        \end{tabular}
    \end{center}

    concludendo che $q(x) = (x-3)(x+2)$ e dunque che $p(x) = (x-1)(x-3)(x+2)$.

    Nel caso ancor più particolare dei polinomi di secondo grado, possiamo utilizzare direttamente la ben più nota \textbf{formula quadratica} per trovare le sue due radici: dato il polinomio di secondo grado $p(x) = ax^2+bx+c$, le radici di $p(x)$ sono date da
    \[x_{1,2} = \frac{-b \pm \sqrt{b^2-4ac}}{2a}\]

    Ad esempio, considerando il polinomio $p(x) = x^2-x-6$, le sue radici sono date da:
    \[x_{1,2} = \frac{-(-1) \pm \sqrt{(-1)^2 - 4(1)(-6)}}{2(1)} = \frac{1 \pm \sqrt{25}}{2} = \frac{1 \pm 5}{2}\]

    da cui concludiamo che $x_1 = \dfrac{1 + 5}{2} = 3$ e $x_2 = \dfrac{1 - 5}{2} = -2$ e dunque che $p(x) = (x-3)(x+2)$.

    \newpage

    \section{Trigonometria}

    La trigonometria è la parte della matematica che studia i triangoli a partire dai loro angoli. Poiché ogni figura geometrica può essere descritta come un insieme di triangoli, la trigonometria risulta essere uno strumento fondamentale nella geometria. In questa sezione, ci interesseremo del fornire le basi dietro le principali operazioni trigonometriche.

    Consideriamo una circonferenza di raggio 1, detta \textbf{circonferenza unitaria}, i cui punti sono descritti dalle coordinate $(x,y)$, avente come origine il punto $O = (0,0)$. Dato un punto $P = (a,b)$ della circonferenza, il segmento $\overline{OP}$ corrisponde a:
    \begin{center}
        \includegraphics[scale=0.6]{images/trig2.png}
    \end{center} 

    Notiamo facilmente che tale segmento induca la presenza di un triangolo retto su tale circonferenza, ossia il triangolo $\overline{OAP}$, dove $A$ è il punto che interseca l'asse delle ascisse e la retta perpendicolare ad essa passante per $P$:
    \begin{center}
        \includegraphics[scale=0.6]{images/trig3.png}
    \end{center}

    Siano quindi $\ell_{\overline{OP}}, \ell_{\overline{OA}}$ e $\ell_{\overline{AP}}$ rispettivamente le lunghezze dei segmenti $\overline{OP}, \overline{OA}$ e $\overline{AP}$. Poiché la circonferenza ha raggio $1$, ne segue che la lunghezza del segmento $\overline{OP}$ sia $a = 1$. Di conseguenza, per il teorema di Pitagora, abbiamo che:
    \[(\ell_{\overline{OP}})^2 = (\ell_{\overline{OA}})^2 + (\ell_{\overline{AP}})^2 \implies 1 = (\ell_{\overline{OA}})^2 + (\ell_{\overline{AP}})^2\]

    Essendo un triangolo retto, esso induce anche la presenza di due angoli non retti $\alpha$ e $\beta$ al suo interno (entrambi descritti in radianti). Senza perdita di generalità, assumiamo che $\alpha$ sia l'angolo associato al vertice dell'origine. Tale angolo ci permette di descrivere il punto $P$ senza dover necessariamente sapere le sue coordinate.

    \begin{frameddefn}{Seno e coseno}
        Dato un angolo $\alpha$ descrivente un punto $P = (x,y)$ sulla circonferenza unitaria, definiamo il \textbf{seno} di $\alpha$, indicato con $\sin \alpha$, come l'ordinata di $P$, ossia $\sin \alpha = y$. Analogamente, definiamo il \textbf{coseno}, indicato con $\cos \alpha$, come l'ascissa di $P$. ossia $\cos \alpha = x$.
    \end{frameddefn}
    
    Dall'osservazione precedente segue l'\textbf{identità trigonometrica fondamentale}:
    \[1 = \cos^2 \alpha + \sin^2 \alpha\]

    Inoltre, dalla figura precedente possiamo notare come l'angolo $-\alpha$ descriva il punto $Q = (-x,y)$
    \begin{center}
        \includegraphics[scale=0.575]{images/trig6.png}
    \end{center}
    
    Ciò implica facilmente che:
    \[\sin(\alpha) = -\sin(-\alpha) \qquad\qquad \cos(\alpha) = \cos(-\alpha)\]
    
    \newpage

    Per i principali angoli notevoli, i valori di seno e coseno possono essere riassunti nella seguente tabella di valori:

    \begin{center}
        \begin{tabular}{l|cccccccc}
            & $0 \,(0\degree)$ & $\frac{\pi}{2} \, (90\degree)$ & $\pi \,(180\degree)$ & $\frac{3\pi}{2} \,(270\degree)$  & $\frac{\pi}{4} \,(45\degree)$ &  $\frac{\pi}{3} \,(60\degree)$ & $\frac{\pi}{6} \,(30\degree)$ \\
            \hline 
            $\sin \alpha$ & 0 & 1 & 0 & $-1$ & $\frac{\sqrt{2}}{2}$ & $\frac{\sqrt{3}}{2}$ & $\frac{1}{2}$ \\
            $\cos \alpha$ & 1 & 0 & $-1$ & 0 & $\frac{\sqrt{2}}{2}$ & $\frac{1}{2}$ & $\frac{\sqrt{3}}{2}$
        \end{tabular}
    \end{center}


    Per ottenere i valori di altri angoli non noti, possiamo utilizzare le \textit{formule di addizione tra angoli}.

    \begin{framedprop}{Formule di addizione tra angoli}
        Dati due angoli $\alpha, \beta$, per il seno si ha che:
        \[\sin(\alpha + \beta) = \sin (\alpha) \cos (\beta) + \cos(\alpha) \sin (\beta)\]
        mentre per il coseno abbiamo che:
        \[\cos(\alpha + \beta) = \cos (\alpha) \cos (\beta) - \sin(\alpha) \sin (\beta)\]
    \end{framedprop}
    
    Ad esempio, abbiamo che:
    \[\begin{split}
        \sin(75\degree) &= \sin(45\degree + 30\degree)\\
        &= \sin\rbk{\frac{\pi}{4} + \frac{\pi}{6}}\\
        &= \sin\rbk{\frac{\pi}{4}} \cos\rbk{\frac{\pi}{6}} + \cos\rbk{\frac{\pi}{6}} \sin\rbk{\frac{\pi}{4}} \\
        &= \frac{\sqrt{2}}{2} \cdot \frac{\sqrt{3}}{2} + \frac{\sqrt{2}}{2} \cdot \frac{1}{2} \\
        &= \frac{\sqrt{2} \sqrt{3} + \sqrt{2}}{4}\\
        &= \frac{\sqrt{6}+\sqrt{2}}{4}
    \end{split}\]

    Inoltre, tramite tale formula possiamo facilmente notare che:
    \[\sin(\alpha + 2\pi) = \sin(\alpha) \cos(2\pi) + \cos(\alpha) \sin(2\pi) = \sin(\alpha) \cdot 1 + \cos(\alpha) \cdot 0 = \sin \alpha\]
    e che:
    \[\cos(\alpha + 2\pi) = \cos(\alpha) \cos(2\pi) - \sin(\alpha) \sin(2\pi) = \cos(\alpha) \cdot 1 - \sin(\alpha) \cdot 0 = \cos \alpha\]

    In altre parole, incrementando un angolo $\alpha$ di $2\pi$ radianti il valore del seno e del coseno coincidono con quelli dell'angolo $\alpha$. Graficamente, ciò risulta estremamente intuitivo: incrementare un angolo di $2\pi$ equivale ad effettuare un \textbf{giro completo} sulla circonferenza. In linea generale, dunque, dato un angolo $\alpha$ e un intero $k \in \Z$ abbiamo che:
    \[\sin \alpha = \sin(\alpha+2k\pi) \qquad\qquad \cos \alpha = \cos(\alpha+2k\pi)\]
    
    Consideriamo ora la retta tangente alla circonferenza nel punto $B = (1,0)$. Prolungando il segmento $\overline{OP}$ affinché esso intersechi tale retta tangente, otteniamo il segmento $\overline{OT}$.
    \begin{center}
        \includegraphics[scale=0.6]{images/trig4.png}
    \end{center}

    Notiamo che il triangolo $\overline{OAP}$ e il triangolo $\overline{OTB}$ siano triangoli simili in quanto abbiano gli stessi angoli. Di conseguenza, per il teorema dei triangoli simili abbiamo che:
    \[\frac{\ell_{\overline{BT}}}{\ell_{\overline{OB}}} = \frac{\ell_{\overline{AP}}}{\ell_{\overline{OA}}}\]

    Infine, notiamo che $\ell_{\overline{OB}} = 1, \ell_{\overline{AP}} = \sin \alpha$ e $\ell_{\overline{OA}} = \cos \alpha$, ottenendo quindi che:
    \[\ell_{\overline{BT}} = \frac{\sin \alpha}{\cos \alpha}\]

    \begin{frameddefn}{Tangente e cotangente}
        Dato un angolo $\alpha$ descrivente un punto $P$ sulla circonferenza unitaria, definiamo la \textbf{tangente} di $\alpha$, indicato con $\tan \alpha$, come il rapporto tra il suo seno e il suo coseno. Analogamente, definiamo la \textbf{cotangente} di $\alpha$, indicata con $\cot \alpha$, come il rapporto tra il suo coseno e il suo seno.
        In altre parole, abbiamo che:
    \end{frameddefn}

    Tramite le proprietà del seno e del coseno, inoltre, $\forall k \in \Z$ otteniamo automaticamente che:
    \[\tan(\alpha + 2k\pi) = \frac{\sin(\alpha +2k\pi)}{\cos(\alpha + 2k\pi)} = \frac{\sin \alpha}{\cos \alpha} = \tan \alpha\]
    
    e analogamente che:
    \[\cot(\alpha + 2k\pi) = \frac{\cos(\alpha +2k\pi)}{\sin(\alpha + 2k\pi)} = \frac{\cos \alpha}{\sin \alpha} = \cot \alpha\]

    Inoltre, risulta evidente che $\forall k \in \Z$ valga:
    \[\tan\rbk{\frac{\pi}{2}+k\pi} = \text{indefinito} \quad\quad \cot\rbk{k\pi} = \text{indefinito}\]

    in quanto otterremmo una divisione per zero.

    \newpage

    Infine, consideriamo i seguenti tre operatori: \textbf{arcoseno}, \textbf{arcocoseno} e \textbf{arcotangente}, indicati come $\arcsin$, $\arccos$ e $\arctan$. Dato un valore $x \in \R$, tali operatori ci restituiscono l'angolo $\theta$ per cui si abbia che $\sin \theta = x$, dunque $\arcsin(\sin \theta) = \theta$ oppure $\sin(\arcsin x) = x$ (analogo per coseno e tangente). Ad esempio, dato il valore $1$ abbiamo che $\arcsin(1) = \frac{\pi}{2}$,  $\arccos(1) = 0$ e che $\arctan(1) = \frac{\pi}{4}$.

    \quad

    \section{Equazioni e disequazioni}

    In matematica, definiamo come \textbf{equazione} una qualsiasi formula matematica che esprime l'\textit{eguaglianza} tra due espressioni matematiche che fanno uso di variabili simili o uguali. Ad esempio, la seguente è un'equazione definita sulle variabili $x$ e $y$:
    \[2x+x^2 + \abs{x-y} = 4^x+y-\frac{2}{y}\]

    \textbf{Risolvere} un'equazione definita su $n$ variabili significa determinare quali siano i valori assumibili da tali variabili affinché l'equazione sia vera. Tale processo può essere visto come un cercare di semplificare l'equazione stessa ai termini minimi possibili, solitamente attraverso l'affermazione di equazioni intermedie che derivino dalla precedente che mantengano inalterati le \textit{soluzioni} dell'equazione, ossia i valori che la rendono vera. Un'equazione può avere un \textbf{insieme di soluzioni} finito, infinito o vuoto.

    Ad esempio, consideriamo la seguente equazione:
    \[5x+6y = 18x^2-6y + 7\]

    Per trovare le coppie di valori di $x,y$ che soddisfano tale equazione, procediamo nel seguente modo:
    \begin{enumerate}
        \item Sottraiamo ad entrambe le espressioni tutti i termini dell'espressione sinistra:
        \[5x+6y - (5x+6y) = 18x-6y + 7 - (5x+6y)\]

        ottenendo che:
        \[0 = 13x-12y+7\]

        \item A questo punto, separiamo i termini delle due espressioni in base alle variabili $x$ e $y$:
        \[0 - (13x) = 13x-12y+7 - (13x)\]

        ottenendo che:
        \[-13x = -12y+7\]

        \item Dividendo entrambi i membri per $-13$ otteniamo che:
        \[x = \frac{12}{13}y -\frac{7}{13}\]

        \item Non potendo più semplificare in alcun modo l'equazione, concludiamo che l'insieme delle soluzioni sia $\{(x,y) \in \R^2 \mid x = \frac{12}{13}y -\frac{7}{13}\}$, dove $\R^2 = \R \times \R$.
    \end{enumerate}


    Quando un'equazione è definita su \textbf{due variabili}, è possibile rappresentare l'insieme delle soluzioni tramite un \textit{piano cartesiano} di coordinate $(x,y)$ tali che ogni punto rappresentato sia una soluzione all'equazione.

    Ad esempio, per l'equazione appena risolta l'insieme delle soluzioni può essere rappresentato come:
    \begin{center}
        \includegraphics[scale=0.5]{images/eq.png}
    \end{center}

    Di particolare interesse per le equazioni risulta essere la \textbf{legge di annullamento del prodotto}: dati dei termini $x_1, \ldots, x_n$, si verifica che $x_1 \cdot \ldots \cdot x_n = 0$ se e solo se almeno uno tra $x_1, \ldots, x_n$ è nullo.

    Ad esempio, consideriamo la seguente equazione:
    \[x^2+x^3+8x= 3x^3-4x^2+5\]

    Per trovare i valori di $x$ che soddisfano tale equazione, procediamo nel seguente modo:
    \begin{enumerate}
        \item Sottraiamo ad entrambe le espressioni tutti i termini dell'espressione destra 
        \[x^2+x^3+8x - (3x^3-4x^2+5) = 3x^3-4x^2+5 - (3x^3-4x^2+5)\]

        ottenendo che:
        \[x^2+x^3+8x - 3x^3+4x^2-5 = 0\]

        \item Semplifichiamo l'espressione sinistra:
        \[-2x^3 + 5x^2+8x-5 = 0\]

        \item Abbiamo ottenuto un polinomio di terzo grado, il quale sappiamo essere uguale a 0 se e solo se $x$ è una radice. In particolare, notiamo che $\frac{1}{2}$ sia una radice del polinomio.
        
        Scomponiamo quindi il polinomio tramite la regola di Ruffini:
        
        \begin{center}
            \begin{tabular}{c | c c c | c}
                 & $-2$ & $5$ & $8$ & $-5$\\
            $\frac{1}{2}$ &       & $-1$ & $2$ & $5$\\
            \hline
                & $-2$ & $4$ & $10$ & $0$ \\
            \end{tabular}
        \end{center}

        ottenendo che:
        \[\rbk{x-\frac{1}{2}}(-2x^2+4x+10) = 0\]

        \item A questo punto, tramite la formula quadratica possiamo trovare subito le due radici rimanenti:
        \[\begin{split}
            x_{1,2} &= \frac{-4 \pm \sqrt{16-4(-2)(10)}}{2(-2)} \\
            &= \frac{-4 \pm \sqrt{96}}{-4} \\
            &= \frac{-4 \pm \sqrt{16 \cdot 6}}{-4} \\
            &= \frac{-4 \pm \sqrt{16} \sqrt{6}}{-4} \\
            &= \frac{-4 \pm 4 \sqrt{6}}{-4} \\
            &= 1 \pm (-\sqrt{6})
        \end{split}\]

        concludendo che $1 + \sqrt{6}$ e $1- \sqrt{6}$ siano le due radici rimanenti

        \item Abbiamo quindi ridotto la nostra equazione iniziale alla seguente:
        \[\rbk{x-\frac{1}{2}} (x-1 - \sqrt{6})(x-1 + \sqrt{6}) = 0\]

        \item A questo punto, per la legge di annullamento del prodotto sappiamo che tale equazione risulta possibile se e solo se almeno uno dei tre termini sia nullo. Di conseguenza, ogni qualvolta uno di tali termini sia nullo l'equazione risulta vera:
        \[\begin{array}{c}
            x-\frac{1}{2} = 0 \\
            \text{oppure} \\
            x-1 - \sqrt{6} \\
            \text{oppure} \\
            x-1 + \sqrt{6}
        \end{array} \iff \begin{array}{c}
            x = \frac{1}{2} \\
            \text{oppure} \\
            x = 1 + \sqrt{6} \\
            \text{oppure} \\
            x = 1 - \sqrt{6}
        \end{array}\]
        
        concludendo che le soluzioni dell'equazione siano $x \in \cbk{\frac{1}{2}, 1 + \sqrt{6}, 1- \sqrt{6}}$.
    \end{enumerate}

    Le \textbf{disequazioni} si basano sugli stessi concetti delle equazioni, ma il segno di eguaglianza è sostituito da un segno di diseguaglianza, il quale può essere $<, >, \leq$ o $\geq$. Le disequazioni godono di una proprietà aggiuntiva, detta \textbf{cambio del segno}
    \[x \leq y \implies -x \geq -y\]
    
    Consideriamo ad esempio la seguente disequazione:
    \[-5x \leq 30 + 24y + x\]

    \begin{enumerate}
        \item Prima di tutto, sommiamo $-x$ ad entrambi i membri:
        \[-6x \leq 30+24y\]
        \item Successivamente, dividiamo entrambi i membri per $-6$ (per la proprietà di cambio del segno, la disequazione viene invertita)
        \[x \geq -5-4y\]
        \item Non possiamo più ridurre i termini della disequazione, ottenendo che la disequazione originale sia vera per ogni coppia di valori $x,y \in \R$ tali che $x \geq -4y-5$
    \end{enumerate}

    Per quanto riguarda la legge di annullamento del prodotto, nel caso delle disequazioni abbiamo una legge quasi analoga ad essa, ossia la banale \textbf{regola dei segni}: dati dei termini $x, y$, si ha che
    \[xy > 0 \iff x,y > 0 \text{ oppure } x,y < 0\]
    e di conseguenza che
    \[xy < 0 \iff (x > 0 \text{ e } y < 0) \text{ oppure } (x < 0 \text{ e } y > 0)\]
    
    Consideriamo ad esempio, la seguente disequazione:
    \[x(x+1) \geq 0\]
    
    \begin{enumerate}
        \item Per definizione stessa abbiamo che:
        \[x(x+1) \geq 0 \iff \begin{array}{c}
            x(x+1) = 0 \\
            \text{oppure} \\
            x(x+1) > 0
        \end{array}\]

        \item Tramite la legge di annullamento del prodotto sappiamo che:
        \[\begin{array}{c}
            x(x+1) = 0 \\
            \text{oppure} \\
            x(x+1) > 0
        \end{array}
        \iff \begin{array}{c}
            x = 0 \\
            \text{oppure} \\
            x = -1 \\
            \text{oppure} \\
            x(x+1) > 0
        \end{array}\]

        \item Per la regola dei segni abbiamo che:
        \[\begin{array}{c}
            x(x+1) = 0 \\
            \text{oppure} \\
            x(x+1) > 0
        \end{array}
        \iff \begin{array}{c}
            x = 0 \\
            \text{oppure} \\
            x = -1 \\
            \text{oppure} \\
            x > 0 \text{ e } x+1 > 0\\
            \text{oppure} \\
            x < 0 \text{ e } x+1 < 0\\
        \end{array}\]

        \newpage

        \item Notiamo quindi che $x > 0$ e $x+1 > 0$ siano condizioni entrambe verificate se $x > 0$. Analogamente, abbiamo che $x < 0$ e $x+1 < 0$ sono verificate se $x < -1$. Per tanto, abbiamo che:
        \[\begin{array}{c}
            x = 0 \\
            \text{oppure} \\
            x = -1 \\
            \text{oppure} \\
            x > 0 \text{ e } x+1 > 0\\
            \text{oppure} \\
            x < 0 \text{ e } x+1 < 0\\
        \end{array} \iff
        \begin{array}{c}
            x = 0 \\
            \text{oppure} \\
            x = -1 \\
            \text{oppure} \\
            x > 0\\
            \text{oppure} \\
            x < -1\\
        \end{array}\]

        \item A questo punto, possiamo accorpare le informazioni ottenute:
        \[
        \begin{array}{c}
            x = 0 \\
            \text{oppure} \\
            x = -1 \\
            \text{oppure} \\
            x > 0\\
            \text{oppure} \\
            x < -1\\
        \end{array} \iff
        \begin{array}{c}
            x \geq 0 \\
            \text{oppure} \\
            x \leq -1 \\
        \end{array}\]

        concludendo che le soluzioni siano $\{x \in \R \mid x \leq -1 \lor x \geq 0\}$, dove il simbolo $\lor$ significa \textit{"oppure"}
    \end{enumerate}

    Generalmente, dunque, tramite la regola dei segni e la legge di annullamento del prodotto otteniamo la seguente ulteriore regola: dati dei termini $x, y$, si ha che
    \[xy \geq 0 \iff x,y \geq 0 \text{ oppure } x,y \leq 0\]
    e di conseguenza che
    \[xy \leq 0 \iff (x \geq 0 \text{ e } y \leq 0) \text{ oppure } (x \leq 0 \text{ e } y \geq 0)\]

    Poiché svolgere un processo simile a quello mostrato precedentemente risulta essere tedioso per disequazioni più complesse, possiamo utilizzare una \textit{rappresentazione grafica} detta \textbf{grafico del segno}.
    
    Consideriamo ad esempio la seguente disequazione:
    \[x(x-1)(x+3) \geq 0\]
    \begin{enumerate}
        \item Prima di tutto, scomponiamo la disequazione in tre disequazioni:
        \[x(x-1)(x+3) \geq 0 \iff \begin{array}{c}
            x \geq 0 \\
            \text{oppure}\\
            x-1 \geq 0 \\
            \text{oppure}\\
            x+3 \geq 0 \\
        \end{array}\]

        \item Risolvendo le tre disequazioni otteniamo quindi che:
        \[x(x-1)(x+3) \geq 0 \iff \begin{array}{c}
            x \geq 0 \\
            \text{oppure}\\
            x \geq 1 \\
            \text{oppure}\\
            x \geq -3 \\
        \end{array}\]

        \item Disegniamo il seguente grafico del segno, dove i segmenti non tratteggiati rappresentano la parte maggioritaria delle tre disequazioni, tratteggiata la parte minoritaria e i pallini rappresentano l'eguaglianza
        
        \begin{center}
            \includegraphics[scale=0.6]{images/sign1.png}
        \end{center}

        \item Per la regola del segno, quando in un intervallo il numero di disequazioni minoritarie risulta essere dispari, il prodotto tra tali disequazioni sarà minoritario. Se invece il numero di disequazioni minoritarie è pari, il prodotto tra tali disequazioni sarà maggioritario
        
        \begin{center}
            \includegraphics[scale=0.575]{images/sign3.png}
        \end{center}

        \item Per tanto, concludiamo che la disequazione $x(x-1)(x+3) \geq 0$ abbia come soluzioni $\{x \in \R \mid -3 \leq x \leq -1 \lor x \geq 1\}$
    \end{enumerate}

    \newpage

    Vediamo ora invece quello che viene comunemente chiamato \textbf{sistema di equazioni} (o di disequazioni). Un sistema di equazioni corrisponde ad un insieme di equazioni per cui vogliamo che le variabili definite in essi rispettino tutte le equazioni presenti nel sistema.

    Ad esempio, consideriamo il seguente sistema:
    \[\soe{l}{
        7x+y = 31 \\
        3x-4y = 0
    }\]

    Per risolvere tale sistema, possiamo operare in più modi:
    \begin{itemize}
        \item Riscriviamo una delle due equazioni in modo da poter \textit{sostituire} nell'altra i valori ottenuti:
        \[\soe{l}{
            7x+y = 31 \\
            3x-4y = 0
        } \implies \soe{l}{
            7x+y = 31 \\
            x= \frac{4}{3}y
        } \implies \soe{l}{
            7\rbk{\frac{4}{3}y}+y = 31 \\
            x= \frac{4}{3}y
        }
        \]
        \[\implies \soe{l}{
            y = 3 \\
            x= \frac{4}{3}y
        }
        \implies \soe{l}{
            y = 3 \\
            x= 4
        }\]

        \item Sommando un multiplo dei termini sinistri e destri di un'equazione rispettivamente al termine sinistro e destro di un'altra equazione: 
        \[\soe{l}{
            7x+y = 31 \\
            3x-4y = 0
        } \implies
        \soe{l}{
            7x+y = 31 \\
            3x-4y +4(7x+y)= 0 + 4(31)
        } \]
        \[\implies
        \soe{l}{
            7x+y = 31 \\
            x= 4
        } \implies
        \soe{l}{
            y = 3 \\
            x= 4
        }\]
    \end{itemize}
    
    Per i sistemi di disequazioni, la logica rimane la stessa:
    \[\soe{l}{
        7x+y \geq 31 \\
        3x-4y \geq 0
    } \implies
    \soe{l}{
        7x+y \geq 31 \\
        3x-4y +4(7x+y) \geq 0 + 4(31)
    } \]
    \[\implies
    \soe{l}{
        7x+y \geq 31 \\
        x\geq 4
    } \implies
    \soe{l}{
        y \geq 3 \\
        x\geq 4
    }\]

    dunque le soluzioni sono $\{(x,y) \in \R^2 \mid x \geq 4, y \geq 3\}$.


    \newpage

    \section{Esercizi svolti}

    \begin{framedprob}{}
        Risolvere le seguenti equazioni e disequazioni in $\R$:
        \begin{enumerate}
            \item $x^4-6x^3+9x^2+4x-12 = 0$
            \item $4 x^3 + \frac{2}{3}x^2 + 12 x + 2 = 0$
            \item $\abs{x+4} = x^2-x$
            \item $\soe{l}{
                \abs{x+1} - 2x \leq 2 \\
                -x^2-3x-1 > 0
            }$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}

    \begin{enumerate}
        \item Per evitare di procedere a casaccio nell'individuare le radici del polinomio, sfruttiamo il seguente teorema: se un polinomio $p(x) = c_0 + c_1x + \ldots + c_nx^n$ ha coefficienti interi, dunque $c_0, \ldots, c_n \in \Z$, allora $\forall a,b \in \Z$ si ha che:
        \[a \text{ non divide } c_0 \text{ oppure } b \text{ non divide } c_n \implies p\rbk{\frac{a}{b}} \neq 0\]

        Tale teorema ci permette di restringere notevolmente i nostri potenziali valori da testare. Ad esempio, in questo caso abbiamo che $c_0 = -12$ e $c_4 = 1$, dunque le nostre radici \underline{razionali} possibili sono:
        \[\pm \frac{1}{1}, \; \pm \frac{2}{1}, \; \pm \frac{3}{1}, \; \pm\frac{4}{1}, \; \pm\frac{6}{1}, \; \pm\frac{12}{1}\] 

        ossia $\pm 1, \; \pm 2, \; \pm 3, \; \pm 4, \; \pm 12$.

        Cerchiamo quindi una soluzione possibile tra i valori trovati:
        \begin{itemize}
            \item $(1)^4-6(1)^3+9(1)^2+4(1)-12 = -4$, dunque non è radice
            \item $(-1)^4-6(-1)^3+9(-1)^2+4(-1)-12 = 0$, dunque è radice
        \end{itemize}
        
        Utilizzando la regola di Ruffini, otteniamo che:
        \begin{center}
            \begin{tabular}{c | c c c c | c}
                 & $1$ & $-6$ & $9$ & $4$ & $-12$\\
            $-1$ &       & $-1$ & $7$ & $-16$& $12$\\
            \hline
                & $1$ & $-7$ & $16$ & $-12$ & $0$ \\
            \end{tabular}
        \end{center}

        dunque $x^4-6x^3+9x^2+4x-12 = (x+1)(x^3-7x^2+16x-12)$. Cerchiamo quindi un'altra radice utilizzando sempre i valori precedentemente trovati:
        \begin{itemize}
            \item $(2)^4-6(2)^3+9(2)^2+4(2)-12 = 0$, dunque è radice
        \end{itemize}

        \newpage

        Utilizzando la regola di Ruffini, otteniamo che:
        \begin{center}
            \begin{tabular}{c | c c c| c}
                 & $1$ & $-7$ & $16$ & $-12$\\
            $2$ &       & $2$ & $-10$ & $12$\\
            \hline
                & $1$ & $-5$ & $6$ &  $0$ \\
            \end{tabular}
        \end{center}

        dunque $x^4-6x^3+9x^2+4x-12 = (x+1)(x-2)(x^2-5x+6)$. A questo punto, essendo arrivati ad un polinomio di secondo grado, utilizziamo la formula quadratica per trovare le ultime due radici:
        \[x_{1,2} = \frac{5 \pm \sqrt{25-4\cdot 6}}{2} = \frac{5 \pm 1}{2}\]
        concludendo che $x_1 = 2$ e $x_2 = 3$ e dunque che:
        \[x^4-6x^3+9x^2+4x-12 = (x+1)(x-3)(x-2)^2\]
        
        Per tanto, le soluzioni sono $x \in \{-1, 2, 3\}$.

        \item Notiamo che il polinomio in questo caso non abbia coefficienti interi, impedendoci di utilizzare il teorema dell'esercizio precedente. Tuttavia, possiamo in realtà moltiplicare entrambi i membri dell'equazione per trasformarla in un polinomio a coefficienti interi:
        \[4 x^3 + \frac{2}{3}x^2 + 12 x + 2 = 0 \iff 12x^3+2x^2+36+6 = 0\]

        A questo punto, abbiamo che $c_0 = 6$ e $c_3 = 12$, dunque i valori da verificare sono:
        \[\pm \frac{1}{1}, \; \pm \frac{1}{2}, \; \pm \frac{1}{3}, \; \pm \frac{1}{4}, \; \pm \frac{1}{6}, \; \pm \frac{1}{12}, \; \pm \frac{2}{1}, \; \pm \frac{2}{2}, \; \pm \frac{2}{3}, \; \pm \frac{2}{4}, \; \pm \frac{2}{6}, \; \pm \frac{2}{12}, \;\]
        \[\pm \frac{3}{1}, \; \pm \frac{3}{2}, \; \pm \frac{3}{3}, \; \pm \frac{3}{4}, \; \pm \frac{3}{6}, \; \pm \frac{3}{12}\]

        ossia i valori $\pm 1, \; \pm 2 \; \pm 3\; \pm \frac{1}{2}, \; \pm \frac{1}{3}, \; \pm \frac{1}{4}, \; \pm \frac{1}{6}, \pm \frac{1}{12}, \pm \frac{2}{3},\; \frac{3}{2}, \pm \frac{3}{4}$.

        Dopo varie prove, notiamo che $-\frac{1}{6}$ sia radice del polinomio. Dunque, tramite Ruffini abbiamo che:

        \begin{center}
            \begin{tabular}{c | c c c| c}
                 & $4$ & $\frac{2}{3}$ & $12$ & $2$\\
            $-\frac{1}{6}$ &       & $-\frac{4}{6}$ & $0$ & $-2$\\
            \hline
                & $4$ & $0$ & $12$ &  $0$ \\
            \end{tabular}
        \end{center}

        concludendo che $4 x^3 + \frac{2}{3}x^2 + 12 x + 2 = \rbk{x+\frac{1}{6}}(4x^2+12) = 4\rbk{x+\frac{1}{6}}(x^2+3)$. A questo punto, tramite la formula quadratica notiamo che:
        \[x_{1,2} = \frac{0 \pm \sqrt{0 - 4(12)}}{2} = \pm \frac{\sqrt{-48}}{2}\]
        la quali però non risultano essere valori reali in quanto la radice è definita solo per valori reali non negativi. Per tanto, tale polinomio è in realtà irriducibile in $\R$, concludendo che l'unica soluzione reale sia $x = -\frac{1}{6}$. 

        \newpage

        \item Per sviluppare tale equazione, è necessario dividere i valori possibili in due casi per via del valore assoluto:
        \begin{itemize}
            \item Quando $x+4 \geq 0$ abbiamo che $\abs{x+4} = x+4$, dunque otteniamo che:
            \[\abs{x+4} = x^2 - x \iff x+4 = x^2-x \iff x^2 = 4 \iff x = \pm 2\]

            A questo punto, dobbiamo unire le due condizioni trovate: l'equazione risulta vera quando quando $x \geq -4$ e $x = \pm 2$. Poiché $x = \pm 2$ rispetta la condizione $x \geq -4$, quest'ultima diventa superflua, concludendo che $x = 2$ e $x = -2$ siano due soluzioni valide
            
            \item Quando $x+4 < 0$ abbiamo che $\abs{x+4} = -x-4$, dunque otteniamo che:
            \[\abs{x+4} = x^2 - x \iff -x-4 = x^2-x \iff x^2 + 4 \iff x = \pm \sqrt{-4}\]

            Tuttavia, tali valori trovati non risultano essere reali. Per tanto, in questo caso l'equazione non ha soluzioni.
        \end{itemize}

        Unendo i due casi, dunque, concludiamo che le soluzioni siano $\{-2, 2\}$.

        \item Risolviamo separatamente le due disequazioni del sistema:
        
        \begin{itemize}
        
            \item Per la disequazione $\abs{x+1} - 2x \leq 2$, dividiamo in due casi:
            \begin{itemize}
                \item Se $x +1 \geq 0$ allora:
                \[\abs{x+1} - 2x \leq 2 \iff x+1 - 2x \leq 2 \iff x \geq -1 \]
                
                Ottenendo quindi una condizione equivalente a quella di partenza. Per tanto, la disequazione risulta vera quando $x \geq 1$.

                \item Se $x+1 < 0$ allora:
                \[\abs{x+1} - 2x \leq 2 \iff -x-1 -2x \leq 2 \iff x \geq -1\]

                Tuttavia, unendo le due condizioni notiamo che $x < -1$ e $x \geq -1$, il che risulta impossibile. Per tanto, in questo caso la disequazione risulta falsa.
            \end{itemize}

            Dunque, concludiamo che le soluzioni siano $\{x \in \R \mid x \geq -1\}$

            \item Prima di tutto, poniamo la disequazione in una forma standard invertendone il segno:
            \[-x^2-3x-1 > 0 \iff x^2+3x+1 < 0\]

            Successivamente, troviamo le due radici del polinomio:
            \[x_{1,2} = \frac{-3 \pm \sqrt{9-4}}{2} = \frac{-3 \pm \sqrt{5}}{2}\]
            ottenendo dunque che:
            \[x^2+3x+1 < 0 \iff \rbk{x+\frac{3 + \sqrt{5}}{2}}\rbk{x+\frac{3 - \sqrt{5}}{2}} < 0 \]

            e quindi che le soluzioni siano $\{x \in \R \mid \frac{3 + \sqrt{5}}{2} < x < -\frac{3 - \sqrt{5}}{2}\}$
        \end{itemize}

        A questo punto, considerando l'intersezione tra gli insiemi di soluzioni delle due disequazioni, otteniamo che l'insieme delle soluzioni dell'intero sistema sia $\{ x \in \R \mid -1 \leq x < -\frac{3 - \sqrt{5}}{2}\}$.
        
    \end{enumerate}


    \chapter{Funzioni ad una variabile reale}

    \section{Funzioni}

    In matematica, il concetto di \textbf{funzione} (o \textit{applicazione}) racchiude il concetto di \textit{mappatura} che associ \underline{ogni} elemento di un primo insieme ad un \underline{unico} elemento di un secondo insieme. 

    \begin{center}
        \includegraphics[scale=0.5]{images/func.png}
    \end{center}

    Ad esempio, consideriamo il seguente insieme di partenza $A = \{a,b,c\}$, detto \textbf{dominio} della funzione, e il seguente insieme di arrivo $B = \{1,2,3\}$, detto \textbf{codominio}.
    
    Consideriamo le seguenti quattro mappature:
    \[\begin{split}
        a &\mapsto 1 \\
        b &\mapsto 2 \\
        c &\mapsto 3
    \end{split}
    \qquad\qquad\qquad
    \begin{split}
        a &\mapsto 1 \\
        b &\mapsto 2 \\
        c &\mapsto 2
    \end{split}
    \qquad\qquad\qquad
    \begin{split}
        a &\mapsto 2 \\
        a &\mapsto 1 \\
        b &\mapsto 1 \\
        c &\mapsto 2
    \end{split}
    \qquad\qquad\qquad
    \begin{split}
        a &\mapsto 1 \\
        b &\mapsto 2 \\
    \end{split}\]

    Notiamo che solo le prime due risultino essere delle funzioni valide poiché nella terza mappatura l'elemento $a$ è associato a due elementi del codominio, mentre nella quarta mappatura l'elemento $c$ non è associato ad alcun elemento del codominio.

    Una funzione viene solitamente descritta tramite una \textit{regola generale} che ne descriva il comportamento, ma ogni associazione può anche essere imposta a priori (anche un'imposizione è pur sempre una "regola"). 
    
    Per descrivere tale regola viene spesso utilizzata la seguente \textbf{segnatura}:
    \[f : A \to B : a \mapsto f(x)\]

    che si legge come "$f$ è una funzione dall'insieme $A$ all'insieme $B$ che mappa un elemento $a$ all'elemento $f(a)$. Ad esempio, consideriamo la seguente funzione:
    \[\funcmap{f}{\N}{\N}{n}{2n}\]

    Risulta intuitivo che dato in \textit{input} un elemento $n \in \N$ tale funzione restituisca l'elemento $2n \in \N$. Formalmente, una funzione è definita come un \textbf{insieme di coppie} che rispetta la legge associata alla funzione stessa. 

    \begin{frameddefn}{Funzione}
        Dato un insieme $A$ detto \textbf{dominio} e un insieme $B$ detto \textbf{codominio}, una \textbf{funzione} $f : A \to B : a \mapsto f(x)$ è un insieme di coppie dove per ogni elemento del dominio esiste un unico elemento del codominio con cui è associato. In altre parole, abbiamo che:
        \[f := \{(a,b) \in A \times B \mid \forall a \in A \; \exists! b \in B \text{ tale che } f(a) = b\}\]
        dove $f(a) = b$ indica che $(a,b) \in f$.
    \end{frameddefn}

    In questo corso, tratteremo principalmente le cosiddette \textit{funzioni ad una variabile reale}, ossia funzioni che vanno da un sottoinsieme $S \subseteq \R$ in $\R$ stesso.

    \begin{frameddefn}{Funzione ad una variabile reale}
        Una \textbf{funzione ad una variabile reale} è una funzione il cui dominio è un sottoinsieme di $\R$ e il suo codominio è $\R$ stesso.
        \[\funcmap{f}{S \subseteq \R}{\R}{x}{f(x)}\]
    \end{frameddefn}

    Tutti i principali operatori che abbiamo discusso fino ad ora sono interpretabili come funzioni ad una variabile reale. Ad esempio, la funzione che eleva un numero al quadrato è definita come:
    \[\funcmap{f}{\R}{\R}{x}{x^2}\]
    
    Funzioni ad una variabile reale più complesse possono essere ottenute tramite il concetto di \textbf{composizione tra funzioni}. 

    \begin{frameddefn}{Composizione tra funzioni}
        Date due funzioni $f : A \to B : x \mapsto f(x)$ e $g: C \to D : x \mapsto g(x)$, la \textbf{composizione} tra $g$ e $f$ corrisponde alla funzione 
        \[g \circ f : A \to D : x \mapsto g(f(x))\]

        \textit{Nota 1}: non è detto che $g \circ f = f \circ g$.
        
        \textit{Nota 2}: affinché la composizione sia possibile, è necessario che $B \subseteq C$.
    \end{frameddefn}

    Ad esempio, consideriamo le funzioni $f : \N \to \N : x \mapsto 2x$ e $g : \R \to \R : x \mapsto x^2$. La composizione tra $g$ e $f$ corrisponde a:
    \[g \circ f : \N \to \R : x \mapsto (2x)^2\]

    mentre la composizione tra $f$ e $g$ non può esistere poiché $\R \not\subseteq \N$. Ad esempio, notiamo che $g\rbk{\frac{1}{2}} = \frac{1}{4}$, il quale ovviamente non è un numero naturale e per tanto non possiamo applicare $f$ su di esso.

    Tuttavia, estendendo il dominio e il codominio di $f$ anche tale composizione risulterebbe ben definita. Ad esempio, definendo:
    \[h : \R \to \R : x \mapsto 2x\]
    
    otteniamo che la composizione tra $h$ e $g$ corrisponda a:
    \[h \circ g : \R \to \R : x \mapsto 2x^2\]

    \newpage

    \section{Dominio e immagine di una funzione reale}

    La definizione formale di funzione stipulata nella sezione precedente ci permette di stabilire anche il concetto di \textbf{uguaglianza tra funzioni}: due funzioni $f$ e $g$ sono dette uguali  se i loro insiemi delle coppie sono uguali.

    Sebben possa sembrare una definizione banale e scontata, essa implica alcune distinzioni fondamentali. Ad esempio, per definizione stessa di funzione sappiamo che non sia necessario che ogni elemento del codominio sia raggiungibile tramite un elemento del codominio. Per tanto, affinché due funzioni siano uguali \underline{non} è necessario che esse abbiano lo stesso codominio.

    Ad esempio, le funzioni $\funcmap{f}{\R}{\R}{x}{\sin x}$ e $\funcmap{g}{\R}{[-1,1]}{x}{\sin x}$ risultano in realtà essere la stessa identica funzione poiché il valore de seno è sempre compreso tra $-1$ e $1$. Tale insieme di valori assunti dalla funzione viene detto \textbf{immagine} della funzione.

    \begin{frameddefn}{Immagine di una funzione}
        Data una funzione $\funcmap{f}{A}{B}{a}{f(a)}$, definiamo l'\textbf{immagine} di $f$, indicata con $\mathrm{Im}(f)$, l'insieme dei valori assunti da $f$, ossia:
        \[\mathrm{Im}(f) := \{b \in B \mid \exists a \in A \text{ tale che } f(a) = b\}\]
    \end{frameddefn}

    Consideriamo ora invece le seguenti due funzioni $f(x) = \frac{4x^2}{2x}$ e $g(x) = 2x$, dove $x \in \N$. Tramite delle facili semplificazioni algebriche, possiamo facilmente notare che $\frac{4x^2}{2x} = 2x$. Tuttavia, tale uguaglianza risulta in realtà vera solo se $x \neq 0$.

    Difatti, se assumessimo che $\mathrm{Dom}(f)$, ossia il dominio di $f$, fosse uguale ad $\R$, la funzione risulterebbe \textbf{non ben definita}, poiché l'elemento $0$ non può essere associato ad alcun elemento del codominio. 
    Per tanto, dobbiamo \textbf{limitare} il dominio di $f$ escludendo il valore 0 da esso. Tuttavia, per la funzione $g$ tale problema non di verifica in quanto $g(0) = 0$ sia un'associazione possibile.

    In altre parole, abbiamo che:
    \[f : \N-\{0\} \to \N : x \mapsto \frac{4x^2}{2x}\]
    \[g : \N \to \N : x \mapsto 2x\]

    Poiché i domini sono diversi, risulta ovvio che tali funzioni siano diverse. Difatti, \textit{restringendo} il dominio di $g$ affinché coincida con quello di $f$ potremmo dire che tali funzioni siano in realtà uguali. In altre parole, data:
    \[h : \N-\{0\} \to \N : x \mapsto 2x\]
    abbiamo che $f = h$.

    Uno degli obiettivi principali per quanto riguarda le funzioni ad una variabile reale, risulta essere la ricerca del \textbf{campo di esistenza} della funzione, ossia il massimo sottoinsieme $S \subseteq \R$ per cui la funzione sia ben definita se $\mathrm{Dom}(f) = S$.

    Ad esempio, consideriamo la seguente funzione:
    \[f(x) = \frac{x^3+2x-1}{x^2-1}\]

    Sappiamo che in $\R$ la funzione non sia ben definita se il denominatore di tale frazione è uguale a 0. Per tanto, imponiamo sull'insieme $\R$ la seguente \textbf{condizione di esistenza}: $x^2-1 \neq 0$. Successivamente, cerchiamo quindi i valori di $\R$ che rendono \textit{falsa} tale condizione di esistenza, ossia quei valori di $\R$ tali che $x^2-1 = 0$. Poiché $x^2-1 = (x+1)(x-1)$, sappiamo che i valori che rendono nullo tale polinomio sono $\pm 1$. Per tanto, il campo di esistenza di $f$ corrisponde a $\R - \{-1, +1\}$.

    Per calcolare il campo di esistenza di una funzione più complessa, è sufficiente considerare le condizioni di esistenza delle singole sottofunzioni che la compongono. Ad esempio, consideriamo la seguente funzione:
    \[f(x) = \frac{\sqrt{2x+1}}{\log_2(3x)-1}\]

    Notiamo la presenza di tre condizioni di esistenza:
    \begin{itemize}
        \item Affinché $\sqrt{2x+1}$ sia ben definita, è necessario che $2x+1 \geq 0$
        \item Affinché $\frac{1}{\log_2(3x)-1}$ sia ben definita, è necessario che $\log_2(3x) -1 \neq 0$
        \item Affinché $\log_2(3x)$ sia ben definita, è necessario che $3x > 0$
    \end{itemize}

    Risolviamo quindi le tre disequazioni separatamente, per poi considerare l'intersezione delle tre condizioni. Per la prima abbiamo che:
    \[2x+1 \geq 0 \implies 2x \geq -1 \implies x \geq -\frac{1}{2}\]

    Per la seconda, invece, abbiamo che:
    \[\log_2(3x) -1 \neq 0 \implies \log_2(3x) \neq 1 \implies 2^{\log_2(3x)} \neq 2^1 \implies 3x \neq 2 \implies x \neq \frac{2}{3}\]

    Infine, per la terza abbiamo che:
    \[3x > 0 \implies x > 0\]

    Per quanto riguarda l'intersezione delle tre condizioni, notiamo che la terza includa già la prima, rendendo quest'ultima superflua. La seconda, invece, crea un piccolo buco nella terza. Per tanto, il campo di esistenza di $f(x)$ risulta essere $\{x \in \R \mid x > 0, x \neq \frac{2}{3}\}$.

    \begin{center}
        \includegraphics[scale=0.55]{images/func2.png}

        \textit{In rosso vengono riportati gli intervalli e i punti esclusi dal campo di esistenza, \\in verde viene riportata la funzione descritta dalle coppie $(x, f(x))$}
    \end{center}

    Per poter imporre le condizioni di esistenza su funzioni più complesse, dunque, è necessario conoscere quale sia il campo di esistenza e l'immagine delle \textbf{funzioni elementari}:
    \begin{itemize}
        \item La funzione $f(x) = \frac{1}{x}$ è ben definita se $f : \R-\{0\} \to \R^+$
        \begin{center}
            \includegraphics[scale=0.5]{images/func3.png}
        \end{center}

        \item La funzione $f(x) = x^a$ con $a \in \Z^+$ e $a$ pari è ben definita se $f : \R \to \R^+$
        \begin{center}
            \includegraphics[scale=0.55]{images/func6.png}
        \end{center}

        \item La funzione $f(x) = x^a$ con $a \in \Z^+$ e $a$ dispari è ben definita se $f : \R \to \R$
        \begin{center}
            \includegraphics[scale=0.5]{images/func8.png}
        \end{center}

        \item La funzione $f(x) = \sqrt[n]{x}$ con $n$ pari è ben definita se $f : \R^+ \to \R^+$
        \begin{center}
            \includegraphics[scale=0.55]{images/func7.png}
        \end{center}

        \item La funzione $f(x) = \sqrt[n]{x}$ con $n$ dispari è ben definita se $f : \R \to \R$
        \begin{center}
            \includegraphics[scale=0.55]{images/func9.png}
        \end{center}

        \newpage

        \item La funzione $f(x) = a^x$ con $0 < a \neq 1$ è ben definita se $f : \R \to \R^+-\{0\}$
        \begin{center}
            \includegraphics[scale=0.55]{images/func4.png}
        \end{center}


        \item La funzione $f(x) = \log_a(x)$ con $\alpha > 1$ è ben definita se $f : \R^-\{0\}+ \to \R$
        \begin{center}
            \includegraphics[scale=0.5]{images/func10.png}
        \end{center}

        \item La funzione $f(x) = \sin(x)$ è ben definita se $f : \R \to [-1,1]$
        \begin{center}
            \includegraphics[scale=0.425]{images/func13.png}
        \end{center}

        \item La funzione $f(x) = \cos(x)$ è ben definita se $f : \R^+ \to [-1,1]$
        \begin{center}
            \includegraphics[scale=0.425]{images/func12.png}
        \end{center}
    \end{itemize}

    \textit{Nota}: nell'elenco abbiamo assunto che il dominio sia il campo di esistenza e che il codominio sia l'immagine.

    \newpage

    \section{Caratteristiche di una funzione reale}

    Poiché le funzioni ad una variabile reale mandano un elemento da un sottoinsieme di $\R$ ad un elemento di $\R$ stesso, risulta intuitiva l'idea di graficare l'insieme delle coppie descritto dalla funzione stessa. Il grafico di una funzione ad una variabile reale riassume in modo chiaro ed immediato il comportamento di una funzione.
    
    Tuttavia, per poter rappresentare il grafico di una funzione è necessario studiarne le \textbf{caratteristiche} (o \textit{proprietà}). Le due caratteristiche più semplici che una funzione possa assumere sono le proprietà di \textit{inettività} e \textit{suriettività}.

    \begin{frameddefn}{Iniettività}
        Una funzione $f : A \to B$ è detta \textbf{iniettiva} quando due elementi hanno lo stessa immagine solo se sono stesso identico elemento.
        \[\forall x, x' \in A \;\;\; f(x) = f(x') \implies x = x'\] 
    \end{frameddefn}

    Prima di tutto, è opportuno notare che l'affermazione riportata in tale definizione sia equivalente a:
    \[\forall x, x' \in A \;\;\;  x \neq x' \implies f(x) \neq f(x')\]
    ossia che se una funzione è iniettiva allora presi due elementi distinti anche la loro immagine sarà distinta (spesso tale formulazione risulta più intuitiva per alcuni).

    Consideriamo ad esempio la funzione reale $f(x) = x^2$. Notiamo facilmente che tale funzione non sia iniettiva in quanto $f(1) = f(-1)$ ma $1 \neq -1$. Per quanto riguarda la funzione reale $g(x) = 2^x$, invece, notiamo che $\forall x,x' \in \R$ si abbia che $g(x) = g(x') \implies x = x'$, dunque tale funzione risulta iniettiva.

    Graficando una funzione possiamo facilmente vedere se essa sia iniettiva o no tramite quello che viene chiamato \textbf{test della linea orizzontale}: se nel grafico è possibile tracciare una linea orizzontale che interseca la funzione in due o più punti allora la funzione non è iniettiva. Ad esempio, dal grafico della funzione $f(x) = x^3+3x^2$ possiamo facilmente notare che essa non sia iniettiva:
    \begin{center}
        \includegraphics[scale=0.5]{images/iniett.png}
    \end{center}

    \begin{frameddefn}{Suriettività}
        Una funzione $f : A \to B$ è detta \textbf{suriettiva} quando ogni elemento del codominio è raggiungibile da almeno un elemento del dominio.
        \[\forall y \in B \;\; \exists x \in A \text{ tale che } f(x) = y\] 
    \end{frameddefn}

    Consideriamo ad esempio ancora la funzione reale $f(x) = x^2$. Notiamo facilmente che tale funzione non sia suriettiva in quanto il valore $-1$ non sia raggiungibile da nessun valore di $\R$. La funzione reale $h(x) = x$, invece, risulta chiaramente essere suriettiva poiché ogni valore del codominio è raggiungibile da se stesso.

    In particolare, notiamo che una funzione $f : A \to B$ sia suriettiva se e solo se $\mathrm{Im}(f) = B$. Tale risultato risulta ovvio poiché generalmente $\mathrm{Im}(f) \subseteq B$ è sempre vero per definizione stessa di immagine e se la funzione è suriettiva allora anche $B \subseteq \mathrm{Im}(f)$ sarà vero.
    Per tale motivo, nell'ambito delle funzioni reali spesso la proprietà di suriettività viene considerata come \textit{implicita}, poiché possiamo sempre restringere il codominio della funzione al minimo possibile, ossia finché non coinciderà con l'immagine stessa. Ad esempio, la funzione $f:\R \to \R : x \mapsto x^2$ non è suriettiva, ma la funzione $g : \R \to \R^+ : x \mapsto x^2$ lo è.
    
    Quando una funzione è sia iniettiva sia suriettiva, essa viene detta \textbf{biettiva}. Ad esempio, la funzione $f(x) = x$ è biettiva in quanto sia iniettiva che suriettiva. Le funzioni biettive godono della proprietà di poter essere \textit{invertite}, ossia esiste una funzione $f^{-1}(x)$, detta \textbf{funzione inversa}, tale che $f(f^{-1}(x)) = f^{-1}(f(x))$. La condizione di biettività risulta sufficiente e necessaria affinché esista una funzione inversa valida. Tuttavia, abbiamo osservato come nell'ambito delle funzioni reali il concetto di suriettività possa essere considerato implicito. Ciò implica quindi che una funzione reale sia considerabile invertibile \textbf{anche solo quando essa sia iniettiva}.

    Consideriamo ad esempio la funzione $f:\R \to \R : x \mapsto 2^x$, la quale sappiamo essere iniettiva ma non suriettiva. In quanto non è biettiva, essa non è invertibile. Tuttavia, restringendo il codominio di $f$ fino alla sua immagine la funzione diventerà automaticamente suriettiva. Dunque, la funzione $g:\R \to \R^+-\{0\} : x \mapsto 2^x$ risulta essere biettiva. Difatti, sappiamo che esiste la funzione inversa $g^{-1} : \R^+-\{0\} \to \R : x \mapsto \log_2(x)$ per cui abbiamo sia $g^{-1}(g(x)) = \log_2(2^x) = x$ sia $g(g^{-1}) = 2^{\log_2(x)} = x$.

    Avendo stabilito che nel caso delle funzioni reali sia sufficiente essere iniettiva al fine di essere invertibile, notiamo che alcune funzioni comunemente riferite come inverse in realtà lo siano solo sotto alcune \textbf{condizioni}: la funzione $f : \R \to \R^+ : x \mapsto x^2$ non è iniettiva, dunque non invertibile, nonostante essa abbia la ben nota funzione "inversa" $g(x) : \R^+ \mapsto \R : x \to \sqrt{x}$. Queste due funzioni vengono erroneamente denotate l'una come l'inversa dell'altra, nonostante non lo siano. Difatti, notiamo che $g(f(x)) = \sqrt{x^2} = x$ ma anche che $g(f(-x)) = \sqrt{(-x)^2} = x$, dunque non è sempre vero che applicando le due funzioni otteniamo il valore di partenza. Volendo essere corretti, dunque, potremmo dire che $g$ sia in realtà l'inversa della funzione $h : \R^+ \to \R^+ : x \mapsto x^2$.
    
    \newpage

    Le funzioni reali possono godere anche di caratteristiche inerenti a \textbf{simmetrie} tra il loro dominio e la loro immagine.

    \begin{frameddefn}{Parità}
        Una funzione $f : A \to B$ è detta \textbf{pari} se l'immagine di ogni elemento è uguale all'immagine del suo opposto, ossia se:
        \[\forall x \in A \;\;\; f(x) = f(-x)\]
    \end{frameddefn}

    L'esempio più banale di funzioni pari vista fino ad esso risulta essere la funzione $f(x) = x^2$ in quanto per ogni $x$ si abbia $x^2 = (-x)^2$. Quando vengono graficate, le funzioni pari assumono una \textbf{forma a specchio verticale}, dove tutti i punti presenti a sinistra dell'asse delle ordinate siano specchiati anche a destra.

    \begin{center}
        \includegraphics[scale=0.475]{images/func6.png}
    \end{center}

    \begin{frameddefn}{Disparità}
        Una funzione $f : A \to B$ è detta \textbf{dispari} se l'immagine di ogni elemento è uguale all'opposto dell'immagine del suo opposto, ossia se:
        \[\forall x \in A \;\;\; f(x) = -f(-x)\]
    \end{frameddefn}

    Un tipico esempio di funzione dispari risulta essere la funzione $f(x) = x^3$, in quanto per ogni $x$ si abbia che $x^3 = -(-x)^3$. Quando vengono graficate, le funzioni pari assumono una \textbf{forma a specchio diagonale}, dove tutti i punti presenti al di sotto della retta $g(x) = -x$ siano specchiati al di sopra della retta stessa.

    \begin{center}
        \includegraphics[scale=0.425]{images/func11.png}
    \end{center}

    \begin{frameddefn}{Periodicità}
        Una funzione $f : A \to B$ è detta \textbf{periodica} se esiste una costante $c$ detta \textit{periodo} per cui la funzione ripete le sue immagini incrementando di $c$ il valore in input
        \[\forall x \in A \;\;\; f(x) = f(x+c)\]
    \end{frameddefn}

    Esempio tipico di funzioni periodiche risultano essere le funzioni $f(x) = \sin x$ e $g(x) = \cos x$, entrambe aventi periodo pari $2\pi$. Difatti, abbiamo già accennato come:
    \[\sin x = \sin(x+2\pi) \qquad\qquad \cos x = \cos(x+2\pi)\]

    Quando vengono graficate, le funzioni periodiche assumono una forma ad onda (la quale può essere anche "spigolosa" o "seghettata").

    \begin{center}
        \includegraphics[scale=0.425]{images/func12.png}
    \end{center}

    Infine, siamo interessati a sapere come i valori assunti da una funzione si comportino in uno specifico intervallo. Ad esempio, per la funzione seno riportata al di sopra notiamo che la funzione assuma prima valori che crescono al crescere dell'input per poi assumere valori che decrescono al crescere dell'input, ripetendo il tutto ad intervalli regolari in quanto periodica.

    \begin{frameddefn}{Monotonia}
        Data una funzione $f: A \to B$ ed un intervallo $I \subseteq A$, diciamo che $f$ è \textbf{monotona crescente} in $I$ se si verifica che:
        \[\forall x_1, x_2 \in I \text{ con } x_1 < x_2 \text{ si ha che } f(x_1) \leq f(x_2)\]

        Similmente, diciamo che $f$ è \textbf{monotona decrescente} in $I$ se si verifica che:
        \[\forall x_1, x_2 \in I \text{ con } x_1 < x_2 \text{ si ha che } f(x_1) \geq f(x_2)\]
    \end{frameddefn}

    Quando nell'intervallo $I$ con $x_1 < x_2$ la diseguaglianza $f(x_1) \leq f(x_2)$ non si verifica mai all'uguaglianza, ossia abbiamo sempre che $f(x_1) < f(x_2)$, la funzione $f$ viene detta \textbf{strettamente monotona crescente} in $I$. Analogamente, quando $f(x_1) \geq f(x_2)$ non si verifica mai all'uguaglianza diciamo che $f$ sia \textbf{strettamente monotona decrescente} in $I$. Inoltre, quando l'intervallo di crescenza (o decrescenza, stretta o non) coincide con l'intero dominio della funzione, allora essa viene detta \textbf{globalmente} monotona crescente (o decrescente, stretta o no).

    \newpage

    In generale, trovare studiare gli intervalli di crescenza di una funzione risulta un lavoro tedioso. Ad esempio, consideriamo la funzione $f(x) = x^3 + 3x^2$. Provando con degli input casuali, notiamo che $f(1) = (1)^3+3(1)^2 = 4$
    e che $f(-1) = (-1)^3+3(-1)^2 = 2$, dunque dati $-1 \leq 1$ otteniamo che $f(-1) \leq f(1)$. Potremmo quindi supporre che nell'intervallo $[-1,1]$ la funzione sia crescente. Tuttavia, provando altri valori ciò non risulta essere vero in quanto, ad esempio, $f(0) = (0)^3+3(0)^2 = 0$, dunque nonostante $-1 \leq 0 \leq 1$ abbiamo che $f(-1) \geq f(0) \leq f(1)$.

    Difatti, graficando la funzione notiamo facilmente che:
    \begin{center}
        \includegraphics[scale=0.6]{images/ex2.png}
    \end{center}
    ossia che la funzione sia strettamente crescente negli intervalli $(-\infty, -2]$ e $[0, +\infty)$ ma anche strettamente decrescente nell'intervallo $[-2, 0]$. Per ora, dunque, rimanderemo lo studio della crescenza e decrescenza di una funzione ad un punto successivo del corso, in quanto verranno forniti strumenti che possano permetterci di effettuare tali studi in modo semplice.
 
    \newpage

    \section{Segno di una funzione reale}

    Durante il nostro perseguire l'obiettivo di riuscire a descrivere tutte le proprietà assunte da una funzione con il fine di poterne abbozzare un grafico, abbiamo visto come trovare il campo di esistenza e le caratteristiche principali di una funzione. Procediamo ora con lo studiare il \textbf{segno di una funzione reale}, ossia determinare quali siano gli intervalli $I \subseteq \R$ per cui dato $x \in I$ si abbia che $f(x) > 0 , f(x) = 0$ oppure $f(x) < 0$.

    Per studiare il segno di una funzione, è sufficiente svolgere i seguenti due passaggi:
    \begin{enumerate}
        \item Individuare il campo di esistenza della funzione
        \item Individuare quali siano i valori di $x$ per cui si abbia $f(x) \geq 0$
        \item Trovare l'intersezione tra i valori individuati al punto precedente e il campo di esistenza della funzione
    \end{enumerate}

    Consideriamo ad esempio la seguente funzione:
    \[f(x) = \frac{x^2-1}{2^x-1}\]

    La frazione ci impone la condizione di esistenza $2^x-1 \neq 0$, implicando che:
    \[2^x-1 \neq 0 \implies 2^x \neq 1 \implies \log_2(2^x) \neq \log_2(1) \implies x \neq 0\]
    dunque il campo di esistenza della funzione risulta essere $\R-\{0\}$.

    A questo punto, dobbiamo risolvere la seguente disequazione:
    \[\frac{x^2-1}{2^x-1} \geq 0\]

    Come discusso nella sezione sulle diseguaglianze, tale diseguaglianza risulta vera quando il numeratore e il denominatore sono entrambi non-negativi o entrambi negativi (ricordiamo che una frazione $\frac{a}{b}$ non è altro che il prodotto $a \cdot \frac{1}{b}$).

    Studiamo quindi il segno delle due sottofunzioni:
    \begin{itemize}
        \item Per $x^2-1 \geq 0$ abbiamo che:
        \[x^2-1 \geq 0 \implies (x-1)(x+1) \geq 0 \implies x \leq -1 \lor 1 \leq x\]
        \item Per $2^x-1 \geq 0$ abbiamo che:
        \[2^x-1 \geq 0 \implies 2^x \geq 1 \implies  \log_2(2^x) \geq \log_2(1) \implies x \geq 0\]
    \end{itemize}

    \newpage

    Tramite il grafico del segno troviamo quindi l'intersezione tra i due risultati ottenuti e il campo di esistenza:
    \begin{center}
        \includegraphics[scale=0.55]{images/ex3.png}

        \textit{In rosso vengono riportati gli intervalli e i punti esclusi dal campo di esistenza}
    \end{center}

    Dunque, concludiamo che $f(x) \geq 0$ sia vero se $-1 \leq x < 0 \,\lor\, x \geq 1$. Una volta calcolatone il segno, possiamo individuare le zone del grafico che saranno occupate dalla funzione:

    \begin{center}
        \includegraphics[scale=0.55]{images/ex4.png}

        \textit{In rosso vengono riportati gli intervalli e i punti esclusi dal campo di esistenza,\\in nero le zone escluse tramite lo studio del segno}
    \end{center}

    \quad

    Difatti, graficando la funzione notiamo che essa passi solo per le zone non escluse:

    \begin{center}
        \includegraphics[scale=0.55]{images/ex5.png}
    \end{center}

    \newpage

    Vediamo quindi un altro esempio. Consideriamo la seguente funzione:
    \[f(x) = \ln(-x^2+5)\]

    Il logaritmo ci impone la condizione di esistenza $-x^2+5 > 0$, implicando che:
    \[-x^2 +5 > 0 \implies x^2 - 5 < 0 \implies (x-\sqrt{5})(x+\sqrt{5}) < 0 \implies -\sqrt{5} < x < \sqrt{5}\]
    dunque il campo di esistenza della funzione risulta essere $\{x \in \R \mid -\sqrt{5} < x < \sqrt{5}\}$. Studiamo quindi il segno della funzione:
    \[\ln(-x^2+5) \geq 0 \implies e^{\ln(-x^2+5)} \geq e^{0} \implies -x^2+5 \geq 1 \]
    \[\implies x^2-4 \leq 0 \implies (x-2)(x+2) \leq 0 \implies -2 \leq x \leq 2\]

    Tramite il grafico del segno troviamo quindi l'intersezione tra il risultato ottenuto e il campo di esistenza:
    \begin{center}
        \includegraphics[scale=0.55]{images/ex6.png}
    \end{center}

    \quad

    Notiamo quindi che il campo di esistenza non influenza il segno in alcun modo, concludendo che $f(x) \geq 0$ sia vero se $-2 \leq x \leq 2$. Una volta calcolatone il segno, possiamo individuare le zone del grafico che saranno occupate dalla funzione:

    \quad

    \begin{center}
        \includegraphics[scale=0.55]{images/ex7.png}
    \end{center}
    

    \newpage

    \section{Esercizi svolti}

    \begin{framedprob}{}
        Trovare il campo di esistenza delle seguenti funzioni in $\R$:
        \begin{enumerate}
            \item $f(x) = \frac{2x-1}{\abs{3x-1}}$
            \item $f(x) = \frac{4x}{\sin x - 1}$
            \item $f(x) = \frac{4x}{\log_2(3x) + 1}$
            \item $f(x) = \ln(x^2+1)$
            \item $f(x) = \sqrt[2]{3 x^3 - 4 x^2 - 5 x + 2}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}

    \begin{enumerate}
        \item Per via della frazione abbiamo la condizione di esistenza $\abs{3x-1} \neq 0$, la quale va sviluppata in due casi trattandosi del valore assoluto:
        \begin{enumerate}
            \item Se $3x-1 \geq 0$ allora:
            \[\abs{3x-1} \neq 0 \implies 3x-1 \neq 0 \implies x \neq \frac{1}{3}\]
            \item Se $3x-1 < 0$ allora:
            \[\abs{3x-1} \neq 0 \implies -3x+1 \neq 0 \implies x \neq \frac{1}{3}\]
        \end{enumerate}

        Per tanto, il campo di esistenza corrisponde a $\R - \cbk{\frac{1}{3}}$

        \item Per via della frazione abbiamo la condizione di esistenza $\sin x -1 \neq 0$, la quale implica che:
        \[\sin x -1 \neq 0 \implies \sin x \neq 1 \implies x \neq k\pi \;\; \forall k \in \Z\]
        Per tanto, il campo di esistenza corrisponde a $\R - \{x \in \R \mid x \neq k\pi, k \in \Z\}$

        \item Per via della frazione abbiamo le condizioni di esistenza $\log_2(3x) +1 \neq 0$, mentre per via del logaritmo abbiamo la condizione di esistenza $3x > 0$. La prima implica che:
        \[\log_2(3x) +1 \neq 0 \implies \log_2(3x) \neq -1 \implies 2^{\log_2(3x)} \neq 2^{-1} \implies 3x \neq \frac{1}{2} \implies x \neq \frac{1}{6}\]
        mentre la seconda implica che:
        \[3x > 0 \implies x > 0\]
        Per tanto, il campo di esistenza corrisponde a $\{x \in \R \mid x > 0, x \neq \frac{1}{6}\}$

        \item Per via del logaritmo abbiamo la condizione di esistenza condizione di esistenza $x^2+1 \geq 0$. Poiché per qualsiasi numero naturale $x \in \R$ si ha che $x^2 \geq 0$, ne segue che $x^2+1 \geq 1 > 0$. Dunque, la condizione di esistenza è verificata per ogni valore di $\R$, concludendo che il campo di esistenza sia $\R$ stesso.
        
        \item Abbiamo la condizione di esistenza $3 x^3 - 4 x^2 - 5 x + 2 \geq 0$. Procediamo quindi cercando le radici del polinomio, notando che $3(-1)^3-4(-1)^2-5(-1)+2 = 0$ e dunque che $-1$ sia una radice. Tramite Ruffini, otteniamo che:
        
        \begin{center}
            \begin{tabular}{c | c c c | c}
                 & $3$ & $-4$ & $-5$ & $2$ \\
            $-1$ &       & $-3$ & $7$ & $-2$ \\
            \hline
                & $3$ & $-7$ & $2$ &  $0$ \\
            \end{tabular}
        \end{center}

        dunque $3 x^3 - 4 x^2 - 5 x + 2 \geq 0 \implies (x+1)(3x^2-7x+2) \geq 0$. Cerchiamo quindi le altre due radici tramite la formula quadratica:
        \[x_{1,2} = \frac{7 \pm \sqrt{49-25}}{6} = \frac{7 \pm 5}{6}\]
        ottenendo che $\frac{1}{3}$ e $2$ siano le altre due radici e dunque che:
        \[3 x^3 - 4 x^2 - 5 x + 2 \geq 0 \implies 3(x+1)(x-2)\rbk{x-\frac{1}{3}}\geq 0\]

        Tramite il grafico del segno possiamo facilmente notare che:
        \begin{center}
            \includegraphics[scale=0.5]{images/ex_1.png}
        \end{center}
        ossia che:
        \[3 x^3 - 4 x^2 - 5 x + 2 \geq 0 \implies -1 \leq x \leq \frac{1}{3} \lor x \geq 2\]

        Per tanto, il campo di esistenza corrisponde a $\{x \in \R \mid -1 \leq x \leq \frac{1}{3} \lor x \geq 2\}$

    \end{enumerate}

    \newpage

    \begin{framedprob}{}
        Determinare se le simmetrie delle seguenti funzioni:
        \begin{enumerate}
            \item $f(x) = x^5+3x^2-x+3$
            \item $f(x) = \cos(3x)-\sin^2 x$
            \item $f(x) = \abs{\frac{x^2-4}{x-2}}$
            \item $f(x) = \frac{\sqrt{x^3}}{\sin x}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzioni:}
    \begin{enumerate}
        \item Notiamo che:
        \[f(-x) = (-x)^5+3(-x)^2-(-x)+3 = -x^5+3x^2+x+3\]
        da cui risulta evidente che $f(x) \neq f(-x)$ e che $f(x) \neq -f(-x)$, dunque la funzione non è né pari né dispari.

        \item Ricordando che:
        \[\cos(\alpha + 2k\pi) = \cos(-\alpha + 2k\pi) \qquad\qquad \sin(\alpha + 2k\pi) = - \sin(-\alpha + 2k\pi)\]
        notiamo che:
        \[f(-x) =  \cos(3(-x)) - \sin^2 (-x) = \cos(3x) - (-\sin(x))^2 = \cos(3x) - - \sin^2 x\]
        da cui risulta evidente che $f(x) = f(-x)$ dunque la funzione è pari.

        \item Per via della frazione abbiamo la condizione di esistenza $\abs{x-2} \neq 0$, la quale implica che:
        \[\abs{x-2} \neq 0 \implies \soe{rl}{
            x -2 \neq 0 & \text{se } x -2 \geq 0 \\
            -x+2 \neq 0 & \text{se } x -2 < 0
        }\]

        Entrambe le condizioni ci portano ad escludere il valore $x = -2$ dal campo di esistenza, il quale risulta quindi essere $\R-\{-2\}$. Poiché $f(2)$ risulta definito ma $f(-2)$ no, concludiamo automaticamente che $f$ non sia né pari né dispari.

        \item Come per la funzione precedente, per via della frazione abbiamo la condizione di esistenza $\sin x \neq 0$, la quale risulta verificata quando $x \neq k\pi$ per ogni $k \in \Z$. Per tanto, il campo di esistenza della funzione risulta essere $\R - \{k\pi \mid k \in \Z\}$. Notiamo quindi che  $f(k\pi)$ e $f(-k\pi)$ risultino entrambi indefiniti per ogni $k \in \Z$, dunque non possiamo concludere nulla sulla simmetria di $f$.
        
        Analizziamo quindi il suo comportamento:
        \[f(-x) = \frac{\sqrt{(-x)^3}}{\sin(-x)} = \frac{-x^3}{-\sin x} = \frac{x^3}{\sin x}\]
        concludendo che $f(x) = f(-x)$ e dunque che la funzione sia pari.
    \end{enumerate}

    \begin{framedprob}{}
        Determinare il segno delle seguenti funzioni e abbozzarne il grafico:
        \begin{enumerate}
            \item $f(x) = \rbk{\frac{x-2}{x-1}}^e$
            \item $f(x) = \sqrt{\ln(x^2-2)}$
            \item $f(x) = \frac{4^x-2}{5^{2x}-1}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}
    \begin{enumerate}
        \item La frazione impone la condizione di esistenza $x-1 \neq 0$, dunque:
        \[x-1 \neq 0 \implies x \neq 1\]
        mentre l'esponenziale impone che $0 < \frac{x-2}{x-1} \neq 1$, dunque:
        \[\frac{x-2}{x-1} \neq 1 \implies x-2 \neq x-1 \implies -1 \neq 0 \]
        che risulta sempre vero e inoltre:
        \begin{itemize}
            \item $x-2 > 0$ e $x-1 > 0$ quando $x > 2$ e $x > 1$, dunque quando $x > 2$
            \item $x-2 < 0$ e $x-1 < 0$ quando $x < 2$ e $x < 1$, dunque quando $x < 1$
        \end{itemize}
        dunque:
        \[\frac{x-2}{x-1} > 0 \implies x < 1 \lor 2 < x\]
        
        Unendo le tre condizioni trovate, il campo di esistenza risulta essere $\{x \in \R \mid  x < 1 \lor 2 < x\}$. Per quanto riguarda il segno della funzione, sappiamo che l'esponenziale sia maggiore di 0, dunque per l'intero campo di esistenza la funzione risulta positiva. Quindi, concludiamo che $f(x) \geq 0$ quando $x < 1 \lor 2 < x$.

        Abbozzando il grafico della funzione, abbiamo che:
        \begin{center}
            \includegraphics[scale=0.5]{images/ex9.png}
        \end{center}

        \newpage

        \item La radice impone la condizione di esistenza $\ln(x^2-2) \geq 0$, dunque:
        \[\ln(x^2-2) \geq 0 \implies e^{\ln(x^2-2)} \geq e^0 \implies x^2-2 \geq 1 \implies x^2-3 \geq 0\]
        \[\implies (x-\sqrt{3})(x+\sqrt{3}) \geq 0 \implies x \leq -\sqrt{3} \lor \sqrt{3} \leq x \]

        mentre il logaritmo impone la condizione di esistenza $x^2-2 > 0$, dunque:
        \[x^2-2 > 0 \implies (x-\sqrt{2})(x+\sqrt{2}) > 0 \implies x < -\sqrt{2} \lor \sqrt{2} < x\]

        Notiamo quindi che:
        \[x \leq -\sqrt{3} < \sqrt{2}  \qquad\qquad \sqrt{2} < \sqrt{3} \leq x\]
        dunque la prima condizione di esistenza vince sulla seconda, concludendo che il campo di esistenza sia $\{x \in \R \mid x \leq -\sqrt{3} \lor \sqrt{3} \leq x\}$.

        Per quanto riguarda il segno della funzione, abbiamo che:
        \[\sqrt{\ln(x^2-2)} \geq 0 \implies (\sqrt{\ln(x^2-2)})^2 \geq 0^2 \implies \ln(x^2-2) \geq 0 \]
        \[\implies x \leq -\sqrt{3} \lor \sqrt{3} \leq x\]
        dunque la funzione risulta positiva per l'intero campo di esistenza. Quindi, concludiamo che $f(x) \geq 0$ quando $x \leq -\sqrt{3} \lor \sqrt{3} \leq x$.

        Abbozzando il grafico della funzione, abbiamo che:
        \begin{center}
            \includegraphics[scale=0.5]{images/ex10.png}
        \end{center}

        \item La frazione impone la condizione di esistenza $5^{2x}-1 \neq 0$, dunque:
        \[5^{2x}-1 \neq 0 \implies 5^{2x} \neq 1 \implies 2x \neq 0 \implies x \neq 0\]
        dunque il campo di esistenza risulta essere $\R-\{0\}$.

        Per quanto riguarda il segno, abbiamo che:
        \[4^x-2 \geq 0 \implies 4^x \geq 2 \implies x \geq \frac{1}{2}\]
        e che:
        \[5^{2x}-1 \geq 0 \implies 5^{2x} \geq 1 \implies 2x \geq 0 \implies x \geq 0\]

        \newpage

        Dal grafico del segno notiamo che:
        \begin{center}
            \includegraphics[scale=0.5]{images/ex11.png}
        \end{center}

        Quindi, concludiamo che $f(x) \geq 0$ quando $x < 0 \lor \frac{1}{2} \leq x$. Abbozzando il grafico della funzione, abbiamo che:
        \begin{center}
            \includegraphics[scale=0.5]{images/ex12.png}
        \end{center}

    \end{enumerate}

    \chapter{Limiti di funzioni}

    \section{Intorni e punti di accumulazione}

    \begin{frameddefn}{Intorno chiuso e aperto}
        Dato un punto $x_0 \in \R$ e un valore $\varepsilon \in \R$ tale che $\varepsilon > 0$, definiamo l'\textbf{intorno chiuso in $x$ di raggio $\varepsilon$}, indicato con $I_\varepsilon[x_0]$, come l'intervallo chiuso che va da $x_0 - \varepsilon$ a $x_0+\varepsilon$.
        \[I_\varepsilon[x_0] := [x_0-\varepsilon, x_0+\varepsilon]\]

        Analogamente, definiamo l'\textbf{intorno aperto in $x$ di raggio $\varepsilon$}, indicato con $I_\varepsilon(x_0)$, come l'intervallo aperto che va da $x_0 - \varepsilon$ a $x_0+\varepsilon$.
        \[I_\varepsilon(x_0) := (x_0-\varepsilon, x_0+\varepsilon)\]
    \end{frameddefn}

    Graficamente il concetto di intorno corrisponde a:
    \begin{center}
        \includegraphics[scale=0.6]{images/intorno.png}
    \end{center}

    Notiamo quindi che l'intorno chiuso $I_\varepsilon[x_0]$ sia composto da tutti i valori che si trovano a \textbf{distanza} minore o uguale a $\varepsilon$. Analogamente, l'intorno aperto è composto da tutti i punti che si trovano a distanza strettamente minore di $\varepsilon$. In altre parole, abbiamo che:
    \[I_\varepsilon[x_0] = \{x \in \R \mid \mathrm{dist}(x_0, x) \leq \varepsilon\}\]
    e che:
    \[I_\varepsilon(x_0) = \{x \in \R \mid \mathrm{dist}(x_0, x) < \varepsilon\}\]

    In matematica, con \textit{distanza} si intende una qualsiasi funzione che goda delle seguenti quattro proprietà intuitive:
    \begin{enumerate}
        \item La distanza tra $x$ e $y$ è sempre non-negativa, ossia $\mathrm{dist}(x,y) \geq 0$
        \item La distanza tra $x$ e se stesso è nulla, ossia $\mathrm{dist}(x,x) = 0$
        \item La distanza tra $x$ e $y$ è uguale alla distanza tra $y$ e $x$, ossia
        \[\mathrm{dist}(x,y) = \mathrm{dist}(y,x)\]

        \item La distanza tra $x$ e $y$ è minore della somma tra la distanza da $x$ a $z$ e la distanza da $z$ a $y$ (anche detta \textit{disuguaglianza triangolare}), ossia
        \[\mathrm{dist}(x,y) \leq \mathrm{dist}(x,z) + \mathrm{dist}(z,y)\]
    \end{enumerate}

    Ovviamente, esistono diversi tipi di distanza. Ad esempio, in un piano bidimensionale, ad esempio $\R^2$ la \textit{distanza euclidea} tra due punti $A = (a,b)$ e $B = (c,d)$ è definita come:
    \[\mathrm{dist}_E(A,B) = \sqrt{(a-c)^2+(b-d)^2}\]

    mentre la \textit{distanza di Manhattan} è definita come:
    \[\mathrm{dist}_M(A,B) = \abs{a-c} + \abs{b-d}\]
 
    \begin{center}
        \includegraphics[scale=0.7]{images/dist.png}
    \end{center}

    Quando ci riduciamo ad un piano monodimensionale, ossia eliminando la seconda dimensione, la distanza euclidea e la distanza di Manhattan coincidono:
    \[\mathrm{dist}_E(x,y) = \sqrt{(x-y)^2} = \abs{x-y} = \mathrm{dist}_M(x,y)\]

    Nel caso degli intorni, ci troviamo proprio nel piano monodimensionale $\R$, dunque la distanza dal punto $x_0$ può essere descritta anche tramite il valore assoluto. In altre parole, abbiamo che:
    \[\begin{split}
        I_\varepsilon[x_0] &= [x_0-\varepsilon, x_0 + \varepsilon] \\
        &= \{x \in \R \mid \mathrm{dist}(x_0, x) \leq \varepsilon\} \\
        &= \{x \in \R \mid \abs{x_0-x} \leq \varepsilon\} \\
        &= \{x \in \R \mid x_0 - \varepsilon \leq x \leq x_0 + \varepsilon\} \\
    \end{split}\]
    e analogamente che:
    \[\begin{split}
        I_\varepsilon(x_0) &= (x_0-\varepsilon, x_0 + \varepsilon) \\
        &= \{x \in \R \mid \mathrm{dist}(x_0, x) < \varepsilon\} \\
        &= \{x \in \R \mid \abs{x_0-x} < \varepsilon\} \\
        &= \{x \in \R \mid x_0 - \varepsilon < x < x_0 + \varepsilon\} \\
    \end{split}\]

    Tramite il concetto di intorno possiamo stipulare una classificazione ben precisa dei valori che costituiscono un'intervallo.

    \begin{frameddefn}{Punti interni, esterni e di frontiera}
        Dato un intervallo $I \subseteq \R$, diciamo che un valore $x_0 \in I$ è un:
        \begin{itemize}
            \item \textbf{Punto interno} da $I$ se è possibile definire un intervallo aperto in $x_0$ che è contenuto all'interno di $I$, ossia 
            \[\exists \varepsilon >0 \text{ tale che } I_\varepsilon(x_0) \subseteq I\]
            
            \item \textbf{Punto esterno} ad $I$ se è possibile definire un intervallo aperto in $x_0$ che completamente al di fuori da $I$, ossia 
            \[\exists \varepsilon >0 \text{ tale che } I_\varepsilon(x_0) \subseteq \R-I\]

            \item \textbf{Punto di frontiera} di $I$ se in qualsiasi intorno di $x_0$ esistono due punti che cadono rispettivamente in $I$ e in $\R-I$, ossia
            \[\forall \varepsilon >0 \;\; \exists a,b \in I_\varepsilon(x_0) \text{ tali che } a \in I \text{ e } b \in \R-I\]
        \end{itemize}
    \end{frameddefn}

    Equivalentemente, possiamo affermare che un punto esterno ad $I$ sia un punto interno a $\R-I$ e che un punto di frontiera non sia né un punto interno né un punto esterno.

    \newpage

    Per comprendere meglio, consideriamo ad esempio l'intervallo semiaperto $[4,7)$. Intuitivamente, l'insieme dei punti interni a tale intervallo corrisponde al sottointervallo aperto $(4,7)$. L'insieme dei punti esterni, invece, corrisponde all'unione $(-\infty, 4) \cup (7, +\infty)$. Infine, l'insieme dei punti di frontiera corrisponde a $\{4,7\}$.

    \begin{center}
        \includegraphics[scale=0.6]{images/points.png}
    \end{center}

    \quad

    Vediamo ora un altro tipo di punti classificabili in un intervallo tramite il concetto di intorno.

    \begin{frameddefn}{Punto di accumulazione}
        Dato un intervallo $I \subseteq \R$, diciamo che un valore $x_0 \in I$ è un punto di accumulazione se in ogni intorno di $x_0$ cade un punto di $I$ diverso da $x_0$ stesso, ossia:
        \[\forall \varepsilon > 0 \;\; \exists x \in I-\{x_0\} \text{ tale che } x \in I_\varepsilon(x_0)\;\;\]
    \end{frameddefn}

    Per comprendere meglio il concetto, consideriamo ancora l'intervallo semiaperto $[4,7)$ e il valore $5 \in [4,7)$. Considerando un qualsiasi raggio $\varepsilon > 0$, l'intorno aperto $I_\varepsilon(5)$ conterrà sempre un punto oltre al valore $5$ stesso che sia contenuto in $[4,7)$, dunque $5$ risulta essere un punto di accumulazione per tale intervallo.
    
    L'origine del concetto di \textit{accumulazione} deriva proprio dal valore $\varepsilon$ che possiamo scegliere. Difatti, la definizione stessa implica che scegliendo un valore sempre più piccolo l'intorno del punto di accumulazione conterrà sempre un valore dell'intervallo diverso dal punto stesso. In altre parole, riducendo sempre di più il raggio dell'intorno, avremo comunque un punto valido che si avvicina sempre di più al punto di accumulazione.
    
    \begin{center}
        \includegraphics[scale=0.6]{images/accum.png}
    \end{center}

    Dalle definizioni stesse, risulta evidente che ogni punto interno sia anche un punto di accumulazione, mentre un punto esterno non lo è mai. Per quanto riguarda i punti di frontiera, generalmente essi sono dei punti di accumulazione, anche se esistono dei casi particolari in cui ciò non risulta vero.
    
    Ad esempio, consideriamo l'intervallo $I = [x_0,x_0]$, dunque $I = \{x_0\}$. Notiamo che il punto $x_0$ sia un punto di frontiera in quanto $\forall \varepsilon > 0$ si abbia che il punto $x_0$ stesso sia contenuto in $I_\varepsilon(x_0)$, mentre ogni altro punto di tale intorno è al di fuori di $I$. Tuttavia, non è possibile trovare un altro punto di $I$ che sia contenuto in $I_\varepsilon(x_0)$ in quanto $I$ contiene solo $x_0$, concludendo quindi che esso non sia un punto di accumulazione.

    \newpage

    \section{Definizione topologica di limite}

    Nella sezione precedente, abbiamo introdotto come il concetto di \textit{punto di accumulazione} sia estremamente collegato con il concetto di \textit{avvicinamento} verso un determinato punto di un intervallo. Partendo da tale premessa, vogliamo estendere il concetto di avvicinamento anche al concetto di funzione.
    
    Consideriamo il seguente grafico di una certa funzione reale $f(x)$.
    \begin{center}
        \includegraphics[scale=0.55]{images/lim1.png}
    \end{center}

    \quad

    Consideriamo quindi l'intervallo $[3,7]$ sull'asse delle ascisse. Ovviamente, il punto $5$ risulta essere interno a tale intervallo e dunque anche un suo punto di accumulazione. Per tanto, possiamo considerare dei punti dell'intervallo stesso che siano man a mano più vicini al punto $5$.

    \begin{center}
        \includegraphics[scale=0.55]{images/lim2.png}
    \end{center}

    Sia quindi $\ell$ il valore tale che $f(5) = \ell$ e consideriamo il valore assunto dalla funzione $f$ per ciascuno di tali punti man a mano più vicini a $5$. Notiamo facilmente che anche il valore assunto dai punti accumulati in 5 \textit{tendano} ad essere estremamente simili a $\ell$.

    \begin{center}
        \includegraphics[scale=0.575]{images/lim3.png}
    \end{center}

    \quad

    In altre parole, possiamo definire un intorno $I_\varepsilon(\ell)$ sull'asse delle ordinate di raggio man man più piccolo per cui esista un certo intorno $I_\delta(5)$ sull'asse delle ascisse tale che $\forall I_\delta(5)-\{5\}$ si abbia che $f(x) \in I_\varepsilon(\ell)$.
    
    Generalmente, avremmo quindi che:
    \[\forall \varepsilon > 0 \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } x \in I_\delta(x_0)-\{x_0\} \implies f(x) \in I_\varepsilon(\ell)\]
    o riscritto in termini pià comodi:
    \[\forall \varepsilon > 0 \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } 0 < \abs{x-x_0} < \delta \implies \abs{f(x)-\ell} < \varepsilon\]
    
    Quando si verifica ciò diciamo che per valori di $x$ vicino a $x_0$ la funzione \textit{tende} ad $\ell$.

    \begin{frameddefn}{Limite in $\ell$ per valori tendenti a $x_0$}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, diciamo che per valori di $x$ che \textit{tendono} a $x_0$ il \textbf{limite} della funzione $f(x)$ \textbf{converge} ad un certo valore $\ell$, se si verifica che:
        \[\forall \varepsilon > 0 \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } 0 < \abs{x-x_0} < \delta \implies \abs{f(x)-\ell} < \varepsilon\]    
            
        Per esprimere ciò utilizziamo una delle seguenti due notazioni:
        \[\lim_{x \to x_0} f(x) = \ell \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to x_0} \; \ell\]
    \end{frameddefn}

    \begin{framedobs}{}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, se per l'intervallo $I$ si ha che $f(x) \to \ell$ quando $x \to x_0$, allora ciò vale anche per ogni intervallo $J$ tale che $I \subseteq J \subseteq \R$.
    \end{framedobs}

    L'ultima osservazione ci permette di stabilire che non sia importante quale intervallo venga scelto, l'importante è che esista almeno un intervallo per cui il punto $x_0$ sia un punto di accumulazione scelto

    Consideriamo ad esempio la funzione $f(x) = x^2$ e il valore $x = 4$. Poiché nell'intervallo $[3,7]$ il valore $x = 4$ risulta essere un punto interno, esso è anche un suo punto di accumulazione. In particolare notiamo che l'intervallo $[3,7]$ è stato scelto casualmente, avremmo potuto scegliere anche $[3.99999, 4.00001]$, l'importante è che 4 sia un punto di accumulazione per qualche intervallo interno a $\R$. 
    
    Poiché $f(4) = 16$, intuitivamente ci viene da ipotizzare che per $x \to 4$ si abbia che $f(x) \to 16$. Verifichiamo quindi che la nostra ipotesi sia corretta. Per fare ciò dobbiamo trovare un valore $\delta > 0$ da associare ad ogni $\varepsilon > 0$ possibile che renda vera la definizione di limite. Per fare ciò risulta più comodo procedere a ritroso, ossia facendo delle assunzioni su $\delta$ che ci permettono di trovare il suo $\varepsilon$ associato.

    Consideriamo quindi un valore $\delta > 0$ tale
    \[0 < \abs{x-4} < \delta\]

    Successivamente, osserviamo come:
    \[\abs{x^2-16} = \abs{(x-4)(x+4)} = \abs{x-4} \abs{x+4} < \delta \abs{x+4}\]
    
    Poiché siamo interessati a conoscere il limite della funzione per valori sempre più vicini a $4$, possiamo supporre che il valore $\delta$ sia molto piccolo. Supponiamo quindi che $\delta < 1$, ottenendo che:
    \[\abs{x-4} < \delta < 1 \implies 4-1 < x < 4+1 \implies 3 < x < 5 \implies 7 < \abs{x+4} < 9\]

    Dunque, ciò ci fa concludere che se $\delta < 1$ allora:
    \[\abs{x-4} < \delta < 1 \implies \abs{x^2-16} < \delta \abs{x+4} < 9\delta\]

    Per ogni $\varepsilon \geq 9$, dunque, è sufficiente considerare un qualsiasi valore $\delta < 1$ affinché si abbia che:
    \[\abs{x+4} < \delta < 1 \implies \abs{x^2-16} < 9\delta < 9 \leq \varepsilon\]

    Consideriamo ora i valori $0 < \varepsilon < 9$. Ponendo $\delta = \frac{\varepsilon}{9}$, notiamo che $0 < \delta < 1$. Ma allora, tramite il risultato precedente abbiamo che:
    \[\delta = \frac{\varepsilon}{9} < 1 \implies \abs{x-4} < \delta < 1 \implies \abs{x+4} < 9\delta = \varepsilon\]

    Ricapitolando, per ogni $\varepsilon$ tale che $\varepsilon \geq 9$ possiamo scegliere un qualsiasi valore $\delta < 1$ affinché valga la condizione, mentre per ogni $\varepsilon$ tale che $0 < \varepsilon < 9$ possiamo porre $\delta = \frac{\varepsilon}{9}$ affinché la condizione sia soddisfatta, concludendo che:
    \[\lim_{x \to 4} x^2 = 16\]

    Tuttavia, è opportuno sottolineare come il concetto di limite esprime un \underline{avvicinarsi} ad un valore $\ell$ per valori di $x$ vicini al punto di accumulazione e \underline{non} che nel punto di accumulazione la funzione valga un determinato valore.

    Ad esempio, consideriamo la funzione $f(x) = \frac{x^2-1}{x+1}$. Da una veloce analisi del campo di esistenza, sappiamo che $f$ risulta definita solo per $\R - \{-1\}$. Tuttavia, calcolando $f(x)$ per valori negativi molto vicini a $-1$ notiamo come:
    \[f(-2.5) = -3.5 \qquad f(-1.5) = -2.5 \qquad f(-1.25) = -2.25 \qquad f(-1.125) = -2.125\]
    mentre per valori positivi molto vicini a $-1$ notiamo come:
    \[f(1) = 0 \qquad f(-0.5) = -1.5 \qquad f(-0.75) = -1.75 \qquad f(-0.875) = -1.875\] 

    Ipotizziamo quindi che per $x \to -1$ si abbia che $f(x) \to -2$. Consideriamo allora un valore $\delta > 0$ tale che:
    \[0 < \abs{x-(-1)} = \abs{x+1} < \delta\]

    Successivamente, poiché $\abs{x+1} \neq 0$, osserviamo come:
    \[\abs{\frac{x^2-1}{x+1} - (-2)} = \abs{\frac{x^2-1}{x+1} + 2} = \abs{\frac{x^2-1+2(x+1)}{x+1}} = \abs{\frac{x^2+2x+1}{x+1}}\]
    \[= \abs{\frac{(x+1)^2}{x+1}} = \frac{\abs{x+1}^2}{\abs{x+1}} = \abs{x+1} < \delta\]
    
    Di conseguenza, per ogni $\varepsilon > 0$ è sufficiente porre $\delta = \varepsilon$ affinché valga che:
    \[\abs{x+1} < \delta \implies \abs{\frac{x^2-1}{x+1} + 2} < \varepsilon\]
    
    Dunque poiché $\forall \varepsilon > 0$ possiamo trovare un $\delta > 0$ che soddisfi la condizione, concludiamo che:
    \[\lim_{x \to -1} \frac{x^2-1}{x+1} = -2\]

    nonostante sappiamo che $f(-1) = \mathrm{Indefinito}$.

    \begin{framedobs}{}
        Quando una funzione è indefinita in un punto di accumulazione $x_0$, il suo limite per $x \to x_0$ potrebbe comunque esistere.
    \end{framedobs}

    \newpage

    Non sempre siamo interessati a studiare solo tale tipologia di limite. In alcuni casi siamo interessati a studiare il \textit{limite sinistro} e il \textit{limite destro} di una funzione all'avvicinarsi in un punto di accumulazione. 

    Formalmente, dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, diciamo che er valori di $x$ che \textit{tendono da sinistra} a $x_0$ il \textbf{limite sinistro} della funzione $f(x)$ \textbf{converge} ad un certo valore $\ell$, se si verifica che:
    \[\forall \varepsilon > 0 \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } x_0-\delta < x < x_0 \implies \abs{f(x)-\ell} < \varepsilon\]

    ed utilizziamo una delle seguenti due notazioni:
    \[\lim_{x \to x_0^-} f(x) = \ell \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to x_0^-} \; \ell\]

    \begin{center}
        \includegraphics[scale=0.85]{images/lim_sx.png}
    \end{center}

    Analogamente, diciamo che per valori di $x$ che \textit{tendono da destra} a $x_0$ il \textbf{limite destro} della funzione $f(x)$ \textbf{converge} ad un certo valore $\ell$, se si verifica che:
    \[\forall \varepsilon > 0 \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } x_0 < x < x_0+\delta \implies \abs{f(x)-\ell} < \varepsilon\]

    ed utilizziamo una delle seguenti due notazioni:
    \[\lim_{x \to x_0^+} f(x) = \ell \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to x_0^+} \; \ell\]

    \begin{center}
        \includegraphics[scale=0.85]{images/lim_dx.png}
    \end{center}

    \newpage
    
    Per definizione stessa, risulta intuitivo che se il limite sinistro sia un valore $\ell$ e il limite destro sia lo stesso valore $\ell$ allora l'intero limite convergerà al valore $\ell$.
    
    \begin{framedobs}{}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, si verifica che:
        \[\lim_{x \to x_0^-} f(x) = \lim_{x \to x_0^+} f(x) = \ell \implies \lim_{x \to x_0} f(x) = \ell\]
    \end{framedobs}

    \begin{center}
        \includegraphics[scale=0.85]{images/lim_sx_dx.png}
    \end{center}

    Tuttavia, non tutti i limiti quando svolti da entrambi i lati convergono allo stesso valore. Ad esempio, possiamo considerare delle funzioni "artificiose" che tendano a due valori diversi a seconda della direzione considerata, come la seguente:
    \[f(x) = \soe{ll}{
        x^2+1 & \text{se } x \geq 0 \\
        x^2-1 & \text{se } x < 0 \\
    }\]

    \begin{center}
        \includegraphics[scale=0.6]{images/ex13.png}
    \end{center}

    Dal grafico, notiamo facilmente che:
    \[\lim_{x \to 0^-} f(x) = -1 \qquad \lim_{x \to 0^+} f(x) = 1\]
    
    Quando ciò si verifica, diciamo che il limite \textbf{non esiste}.

    \begin{framedobs}{}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, si verifica che:
        \[\lim_{x \to x_0^-} f(x) \neq \lim_{x \to x_0^+} f(x) \implies \lim_{x \to x_0} f(x) = \nexists\]
    \end{framedobs}

    In alcuni casi, inoltre, una delle due direzioni potrebbe \textbf{non essere è ben definita} poiché i valori da considerare sono al di fuori dal campo di esistenza. In tal caso, viene considerata solo la direzione ben definita. Ad esempio, per la funzione $f(x) = \ln x$ il limite sinistro per $x \to 0^-$ non è ben definito poiché il campo di esistenza di $f(x)$ è $\{x \in \R \mid x > 0\}$, dunque il calcolo del limite $x \to 0$ è equivalente al calcolo del limite $x \to 0^+$.
    \[\lim_{x \to 0} \ln x = \lim_{x \to 0^+} \ln x\]

    All'avvicinarsi verso un punto di accumulazione $x_0$, alcune funzioni potrebbero persino \textbf{non convergere} ad un limite $\ell$, bensì potrebbero \textbf{divergere}, ossia minore è la distanza tra $x$ e $x_0$ maggiore (o minore) sarà il valore di $f(x)$. In altre parole, per ogni intorno valore $M \in \R$ possiamo definire un intorno $I_\delta(x_0)$ per cui si abbia che $x \in I_\delta(x_0) \implies f(x) > M$ (o $f(x) < M$). 

    \begin{frameddefn}{Limite a $+\infty$ per valori tendenti a $x_0$}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, diciamo che per valori di $x$ che \textit{tendono} a $x_0$ il \textbf{limite} della funzione $f(x)$ \textbf{diverge positivamente} se si verifica che:
        \[\forall M \in \R \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } 0 < \abs{x-x_0} < \delta \implies f(x) > M\]

        Per esprimere ciò utilizziamo una delle seguenti due notazioni:
        \[\lim_{x \to x_0} f(x) = +\infty \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to x_0} \; +\infty\]
    \end{frameddefn}

    Analogamente, per la divergenza negativa di $f(x)$ la condizione da verificare risulta essere:
    \[\forall M \in \R \;\; \exists \delta > 0 \text{ tale che } \forall x \in I \text{ valga che } 0 < \abs{x-x_0} < \delta \implies f(x) < M\]

    ed utilizziamo una delle seguenti due notazioni:
    \[\lim_{x \to x_0} f(x) = -\infty \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to x_0} \; -\infty\]
    
    Consideriamo la funzione $f(x) = \dfrac{1}{x}$, la quale ha campo di esistenza $\R-\{0\}$. Analizziamo quindi il comportamento della funzione per valori vicini a $0$. Avvicinandoci da sinistra abbiamo che:
    \[f(-1) = -1 \qquad f(-0.1) = -10 \qquad f(-0.01) = -100 \qquad f(-0.001) = -1000\]

    mentre avvicinandoci da destra abbiamo che:
    \[f(1) = 1 \qquad f(0.1) = 10 \qquad f(0.01) = 100 \qquad f(0.001) = 1000\]

    Dai valori ottenuti, possiamo intuire che per $x \to 0^-$ si abbia che $\frac{1}{x} \to -\infty$ mentre per $x \to 0^+$ si abbia che $\frac{1}{x} \to +\infty$. Difatti, le nostre assunzioni risultano essere vere (omettiamo la dimostrazione) implicando quindi che il limite per $x \to 0$ non possa esistere poiché le due direzioni tendono a due limiti diversi. 
    \[\lim_{x \to 0^-} \frac{1}{x} = -\infty \quad \text{ e } \quad \lim_{x \to 0^+} \frac{1}{x} = +\infty \implies \lim_{x \to 0} \frac{1}{x} = \nexists\]

    Difatti, dal grafico notiamo che il nostro risultato sia abbastanza evidente:
    \begin{center}
        \includegraphics[scale=0.5]{images/func3.png}
    \end{center}

    A questo punto, introduciamo l'ultima categoria di limite. Finora abbiamo discusso di limiti per valori di $x$ tendenti ad un punto di accumulazione, notando che in alcuni casi il limite possa persino divergere.
    
    Ci chiediamo ora invece cosa succede se sia il valore $x$ a \textbf{divergere positivamente o negativamente}, ossia considerando valori di $x$ sempre più grandi o sempre più piccoli (in altre parole, allontanandoci a destra o sinistra dall'origine).

    \begin{frameddefn}{Limite in $\ell$ per valori tendenti a $+\infty$}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, diciamo che per valori di $x$ che \textit{divergono} a $+\infty$ il \textbf{limite} della funzione $f(x)$ \textbf{converge} ad un certo valore $\ell$ se si verifica che:
        \[\forall \varepsilon > 0 \;\; \exists N \in \R\text{ tale che } \forall x \in I \text{ valga che } x > N \implies \abs{f(x)-\ell} < \varepsilon\]

        Per esprimere ciò utilizziamo una delle seguenti due notazioni:
        \[\lim_{x \to +\infty} f(x) = \ell \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to +\infty} \; \ell\]
    \end{frameddefn}

    Analogamente, per la divergenza negativa di $x$ la condizione da verificare risulta essere:
    \[\forall \varepsilon > 0 \;\; \exists N \in \R \text{ tale che } \forall x \in I \text{ valga che } x < N \implies \abs{f(x)-\ell} < \varepsilon\]

    ed utilizziamo una delle seguenti due notazioni:
    \[\lim_{x \to -\infty} f(x) = \ell \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to -\infty} \; \ell\]
    
    Ad esempio, consideriamo ancora la funzione $f(x) = \dfrac{1}{x}$. Allontanandoci a sinistra dall'origine abbiamo che:
    \[f(-1) = -1 \qquad f(-10) = -0.1 \qquad f(-100) = -0.01 \qquad f(-1000) = -0.001\]
    mentre allontanandoci a destra dall'origine abbiamo che:
    \[f(1) = 1 \qquad f(10) = 0.1 \qquad f(100) = 0.01 \qquad f(1000) = 0.001\]

    Dai valori ottenuti, possiamo intuire che per $x \to -\infty$ si abbia che $\frac{1}{x} \to 0^-$ mentre per $x \to +\infty$ si abbia che $\frac{1}{x} \to 0^+$. Difatti, le nostre assunzioni risultano essere vere (omettiamo la dimostrazione), concludendo che:
    \[\lim_{x \to -\infty} \frac{1}{x} = 0 \quad \text{ e } \quad \lim_{x \to +\infty} = 0\]

    Infine, come c'è da aspettarsi, possono anche verificarsi casi in cui per valori di $x$ divergenti si abbia anche che il valore $f(x)$ diverga. Ad esempio, per la banale funzione $f(x) = x$ quando $x \to +\infty$ si verifica che $x \to -\infty$.

    \begin{frameddefn}{Limite a $+\infty$ per valori tendenti a $+\infty$}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, diciamo che per valori di $x$ che \textit{divergono} a $+\infty$ il \textbf{limite} della funzione $f(x)$ \textbf{diverge} a $+\infty$ se si verifica che:
        \[\forall M \in \R \;\; \exists N \in \R \text{ tale che } \forall x \in I \text{ valga che } x > N \implies f(x) > M\]

        Per esprimere ciò utilizziamo una delle seguenti due notazioni:
        \[\lim_{x \to +\infty} f(x) = +\infty \qquad\qquad\qquad f(x) \; \substack{\DOTSB\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\relbar\joinrel\rightarrow \\ x \to +\infty} \; +\infty\]
    \end{frameddefn}

    \textit{Nota:} le altre definizioni di limite a $\pm\infty$ per valori tendenti a $\pm \infty$ possono essere ricavate unendo le definizioni precedenti 

    \newpage

    Infine, enunciamo un teorema che, seppur banale, ci assicura che nel calcolo di limite possa esserci una sola risposta (se il limite esiste).

    \begin{framedthm}[label={unique_lim}]{Unicità del limite}
        Dato un intervallo $I \subseteq \R$, sia $f : I \to \R$. Dato un punto di accumulazione $x_0 \in I$, se si verifica che:
        \[\lim_{x \to *} f(x) = \ell \qquad\qquad \lim_{x \to *} f(x) = m\]

        allora si ha che $\ell = m$. In altre parole, se in $x_0$ la funzione tende a due limiti allora devono necessariamente essere lo stesso limite.
        
        Dove il simbolo $*$ può essere $x_0, x_0^+, x_0^-, +\infty$ o $-\infty$.
    \end{framedthm}

    \proofenv{
        Dimostriamo solo il caso in cui il simbolo $*$ equivale a $x_0$.

        Supponiamo per assurdo che:
        \[\lim_{x \to x_0} f(x) = \ell \qquad\qquad \lim_{x \to x_0} f(x) = m\]
        e che $\ell \neq m$. Senza perdita di generalità, inoltre, assumiamo che $\ell > m$ (per il caso $\ell < m$ procediamo analogamente invertendo il ruolo dei due valori).

        Notiamo quindi che $\frac{\ell-m}{2} > 0$ permettendoci di scegliere un valore $\varepsilon$ tale che $0 < \varepsilon < \frac{\ell-m}{2}$.
        
        Poiché i due limiti esistono, ne segue che esista un valore $\delta_1 > 0$ tale che:
        \[ 0 < \abs{x-x_0} < \delta_1 \implies \abs{f(x)-\ell} < \varepsilon\]

        e analogamente che esista un valore $\delta_2 > 0$ tale che:
        \[ 0 < \abs{x-x_0} < \delta_2 \implies \abs{f(x)-m} < \varepsilon\]

        Poniamo quindi $\delta = \min(\delta_1, \delta_2)$. In tal caso, $\forall \varepsilon > 0$ abbiamo che:
        \[ 0 < \abs{x-x_0} < \delta \leq \delta_1, \delta_2 \implies \soe{l}{
            \abs{f(x)-\ell} < \varepsilon \\
            \abs{f(x)-m} < \varepsilon \\
        } \implies \soe{l}{
            \ell - \varepsilon < f(x) < \ell + \varepsilon \\
            m - \varepsilon < f(x) < m + \varepsilon \\
        }\]

        Prendiamo quindi il lato sinistro della prima diseguaglianza e il lato destro della seconda diseguaglianza:
        \[\ell - \varepsilon < f(x) < m + \varepsilon \implies \ell - \varepsilon < m+ \varepsilon \implies \varepsilon > \frac{\ell-m}{2}\]
        il che risulta assurdo in quanto abbiamo scelto $0 < \varepsilon < \frac{\ell-m}{2}$. Di conseguenza, ne segue necessariamente che $\ell = m$.

    }

    \section{Algebra e proprietà dei limiti}

    Come mostrato nella sezione precedente, calcolare i limiti tramite la definizione topologica risulta estremamente ostico. In questa sezione, quindi, forniremo degli strumenti in grado di permetterci di calcolare i limiti di funzioni complesse senza dover far ricorso alla definizione topologica.

    Prima di tutto, elenchiamo i vari \textbf{limiti delle funzioni elementari}: 
    \begin{itemize}
        \item Per la funzione $f(x) = x^{\alpha}$ con $\alpha$ pari, abbiamo che:

        \[\lim_{x \to x_0 \neq 0} x^{\alpha} = (x_0)^\alpha
        \qquad\qquad
        \lim_{x \to 0^-} x^{\alpha} = +\infty 
        \qquad\qquad
        \lim_{x \to 0^+} x^{\alpha} = +\infty\]
        
        \[\lim_{x \to +\infty} x^{\alpha} = \soe{cl}{
            \infty & \text{se } \alpha > 0 \\
            1 & \text{se } \alpha = 0 \\
            0 & \text{se } \alpha < 0\\
        }
        \qquad\qquad
        \lim_{x \to +\infty} x^{\alpha} = \soe{cl}{
            \infty & \text{se } \alpha > 0 \\
            1 & \text{se } \alpha = 0 \\
            0 & \text{se } \alpha < 0\\
        }\]

        \item Per la funzione $f(x) = x^{\alpha}$, con $\alpha$ dispari, abbiamo che:
        
        \[\lim_{x \to x_0 \neq 0} x^{\alpha} = (x_0)^\alpha
        \qquad\qquad
        \lim_{x \to 0^-} x^{\alpha} = -\infty 
        \qquad\qquad
        \lim_{x \to 0^+} x^{\alpha} = +\infty\]
        
        \[\lim_{x \to +\infty} x^{\alpha} = \soe{cl}{
            \infty & \text{se } \alpha > 0 \\
            0 & \text{se } \alpha < 0\\
        }
        \qquad\qquad
        \lim_{x \to +\infty} x^{\alpha} = \soe{cl}{
            \infty & \text{se } \alpha > 0 \\
            0 & \text{se } \alpha < 0\\
        }\]


        \item Per la funzione $f(x) = \alpha^x$, con $\alpha > 0$, abbiamo che:
        
        \[\lim_{x \to x_0} \alpha^x = \alpha^{x_0}\]
        
        \[\lim_{x \to +\infty} \alpha^x = \soe{cl}{
            \infty & \text{se } \alpha > 1 \\
            1 & \text{se } \alpha = 1 \\
            0 & \text{se } 0 < \alpha < 1\\
        }
        \qquad\qquad
        \lim_{x \to -\infty} \alpha^x = \soe{cl}{
            0 & \text{se } \alpha > 1 \\
            1 & \text{se } \alpha = 1 \\
            +\infty & \text{se } 0 < \alpha < 1\\
        }\]

        \item Per la funzione $f(x) = \log_\alpha(x)$ abbiamo che:
        \[\lim_{x \to x_0 \neq 0} \log_\alpha(x) =  \log_\alpha(x_0)
        \qquad\qquad
        \lim_{x \to 0^-} \log_\alpha(x) =  \mathrm{Indef.}
        \qquad\qquad
        \lim_{x \to 0^+} \log_\alpha(x) =  -\infty\]

        \[\lim_{x \to +\infty} \log_\alpha(x) = \soe{cl}{
            +\infty & \text{se } \alpha > 1 \\
            -\infty & \text{se } 0 < \alpha < 1\\
        }
        \qquad\qquad
        \lim_{x \to -\infty} \log_\alpha(x) = \mathrm{Indef.}\]
    \end{itemize}

    \newpage

    D'ora in poi, considereremo tali limiti come assodati e non giustificheremo il loro perché. Vediamo ora quindi delle proprietà che ci permettono di trattare i limiti in modo algebrico.

    Prima di tutto, notiamo che data una funzione costante $f(x) = k$ per qualche valore $x \in \R$, si ha che:
    \[\lim_{x \to x_0} f(x) = k \qquad \lim_{x \to \pm \infty} f(x) = k\]

    Tale osservazione risulta ovvia, ma è opportuno specificarla per risultati successivi. Procediamo ora con una proprietà intuitiva ma non scontata.

    \begin{framedprop}{Somma tra limiti finiti}
        Date due funzioni $f,g : I \to \R$ e un punto di accumulazione $x_0 \in I$, se si verifica che:
        \[\lim_{x \to x_0} f(x) = \ell \qquad\qquad \lim_{x \to x_0} g(x) = m\]
        allora si ha che:
        \[\lim_{x \to x_0} (f(x) + g(x)) = \ell + m\]
    \end{framedprop}

    \proofenv{
        Supponiamo che:
        \[\lim_{x \to x_0} f(x) = \ell \qquad\qquad \lim_{x \to x_0} g(x) = m\]

        Consideriamo quindi un qualsiasi valore $\varepsilon > 0$. Poiché i due limiti esistono, sappiamo che dato $\frac{\varepsilon}{2} > 0$ per $f(x)$ esista un valore $\delta_1 > 0$ tale che:
        \[\abs{x-x_0} < \delta_1 \implies \abs{f(x)-\ell} < \frac{\varepsilon}{2} \implies \ell - \frac{\varepsilon}{2} < f(x) < \ell + \frac{\varepsilon}{2}\]
        mentre per $g(x)$ esiste un valore $\delta_2 > 0$ tale che:
        \[\abs{x-x_0} < \delta_2 \implies \abs{g(x)-m} < \frac{\varepsilon}{2} \implies m - \frac{\varepsilon}{2} < g(x) < m + \frac{\varepsilon}{2}\]

        Poniamo quindi $\delta = \min(\delta_1, \delta_2)$. Ne segue automaticamente che:
        \[\abs{x-x_0} < \delta \leq \delta_1, \delta_2 \implies \ell - \frac{\varepsilon}{2} + m - \frac{\varepsilon}{2} < f(x) + g(x) < \ell + \frac{\varepsilon}{2} + m + \frac{\varepsilon}{2}\]
        \[\implies (\ell + m) - \varepsilon < f(x) + g(x) < (\ell + m) + \varepsilon \implies \abs{(f(x)+g(x)) - (\ell + m)} < \varepsilon\]
        dunque abbiamo che:
        \[\lim_{x \to x_0} (f(x) + g(x)) = \ell + m\]
    }

    Da tale proposizione segue automaticamente che:
    \[\lim_{x \to x_0} f(x) = \ell \implies \forall k \in \R \;\; \lim_{x \to x_0} kf(x) = k\ell\]

    Consideriamo quindi la funzione $f(x) = x^2+2x+4$. Abbiamo che:
    \[\lim_{x \to 4} x^2+2x+4 = \lim_{x \to 4} x^2 + \lim_{x \to 4} 2x + \lim_{x \to 4} 4 = 4^2 + 2 + 4 + 4 = 22\]

    Senza dilungarci in altre dimostrazioni, stiliamo la seguente lista di \textbf{regole algebriche per i limiti finiti}.
    \begin{framedprop}{Regole algebriche per i limiti finiti}
        Date due funzione $f,g : I \to \R$, se si verifica che
        \[\lim_{x \to *} f(x) = \ell \qquad\qquad \lim_{x \to *} g(x) = m\]
        allora si ha che:
        \begin{itemize}
            \item $\lim\limits_{x \to *} f(x) + g(x) = \ell + m$
            \item $\lim\limits_{x \to *} f(x)g(x) = \ell \cdot m$
            \item $\lim\limits_{x \to *} \dfrac{f(x)}{g(x)} = \dfrac{\ell}{m}$ se $m \neq 0$
        \end{itemize}

        Dove il simbolo $*$ può essere $x_0, x_0^+, x_0^-, +\infty$ o $-\infty$.
    \end{framedprop}


    Consideriamo quindi la funzione $f(x) = x^6x^3+\frac{e^x}{x^4}$. Abbiamo che:
    \[\lim_{x \to 1} x^6x^3+\frac{e^x}{x^4} = 1 \cdot 1 + \frac{e}{1} = e+1\]

    Quando i limiti finiti, dunque, essi possono essere trattati come se fossero dei normalissimi valori. Quando essi sono infiniti, invece, le cose diventano più complicate.

    \begin{framedprop}{Somme tra limiti infiniti}
        Date due funzione $f,g : I \to \R$, tali che:
        \[\lim_{x \to *} f(x) = \ell \qquad\qquad \lim_{x \to *} g(x) = m\]
        allora si ha che:
        \[\lim_{x \to *} f(x) + g(x) = \soe{ll}{
            +\infty & \text{se } \ell \in \R \text{ e } m = +\infty \\
            -\infty & \text{se } \ell \in \R \text{ e } m = -\infty \\
            +\infty & \text{se } \ell = +\infty \text{ e } m = +\infty \\
            -\infty & \text{se } \ell = -\infty \text{ e } m = -\infty \\
            \mathrm{Indet.} & \text{se } \ell = +\infty \text{ e } m = -\infty \\
        }\]

        Dove il simbolo $*$ può essere $x_0, x_0^+, x_0^-, +\infty$ o $-\infty$.
    \end{framedprop}

    Notiamo quindi che nel caso in cui abbiamo $+\infty - \infty$ si verifichi quella che viene chiamata \textbf{forma indeterminata}. Le forme indeterminate vanno attentamente studiate tramite delle \textbf{semplificazioni algebriche} quando possibile.

    Ad esempio, per la funzione $f(x) = 3x-x$ ingenuamente potremmo calcolare i due limiti separatamente ed ottenere che:
    \[\lim_{x \to +\infty} 3x-x = +\infty - \infty = \mathrm{Indeterminato}\]

    Tuttavia, semplificando la funzione prima di valutarne il limite notiamo che:
    \[\lim_{x \to +\infty} 3x-x = \lim_{x \to +\infty} 2x = +\infty\]

    Per quanto riguarda i prodotti tra limiti infiniti, abbiamo che:
    \begin{framedprop}{Prodotto tra limiti infiniti}
        Date due funzione $f,g : I \to \R$, tali che:
        \[\lim_{x \to *} f(x) = \ell \qquad\qquad \lim_{x \to *} g(x) = m\]
        allora si ha che:
        \[\lim_{x \to *} f(x)g(x) = \soe{ll}{
            +\infty & \text{se } \ell > 0 \text{ e } m = +\infty \\
            -\infty & \text{se } \ell > 0 \text{ e } m = -\infty \\
            -\infty & \text{se } \ell < 0 \text{ e } m = +\infty \\
            +\infty & \text{se } \ell < 0 \text{ e } m = -\infty \\
            +\infty & \text{se } \ell = +\infty \text{ e } m = +\infty \\
            +\infty & \text{se } \ell = -\infty \text{ e } m = -\infty \\
            -\infty & \text{se } \ell = +\infty \text{ e } m = -\infty \\
            \mathrm{Indet.} & \text{se } \ell = 0^+ \text{ e } m = \pm\infty \\
            \mathrm{Indet.} & \text{se } \ell = 0^- \text{ e } m = \pm\infty \\
        }\]

        Dove il simbolo $*$ può essere $x_0, x_0^+, x_0^-, +\infty$ o $-\infty$.
    \end{framedprop}

    Consideriamo ad esempio la funzione $f(x) = x^2-x$. Di primo occhio, valutando i due limiti otteniamo che:
    \[\lim_{x \to +\infty} x^2-x= +\infty - \infty = \mathrm{Indeterminato}\]

    Tuttavia, semplificando la funzione prima di valutarne il limite notiamo che:
    \[\lim_{x \to +\infty} x^2-x = \lim_{x \to +\infty} x(x-1) = (+\infty) \cdot (+\infty) = +\infty\]

    \newpage

    Nel caso della divisione tra limiti infiniti, invece, le forme indeterminate diventano molteplici:
    \begin{framedprop}{Divisione tra limiti infiniti}
        Date due funzione $f,g : I \to \R$, tali che:
        \[\lim_{x \to *} f(x) = \ell \qquad\qquad \lim_{x \to *} g(x) = m\]
        allora si ha che:
        \[\lim_{x \to *} \frac{f(x)}{g(x)} = \soe{ll}{
            0 & \text{se } \ell \in \R \text{ e } m = \pm\infty \\
            +\infty & \text{se } \ell = +\infty \text{ e } m > 0 \\
            -\infty & \text{se } \ell = +\infty \text{ e } m < 0 \\
            \mathrm{Indeterm} & \text{se } \ell = \pm\infty \text{ e } m = \pm\infty \\
            \mathrm{Indeterm} & \text{se } \ell = 0^+ \text{ e } m = 0^+ \\
            \mathrm{Indeterm} & \text{se } \ell = 0^- \text{ e } m = 0^- \\
            \mathrm{Indeterm} & \text{se } \ell = 0^+ \text{ e } m = 0^- \\
        }\]

        Dove il simbolo $*$ può essere $x_0, x_0^+, x_0^-, +\infty$ o $-\infty$.
    \end{framedprop}

    Consideriamo ad esempio la funzione $f(x) = \frac{x^2}{x}$. Di primo occhio, valutando i due limiti otteniamo che:
    \[\lim_{x \to +\infty} \frac{x^2}{x}= \frac{+\infty}{+\infty} = \mathrm{Indeterminato}\]

    Tuttavia, semplificando la funzione prima di valutarne il limite notiamo che:
    \[\lim_{x \to +\infty} \frac{x^2}{x} = \lim_{x \to +\infty} x = +\infty\]

    Ricapitolando, dunque, le forme indeterminate risultano essere:
    \[+\infty - \infty \qquad\qquad 0 \cdot \infty \qquad\qquad \frac{0}{\infty} \qquad\qquad \frac{0}{0}\]

    Tali forme vanno studiate attentamente, mentre ogni altra forma risulta risolvibile in modo diretto. Per valutare le forme indeterminate, è spesso sufficiente utilizzare qualche \textbf{trucchetto algebrico} che ci permette di semplificare il calcolo. Ad esempio, il seguente limite:
    \[\lim_{x \to +\infty} \frac{x^2-x-1}{3x^3+2x-7}\]

    Di primo occhio, questa risulta essere una forma duplicemente indeterminata poiché abbiamo che $\frac{+\infty - \infty}{\infty}$. Raggruppando il termine di grado più alto sia al numeratore che al denominatore, notiamo che:
    \[\lim_{x \to +\infty} \frac{x^2-x-1}{3x^3+2x-7} = \lim_{x \to +\infty} \frac{x^2 \rbk{1-\frac{1}{x}-\frac{1}{x^2}}}{3x^3 \rbk{1+\frac{2}{x^2}-\frac{7}{x^3}}}\]

    A questo punto, per $x \to \infty$ sappiamo che $\frac{1}{x}, \frac{1}{x^2}, \frac{1}{x^3} \to 0$, implicando allora che:
    \[\lim_{x \to +\infty} \frac{x^2-x-1}{3x^3+2x-7} = \lim_{x \to +\infty} \frac{x^2 \rbk{1-\frac{1}{x}-\frac{1}{x^2}}}{3x^3 \rbk{1+\frac{2}{x^2}-\frac{7}{x^3}}} \]
    \[= \lim_{x \to +\infty} \frac{x^2 \rbk{1-0-0}}{3x^3 \rbk{1+0-0}} = \lim_{x \to +\infty} \frac{x^2}{3x^3} = \lim_{x \to +\infty} \frac{1}{3x} = 0\]

    concludiamo quindi che per $x \to +\infty$ la funzione tenda a 0. Vediamo ora un altro esempio:
    \[\lim_{x \to -3} \frac{x^3 - 7 x + 6}{x^2 + 9 x + 18}\]

    Notiamo che $-3$ risulti essere una radice di entrambi i polinomi. Dunque, se valutassimo il limite sostituendo direttamente il valore a cui stiamo tendendo otterremmo la forma indeterminata $\frac{0}{0}$. Tuttavia, poiché tale valore è radice di entrambi, sappiamo che entrambi i polinomi siano un multiplo di $(x+3)$.
    
    Scomponiamo quindi i due polinomi tramite la regola di Ruffini:
    \begin{center}
        \begin{tabular}{c | c c c | c}
             & $1$ & $0$ & $-7$ & $6$ \\
        $-3$ &       & $-3$ & $9$ & $-6$\\
        \hline
            & $1$ & $-3$ & $2$ & $0$ \\
        \end{tabular}

        \qquad\qquad
        
        \begin{tabular}{c | c c | c}
            & $1$ & $9$ & $18$  \\
       $-3$ &       & $-3$ & $-18$\\
       \hline
           & $1$ & $6$ & $0$ \\
       \end{tabular}
    \end{center}
    dunque $x^3 - 7x + 6 = (x+3)(x^2-3x+2)$ e $x^2+9x+18 = (x+3)(x+6)$.
    
    Torniamo quindi a valutare il nostro limite:
    \[\lim_{x \to -3} \frac{x^3 - 7 x + 6}{x^2 + 9 x + 18} = \lim_{x \to -3} \frac{(x+3)(x^2-3x+2)}{(x+3)(x+6)} = \lim_{x \to -3} \frac{x^2-3x+2}{x+6} = \frac{0^2-3 \cdot 0 + 2}{-3+6} = \frac{1}{3}\]

    Per alcuni limiti, tuttavia, sfruttare trucchi algebrici risulta estremamente difficile. Nelle sezioni successive vedremo ulteriori strumenti che ci permettono di valutare tale tipologia di limiti.

    \newpage

    \section{Cambio di variabile e teorema del confronto}

    Vediamo un teorema fondamentale che ci permette di \textbf{trasformare} i limiti di funzioni composte in limiti di funzioni estremamente più semplici. Tale teorema risulta particolarmente utile nel caso in cui venga applicato ripetutamente, riducendo un limite complesso in uno immediato.

    \begin{framedthm}{Cambio di variabile}
        Date due funzioni $f,g : I \to \R$ tali che:
        \[\lim_{x \to *} f(x) = \ell \qquad\qquad \lim_{y \to \ell} g(y) = m\]
        allora si ha che:
        \[\lim_{x \to *} g(f(x)) = \lim_{y \to \ell} g(y) = m\]

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    Per comprendere meglio tale teorema, consideriamo il seguente limite:
    \[\lim_{x \to +\infty} \frac{\sin \rbk{\frac{1}{e^x}}}{e^{2x}}\]

    Posta la variabile $y = e^x$, notiamo che:
    \[\lim_{x \to +\infty} e^x = +\infty\]

    Grazie al teorema, abbiamo allora che:
    \[\lim_{x \to +\infty} \frac{\sin \rbk{\frac{1}{e^x}}}{e^{2x}} = \lim_{y \to +\infty} \frac{\sin \rbk{\frac{1}{y}}}{y^2}\]

    Ripetendo il processo, poniamo la variabile $z = \frac{1}{y}$ e notiamo che:
    \[\lim_{y \to +\infty} \frac{1}{y} = 0\]

    Ancora una volta dunque grazie al teorema abbiamo che:
    \[\lim_{x \to +\infty} \frac{\sin \rbk{\frac{1}{e^x}}}{e^{2x}} = \lim_{y \to +\infty} \frac{\sin \rbk{\frac{1}{y}}}{y^2} = \lim_{z \to 0} z^2 \sin z = 0\]

    \begin{framedthm}{Teorema del confronto}
        Date tre funzioni $f,g,h : I \to \R$ e un punto di accumulazione $x_0 \in I$, se $\exists \delta > 0$ tale che:
        \[\forall x \in I_\delta(x_0) \text{ vale } g(x) \leq f(x) \leq h(x)\]
        allora si verifica che:
        \[\lim_{x \to x_0} g(x) = \lim_{x \to x_0} h(x) = \ell \implies \lim_{x \to x_0} f(x) = \ell\]
    \end{framedthm}
    
    \proofenv{
        Supponiamo che $\exists \delta > 0$ tale che:
        \[\forall x \in I_\delta(x_0) \text{ vale } g(x) \leq f(x) \leq h(x)\]
        
        Assumiamo quindi che si verifichi:
        \[\lim_{x \to x_0} g(x) = \ell \qquad\qquad \lim_{x \to x_0} h(x) = \ell\]

        Consideriamo quindi un qualsiasi valore $\varepsilon > 0$. Poiché i due limiti esistono, sappiamo che dato $\varepsilon > 0$ per $g(x)$ esista un valore $\delta_1 > 0$ tale che:
        \[\abs{x-x_0} < \delta_1 \implies \abs{g(x)-\ell} < \varepsilon \implies \ell - \varepsilon < g(x) < \ell + \varepsilon\]
        mentre per $h(x)$ esiste un valore $\delta_2 > 0$ tale che:
        \[\abs{x-x_0} < \delta_2 \implies \abs{h(x)-\ell} < \varepsilon \implies \ell - \varepsilon < h(x) < \ell + \varepsilon\]
        
        Poniamo quindi $\delta_0 = \min(\delta, \delta_1, \delta_2)$. In tal caso, $\forall \varepsilon > 0$ abbiamo che:
        \[ 0 < \abs{x-x_0} < \delta_0 \leq \delta, \delta_1, \delta_2 \implies \soe{l}{
            g(x) \leq f(x) \leq h(x)\\
            \abs{g(x)-\ell} < \varepsilon \\
            \abs{h(x)-\ell} < \varepsilon \\
        } \implies \soe{l}{
            g(x) \leq f(x) \leq h(x)\\
            \ell - \varepsilon < g(x) < \ell + \varepsilon \\
            \ell - \varepsilon < h(x) < \ell + \varepsilon \\
        }\]
        \[\implies \ell - \varepsilon < g(x) \leq f(x) \leq h(x) < \ell +\varepsilon \implies \abs{f(x) - \ell} < \varepsilon\]
    }

    \begin{center}
        \includegraphics[scale=0.75]{images/confronto.png}
    \end{center}

    Il teorema del confronto, seppur molto situazionale, ci permette di calcolare limiti particolari per cui altrimenti non avremmo strumenti sufficienti per poterli dimostrare.
    
    \label{sinx_x}
    Consideriamo ad esempio il seguente limite:
    \[\lim_{x \to 0} \frac{\sin x}{x}\]

    Sostituendo direttamente il valore $0$, otteniamo la forma indeterminata $\frac{0}{0}$. Proviamo quindi a verificare i valori assunti dalla funzione all'avvicinarsi di $x$ da sinistra e destra:
    \[f(-0.1) \approx 0.998\ldots \qquad f(-0.01) \approx 0.999\ldots \qquad f(0.01) = \approx 0.999\ldots \qquad f(0.1) = 0.998\ldots\]

    Da entrambi i lati dunque, la funzione sembra tendere verso 1. Notiamo innanzitutto che $\forall x \in  \left [ 0, \frac{\pi}{2} \right )$ abbiamo che:
    \[ \sin x \geq 0 \text{ e } x \geq 0 \implies \frac{\sin x}{x} \geq 0\]
    mentre $\forall x \in  \left (-\frac{\pi}{2}, 0 \right ]$ abbiamo che:
    \[ \sin x \leq 0 \text{ e } x \leq 0 \implies \frac{\sin x}{x} \geq 0\]

    Per cui abbiamo che:
    \[\forall x \in \rbk{-\frac{\pi}{2}, \frac{\pi}{2}} \text{ vale sempre } \frac{\sin x}{x} = \abs{\frac{\sin x}{x}}\]

    Successivamente, notiamo che:
    \[\forall x \in \rbk{-\frac{\pi}{2}, \frac{\pi}{2}} \quad \abs{\sin x} \leq \abs{x} \leq \abs{\tan x}\]

    da cui segue che:
    \[\abs{x} \leq \abs{\tan x} = \abs{\frac{\sin x}{\cos x}} \implies \abs{\cos x} \leq \abs{\frac{\sin x}{x}}\]
    
    e ovviamente che:
    \[\abs{\sin x} \leq \abs{x} \implies \abs{\frac{\sin x}{x}} \leq \abs{\frac{x}{x}}\]

    Di conseguenza, concludiamo che:
    \[\forall x \in \rbk{-\frac{\pi}{2}, \frac{\pi}{2}} \quad \abs{\cos x} \leq \frac{\sin x}{x} = \abs{\frac{\sin x}{x}} \leq \abs{\frac{x}{x}}\]

    Infine, abbiamo che:
    \[1 = \lim_{x \to 0} \abs{\cos x} \leq \lim_{x \to 0} \frac{\sin x}{x} \leq \lim_{x \to 0} \abs{\frac{x}{x}} = 1\]
    concludendo quindi che:
    \[\lim_{x \to 0} \frac{\sin x}{x} = 1\]

    \newpage

    \section{Funzioni simili, o-piccolo, infiniti e infinitesimi}
    
    \begin{frameddefn}{Funzioni simili}
        Date due funzioni $f,g : I \to \R$ e diciamo che $f$ è \textbf{simile} a $g$ per $x \to *$, indicato con $f(x) \sim_{x \to *} g(x)$ o direttamente $f(x) \sim g(x)$ quando chiaro dal contesto, se si verifica che:
        \[\lim_{x \to *} \frac{f(x)}{g(x)} = 1\]
    \end{frameddefn}

    Il concetto di similitudine tra limiti di funzioni ci permette di determinare il modo rapido il comportamento di alcune funzioni. Ad esempio, nella sezione precedente abbiamo visto come:
    \[\lim_{x \to 0} \frac{\sin x}{x} = 1\]
    implicando dunque che $\sin x \sim_{x \to 0} x$. 

    \begin{framedobs}{}
        Date due funzioni $f,g : I \to \R$, dato $\ell \in \R-\{0\}$:
        \[\lim_{x \to *} f(x) = \lim_{x \to *} g(x) = \ell \implies f(x) \sim_{x \to *} g(x)\]

        mentre dato $m \in \R$ che:
        \[\soe{l}{
            f(x) \sim_{x \to *} g(x) \\
            \lim\limits_{x \to *} f(x) = m
        } \implies \lim\limits_{x \to *} g(x) = m\]

    \end{framedobs}

    \begin{framedobs}{Non sostituibilità di funzioni simili}
        Quando $f(x) \sim_{x \to *} g(x)$, non è sempre vero che $h(f(x)) \sim_{x \to *} h(g(x))$
    \end{framedobs}

    Ad esempio, consideriamo la funzione $f(x) = e^{x^3+5x}$. Notiamo che:
    \[\lim_{x \to +\infty} \frac{x^3+5x}{x^3} = \lim_{x \to 0} \frac{x^3\rbk{1+\frac{5}{x^2}}}{x^3} = \lim_{x \to +\infty} \frac{x^3}{x^3} = 1 \implies x^3+5x \sim x^3\]
    
    Tuttavia, abbiamo che:
    \[\lim_{x \to +\infty} \frac{e^{x^3+5x}}{e^{x^3}} = \lim_{x \to +\infty} \frac{e^{x^3\cdot e^{5x}}}{e^{x^3}} = \lim_{x \to +\infty} e^{5x} = +\infty \implies e^{x^3+5x} \not\sim e^{x^3}\]
    
    Per tale motivo, è necessario porre \underline{estrema} quando si lavora con funzioni simili in quanto non è sufficiente sostituire una funzione con l'altra.

    \begin{frameddefn}{Notazione o-piccolo}
        Date due funzioni $f,g : I \to \R$ e diciamo che $f$ è in \textbf{o-piccolo} di $g$ per $x \to *$, indicato con $f(x) = o_{x \to *}(g(x))$ o  direttamente $f(x) = o(g(x))$ quando chiaro dal contesto, se si verifica che:
        \[\lim_{x \to *} \frac{f(x)}{g(x)} = 0\]
    \end{frameddefn}

    Il concetto di $o$-piccolo può essere interpretato come una \textbf{gerarchia}: se $f(x) = o_{x \to *}(g(x))$ allora ciò significa che per $x \to *$ la funzione $g(x)$ assume un valore \textit{"infinitamente"} più grande di $f(x)$.
    
    Ad esempio, consideriamo la funzione $f(x) = x$. Notiamo che:
    \[\lim_{x \to +\infty} \frac{x}{x^2} = \lim_{x \to +\infty} \frac{1}{x} = 0\]
    dunque per $x \to +\infty$ abbiamo che $x = o(x^2)$. La notazione o-piccolo ci permette di determinare immediatamente alcuni limiti. Difatti, per definizione stessa abbiamo che:
    \[\lim_{x \to *} \frac{o(g(x))}{g(x)} = 0\]

    \begin{framedobs}{Transitività degli o-piccoli}
        Date tre funzioni $f,g, h : I \to \R$, per $x \to *$ abbiamo che:
        \[f(x) = o(g(x)) \text{ e } g(x) = o(h(x)) \implies f(x) = o(h(x))\]
    \end{framedobs}

    Ad esempio, risulta evidente che $x = o(x^2)$ e che $x^2 = o(x^3)$, ma anche che $x = o(x^3)$. La particolare utilità della notazione o-piccolo sta nella possibilità di definire delle operazioni algebriche molto semplici (ovviamente, devono essere definiti per lo stesso $x \to *$):
    \begin{enumerate}
        \item Eliminazione delle costanti:
        \[\forall k \in \R \text{ vale } o(k g(x)) = o(g(x)) \text{ e } k(o(g)) = o(g(x))\]

        \item Potenza di una funzione:
        \[f(x) = o(g(x)) \implies \forall \alpha \in \R \;\; f(x)^{\alpha} \implies o(g(x)^\alpha)\]

        \item Somma tra o-piccoli:
        \[o(f(x)) + o (f(x)) = o(f(x))\]

        \item Prodotto tra funzione e o-piccolo:
        \[f(x) o(g(x)) = o(f(x)g(x))\]

        \item Idempotenza:
        \[o(o(f(x))) = o(f(x))\]

        \item Somma tra o-piccoli di potenze:
        \[o(x^n) \pm o(x^m) = o(x^p) \text{ dove } p = \min(n,m)\]
    \end{enumerate}

    Ad esempio, consideriamo la seguente funzione:
    \[\lim_{x \to +\infty} \frac{x^3+x+6}{x^4}\]

    Possiamo facilmente notare che:
    \[\lim_{x \to \infty} \frac{x^3}{x^4} = \lim_{x \to +\infty} \frac{x}{x^4} = \lim_{x \to +\infty} \frac{6}{x^4} = 0\]
    dunque abbiamo che $x^3, x, 6 = o(x^4)$. Per tanto, abbiamo che:
    \[\lim_{x \to +\infty} \frac{o(x^4) + o(x^4) + o(x^4)}{x^4} = \lim_{x \to +\infty} \frac{o(x^4)}{x^4} = 0\]

    \begin{frameddefn}{Infiniti e infinitesimi}
        Data la funzione $f : I \to \R$, diciamo che $f$ è un \textbf{infinito} per $x \to *$ se si verifica che:
        \[\lim_{x \to *} f(x) = \pm\infty \]

        Similmente, diciamo che $f$ è un \textbf{infinitesimo} per $x \to *$ se si verifica che:
        \[\lim_{x \to *} f(x) = 0\]
    \end{frameddefn}

    Ad esempio, per la funzione $f(x) = \frac{1}{x^2}$ abbiamo che:
    \[\lim_{x \to 0} \frac{1}{x^2} = +\infty \qquad \lim_{x \to +\infty} \frac{1}{x^2} = 0\]
    dunque $f(x)$ è un infinito per $x \to 0$ e un infinitesimo per $x \to +\infty$.
    
    \begin{framedobs}{}
        Se $f(x)$ è un infinitesimo per $x \to *$ allora $f(x) = o(1)$
    \end{framedobs}

    \begin{framedobs}{}
        Se $f(x) = o(1)$ per $x \to *$ allora:
        \[\lim_{x \to *} f(x) + k = k\]
    \end{framedobs}

    \newpage

    \section{Ordini di grandezza}
    \label{ordini}

    Dato $\gamma > 0$, consideriamo il seguente limite:
    \[\lim_{x \to +\infty} \frac{e^{\gamma x}}{x}\]

    sostituendo $x \to +\infty$, otteniamo la forma indeterminata $\frac{\infty}{\infty}$. Cerchiamo quindi un altro approccio. Per definizione stessa di $e$, sappiamo che:
    \[\forall y \in \R \;\; e^y \geq 1+y\]

    Posto $y = \frac{\gamma}{2} x$, dunque, abbiamo che $y \in \R$, implicando che:
    \[e^y \geq 1+y \implies  e^{\frac{\gamma}{2} x} \geq 1 + \frac{\gamma}{2} x \implies e^{\gamma x} = \rbk{e^{\frac{\gamma}{2} x}}^2 \geq \rbk{1 + \frac{\gamma}{2} x }^2 = 1+\gamma x +  \frac{\gamma^2}{4} x^2\]

    Consideriamo quindi i valori $x > 0$. Otteniamo che:
    \[e^{\gamma x} \geq 1+\gamma x +  \frac{\gamma^2}{4} x^2 \implies +\infty \geq \frac{e^{\gamma x}}{x} \geq \frac{1}{x}+\gamma +  frac{\gamma^2}{4} x\]

    Valutiamo quindi il limite per $x \to +\infty$:
    \[+\infty \geq \lim_{x \to +\infty} \frac{e^{\gamma x}}{x} \geq \lim_{x \to +\infty} \frac{1}{x}+\gamma +  \frac{\gamma^2}{4} x = +\infty\]

    concludendo che:
    \[\lim_{x \to +\infty} \frac{e^{\gamma x}}{x} = +\infty\]

    Possiamo inoltre estendere tale risultato ad ogni potenza $x^{\beta}$ con $\beta > 0$:
    \[\lim_{x \to +\infty} \frac{e^{\gamma x}}{x^{\beta}} = \lim_{x \to +\infty} \rbk{\frac{e^{\frac{\gamma}{\beta} x}}{x}}^\beta = (+\infty)^{\beta} = +\infty\]

    e infine, estenderlo ad ogni esponenziale $\alpha^{\gamma x}$ con $\alpha > 0$:
    \[\lim_{x \to +\infty} \frac{\alpha^{\gamma x}}{x^{\beta}} = \lim_{x \to +\infty} \frac{e^{\ln(\alpha^{\gamma x})}}{x^{\beta}} = \lim_{x \to +\infty} \frac{e^{\gamma \ln(\alpha) x }}{x^{\beta}} = +\infty\]

    Da questo risultato deriva automaticamente il risultato opposto:
    \[\lim_{x \to +\infty} \frac{x^{\beta}}{\alpha^{\gamma x}} = \lim_{x \to +\infty} \frac{1}{\frac{\alpha^{\gamma x}}{x^{\beta}}} = \lim_{y \to +\infty} \frac{1}{y} = 0\]

    dove $y = \frac{\alpha^{\gamma x}}{x^{\beta}}$. In altre parole, \textbf{ogni esponenziale vince su ogni potenza}.

    Similmente, dati $\alpha, \beta, \gamma > 0$ consideriamo il seguente limite:
    \[\lim_{x \to +\infty} \frac{\log_{\alpha}^\gamma (x)}{x^{\beta}}\]
    
    Notiamo che:
    \[\lim_{x \to +\infty} \log_\alpha(x) = +\infty\]

    Di conseguenza, ponendo $y = \log_\alpha(x)$, abbiamo che:
    \[\lim_{x \to +\infty} \frac{\log_{\alpha}^\gamma (x)}{x^{\beta}} = \lim_{x \to +\infty} \frac{y^\gamma}{\alpha^{\beta y}} = 0^+\]

    Come prima, da questo risultato deriva automaticamente il risultato opposto:
    \[\lim_{x \to +\infty} \frac{x^{\beta}}{\log_{\alpha}^\gamma (x)} = \lim_{x \to +\infty} \frac{1}{\frac{\log_{\alpha}^\gamma (x)}{x^{\beta}}} = \lim_{x \to 0^+} \frac{1}{y} = +\infty\]
    
    dove $y = \frac{\log_{\alpha}^\gamma (x)}{x^{\beta}}$. In altre parole, \textbf{ogni potenza vince su ogni logaritmo}. Vediamo ora cosa succede confrontando esponenziali e fattoriali. Dati $\alpha > 0$, consideriamo il seguente limite:
    \[\lim_{x \to +\infty} \frac{\alpha^{\gamma x}}{x!} \]

    dove per semplicità assumiamo che $x \in \N$ (daremo più avanti degli strumenti che ci permetteranno di giustificare tale assunzione). Espandendo numeratore e denominatore della frazione notiamo che:
    \[ \frac{\alpha^{\gamma x}}{x!} =  \frac{\overbrace{\alpha^{\gamma} \cdot \alpha^{\gamma} \cdot \alpha^{\gamma} \cdot \ldots \cdot \alpha^\gamma}^{\text{$x$ volte}}}{1 \cdot 2 \cdot 3 \cdot \ldots \cdot x} =  \frac{\alpha^\gamma}{1} \cdot \frac{\alpha^\gamma}{2} \cdot \frac{\alpha^\gamma}{3} \cdot \ldots \cdot \frac{\alpha^\gamma}{x-1} \cdot \frac{\alpha^\gamma}{x} \]

    Sia $m \in \N$ il primo intero tale che $x \geq m \geq a^\gamma$. Abbiamo quindi che:
    \[ \frac{\alpha^{\gamma x}}{x!} = \frac{\alpha^\gamma}{1} \cdot \frac{\alpha^\gamma}{2} \cdot \frac{\alpha^\gamma}{3} \cdot \ldots \cdot \frac{\alpha^\gamma}{m-1} \cdot \frac{\alpha^\gamma}{m} \cdot \ldots \cdot \frac{\alpha^\gamma}{x-1} \cdot \frac{\alpha^\gamma}{x}\]

    Poiché $m \geq a$, ne segue che $\frac{\alpha^\gamma}{m} \leq 1$, per tanto abbiamo che:
    \[ \frac{\alpha^{\gamma x}}{x!} \leq \underbrace{\frac{\alpha^\gamma}{1} \cdot \frac{\alpha^\gamma}{2} \cdot \frac{\alpha^\gamma}{3} \cdot \ldots \cdot \frac{\alpha^\gamma}{m-1}}_{\text{tutti $\leq \alpha^\gamma$}} \cdot \underbrace{\frac{\alpha^\gamma}{m} \cdot \ldots \cdot \frac{\alpha^\gamma}{x-1}}_{\text{tutti $\leq 1$}} \cdot \frac{\alpha^\gamma}{x} \leq a^{\gamma(m-1)} \frac{\alpha^\gamma}{x}\]

    Per tanto, abbiamo che:
    \[0 \leq \lim_{x \to +\infty} \frac{\alpha^{\gamma x}}{x!} \leq \lim_{x \to +\infty} a^{\gamma(m-1)} \frac{\alpha^\gamma}{x} = 0\]
    concludendo che:
    \[\lim_{x \to +\infty} \frac{\alpha^{\gamma x}}{x!} = 0\]
    
    In altre parole, \textbf{ogni fattoriale vince su ogni esponenziale} Infine, confrontiamo il termine $x^x$ (anche detto \textit{tetrazione di secondo ordine}) con ogni fattoriale. Dato $\beta > 0$, consideriamo il seguente limite:
    \[\lim_{x \to +\infty} \frac{(x!)^\beta}{x^x}\]

    dove per semplicità assumiamo sempre che $x \in \N$. Procedendo in modo simile al caso precedente, notiamo che:
    \[ \frac{(x!)^\beta}{x^x} = \frac{1^\beta}{x} \cdot \underbrace{\frac{2^\beta}{x} \cdot \frac{3^\beta}{x} \cdot \ldots \cdot \frac{x-1}{x} \cdot \frac{x}{x}}_{\text{tutti $\leq 1$}} \leq \frac{1}{x}\]

    Per tanto, abbiamo che:
    \[0 \leq \lim_{x \to +\infty} \frac{(x!)^\beta}{x^x} \leq \lim_{x \to +\infty} \frac{1}{x} = 0\]
    concludendo che:
    \[\lim_{x \to +\infty} \frac{(x!)^\beta}{x^x} = 0\]. In altre parole, \textbf{ogni tetrazione vince su ogni fattoriale}.

    \begin{framedprop}{Gerarchia degli infiniti}
        Dati $\alpha, \beta, \gamma, \mu, \lambda, \rho > 0$, abbiamo che:
        \[\log_{\alpha}^\gamma(x) \prec x^\beta \prec \mu^{\lambda x} \prec (x!)^{\rho} \prec x^x\]
        dove $f(x) \prec g(x)$ indica che $f(x) = o(g(x))$ quando $x \to +\infty$.
    \end{framedprop}

    \newpage

    \section{Limiti notevoli}

    Nella \Cref{sinx_x} abbiamo visto come alcune forme indeterminate non siano risolvibili in modo semplice. La maggior parte di tali formule indeterminate, tuttavia, contiene al suo interno delle sottofunzioni corrispondenti a dei \textbf{limiti notevoli}, ossia delle forme indeterminate molto comuni per le quali il limite è già noto.

    Abbiamo visto come per $x \to 0$ si abbia che $\sin x \sim x$. Vedremo come questo risultato sia alla base di ogni altro limite notevole noto. Ad esempio, consideriamo il seguente limite:
    \[\lim_{x \to 0} \frac{1-\cos x}{x}\]
    Sostituendo il limite, otterremmo la forma indeterminata $\frac{0}{0}$. Con qualche trucchetto algebrico, tuttavia, possiamo ricondurre tale espressione al limite notevole che già conosciamo. Sapendo che $\cos^2 x = 1 - \sin^2 x$, possiamo ottenere che:
    \[\begin{split}
        \lim_{x \to 0} \frac{1-\cos x}{x} &= \lim_{x \to 0} \frac{1 - \cos x}{x} \cdot \frac{1 + \cos x}{1 + \cos x} \\
        &= \lim_{x \to 0} \frac{1 - \cos^2 x}{x (1 + \cos x)}\\
        &= \lim_{x \to 0} \frac{\sin^2 x}{x (1 + \cos x)}\\
        &= \lim_{x \to 0} \frac{\sin x}{x} \cdot \frac{\sin x}{(1 + \cos x)}\\
        &= \lim_{x \to 0} 1 \cdot \frac{\sin x}{(1 + \cos x)}\\
        &= \lim_{x \to 0} \frac{\sin 0}{(1 + \cos 0)}\\
        &= 0\\
    \end{split}\]
    
    Procedendo analogamente al limite appena svolto, possiamo concludere anche il seguente limite notevole:
    \[\begin{split}
        \lim_{x \to 0} \frac{1-\cos x}{x^2} &= \lim_{x \to 0} \frac{1 - \cos x}{x^2} \cdot \frac{1 + \cos x}{1 + \cos x} \\
        &= \lim_{x \to 0} \frac{\sin^2 x}{x^2 (1 + \cos x)}\\
        &= \lim_{x \to 0} \rbk{\frac{\sin x}{x}}^2 \cdot \frac{1}{(1 + \cos x)}\\
        &= \lim_{x \to 0} 1 \cdot \frac{1}{(1 + \cos x)}\\
        &= \frac{1}{2}\\
    \end{split}\]
    il che ci permette di dedurre che per $x \to 0$ valga $1-\cos x \sim \frac{x^2}{2}$ (strano risultato!).

    Due risultati nettamente più immediati, invece, risultano essere i seguenti:
    \[\lim_{x \to 0} \frac{\tan x}{x} = \lim_{x \to 0} \frac{\sin x}{x \cos x} = \lim_{x \to 0} \frac{1}{\cos x} = 1\]
    dunque per $x \to 0$ abbiamo anche che $\tan x \sim x$, mentre:
    \[\lim_{x \to 0} \frac{\arcsin x}{x} = \lim_{y \to 0} \frac{y}{\sin y} = \lim_{y \to 0} \frac{1}{\frac{\sin y}{y}} = 1\]
    dove $y = \arcsin x$ e analogamente che:
    \[\lim_{x \to 0} \frac{\arctan x}{x} = \lim_{y \to 0} \frac{y}{\tan y} = \lim_{y \to 0} \frac{1}{\frac{\tan y}{y}} = 1\]
    dove $y = \arctan x$.

    Vediamo ora altre tipologie di limite notevole che non siano \textit{"imparentate"} con il limite tramite cui $\sin x \sim x$. Consideriamo quindi il seguente limite:
    \[\lim_{x \to 0} \frac{e^x-1}{x}\]

    ricordiamo di aver definito il numero di Nepero $e$ come l'unico numero reale per cui dato un qualsiasi $x \in \R$ si verifica che $e^x \geq 1 + x$. Poiché ciò vale per ogni elemento in $\R$, sostituendo $-x$ nella disequazione otteniamo che $e^{-x} \geq 1 - x$, ottenendo quindi che:
    \[e^{-x} \geq 1 - x \implies \frac{1}{e^x} \geq 1-x \implies \frac{1}{1-x} \geq e^x\]

    Concatenando le due disequazioni abbiamo che:
    \[\frac{1}{1-x} \geq e^x \geq 1 + x \implies \frac{1}{x(1-x)}-\frac{1}{x} \geq \frac{e^x-1}{x} \geq 1\]

    Semplifichiamo quindi il lato sinistro della disequazione ottenuta:
    \[\frac{1}{x(1-x)}-\frac{1}{x} = \frac{1-(1-x)}{x(1-x)} = \frac{x}{x(1-x)} = \frac{1}{1-x}\]
    dunque tramite il teorema del confronto concludiamo che:
    \[\lim_{x \to 0} \frac{1}{1-x} \geq \lim_{x \to 0} \frac{e^x-1}{x} \geq \lim_{x \to 0} 1 \implies 1 \geq \lim_{x \to 0} \frac{e^x-1}{x} \geq 1 \implies \lim_{x \to 0} \frac{e^x-1}{x} = 1\]

    quindi per $x \to 0$ vale che $e^x - 1 \sim x$. Vediamo ora una serie di limiti notevoli imparentati al limite appena ottenuto, partendo dal seguente limite:
    \[\lim_{x \to 0} \frac{\ln (1+x)}{x}\]
    ponendo $y = \ln (1+x)$ otteniamo che:
    \[\lim_{x \to 0} \frac{\ln (1+x)}{x} = \lim_{y \to 0} \frac{y}{e^y-1} = \lim_{y \to 0} \frac{1}{\frac{e^y-1}{y}} = 1\]

    Vediamo ora il seguente limite:
    \[\lim_{x \to +\infty} \rbk{1+\frac{1}{x}}^x\]

    Per definizione stessa di $\ln x$ in quanto funzione inversa di $e^x$, sappiamo che $x = e^{\ln x}$. Per tanto, abbiamo che:
    \[\begin{split}
        \lim_{x \to +\infty} \rbk{1+\frac{1}{x}}^x &= \lim_{x \to +\infty} e^{\ln \rbk{\rbk{1+\frac{1}{x}}^x}} \\
        &= \lim_{x \to +\infty} e^{x \ln \rbk{\rbk{1+\frac{1}{x}}}} \\
        &= \lim_{y \to 0} e^{\frac{1}{y} \ln \rbk{\rbk{1+y}}} \\
        &= \lim_{y \to 0} e^{1} \\
        &= e \\
    \end{split}\]

    dove abbiamo posto $y = \frac{1}{x}$. Tale limite risulta particolarmente interessante: invece di utilizzare la nostra definizione, alcuni libri di analisi matematica definiscono il numero di Nepero $e$ come esattamente il risultato di tale limite notevole. Difatti, Nepero stesso definì originariamente il numero $e$ in tal modo. Si può dimostrare che le due definizioni sono equivalenti tra loro, ossia che dall'una si possa ricavare l'altra e viceversa (il numero $e$ può essere definito anche in tanti altri modi, tutti equivalenti tra loro!). 

    Di seguito forniamo una tabella riassuntiva di tutti i limiti notevoli analizzati:
    \begin{center}
        \begin{tabular}{ccccc}
            \\
            $\lim\limits_{x \to 0} \dfrac{\sin x}{x} = 1$ & \qquad\qquad & $\lim\limits_{x \to 0} \dfrac{1-\cos x}{x} = 0$ & \qquad\qquad & $\lim\limits_{x \to 0} \dfrac{1-\cos x}{x^2} = \dfrac{1}{2}$ \\\\\\
            $\lim\limits_{x \to 0} \dfrac{\tan x}{x} = 1$ & \qquad\qquad & $\lim\limits_{x \to 0} \dfrac{\arcsin}{x} = 1$ & \qquad\qquad & $\lim\limits_{x \to 0} \dfrac{\arctan}{x} = 1$ \\\\\\
            $\lim\limits_{x \to 0} \dfrac{e^x-1}{x} = 1$ & \qquad\qquad & $\lim\limits_{x \to 0} \dfrac{\ln(1+x)}{x} = 1$ & \qquad\qquad & $\lim\limits_{x \to 0} \rbk{1+\dfrac{1}{x}}^x = e$ 
        \end{tabular}
    \end{center}

    \newpage

    \section{Successioni numeriche}

    Restringiamo ora la nostra attenzione ad un particolare strumento matematico molto intuitivo, ossia le \textbf{successioni numeriche}. Banalmente, una successione numerica è una sequenza di valori generati da un pattern, dove ogni valore della sequenza è generato da un numero naturale. Formalmente, le successioni numeriche sono definite come delle funzioni $a : \N \to \R$ che associano il numero naturale $n$ al valore $a(n)$, solitamente indicato come $a_n$ per distinguerlo dalle normali funzioni. Ad esempio, la sequenza $a_n = 0, 1, 4, 9, 16, 25, \ldots$ è generata dalla successione $a_n : \N \to \R : n \mapsto n^2$.

    Le successioni numeriche sono uno strumento matematico molto semplice ma estremamente connesso a strumenti molto più potenti. Ad esempio, il concetto di successione può essere utilizzato per definire le \textbf{sommatorie numeriche}. Consideriamo la seguente somma:
    \[0 + 2 + 4 + 6 + 8 + 10 + \ldots + 2n\]

    Tale somma corrisponde alla somma dei primi $n$ termini della sequenza generata dalla successione $a_n : \N \to \R : n \mapsto 2n$. Per esprimere tale somma in modo compatto, utilizziamo la seguente scrittura:
    \[\sum_{i = 0}^n 2n\]
    che viene letta come \textit{"la sommatoria per $i$ che va da 0 a $n$ della successione $2n$"}. Generalmente, data una successione $a_n$ abbiamo che:
    \[\sum_{i = k}^n a_n = a_k + a_{k+1} + \ldots + a_{n-1} + a_n\]
    dove $k \in \N$ e $k \leq n$.

    Data una successione $a_n : \N \to \R$, sia $S(a_n)$ l'insieme composto dai termini della successione, ossia $S(a_n) = \{a_n \mid n \in \N\}$. Trattandosi di un insieme, su di esso si applicano i concetti di insieme \textit{limitato superiormente} ed \textit{inferiormente}, oltre che i concetti di \textit{crescita e decrescita}.

    Data una successione $a_n : \N \to \R$, diciamo che tale successione è:
    \begin{itemize}
        \item \textbf{Limitata superiormente} se $\exists M \geq 0$ tale che $a_n \leq M$ per ogni $n \in \N$. 
        \item \textbf{Limitata inferiormente} se $\exists M \geq 0$ tale che $a_n \geq M$ per ogni $n \in \N$. 
        \item \textbf{Limitata} se $\exists M \geq 0$ tale che $\abs{a_n} \leq M$ per ogni $n \in \N$. 
        \item \textbf{Crescente} se $a_n \leq a_{n+1}$ per ogni $n \in \N$ (o \textit{strettamente crescente} se $a_n < a_{n+1}$)
        \item \textbf{Decrescente} se $a_n \geq a_{n+1}$ per ogni $n \in \N$ (o \textit{strettamente decrescente} se $a_n > a_{n+1}$)
        
    \end{itemize}
    
    Ad esempio, la successione $a_n = \frac{1}{n}$ è limitata poiché per ogni $n \in \N$ si ha che $\abs{\frac{1}{n}} \leq 1$ e inoltre è strettamente decrescente in quanto $\frac{1}{1} > \frac{1}{2} > \ldots > \frac{1}{n}$. 

    \newpage

    Essendo le successioni una restrizione delle funzioni, anche su di essere vale il concetto di \textbf{limite di successione}, del tutto analogo al concetto di limite di funzione. Ad esempio, abbiamo che:
    \[\lim_{n \to +\infty} \frac{n^4 + n^3}{2n^4+3n+1} = \lim_{n \to +\infty} \frac{n^4 \rbk{1} + \frac{1}{n}}{n^4 \rbk{2+\frac{3}{n^3}+\frac{1}{n^4}}} = \frac{1}{2}\]

    Consideriamo la successione $a_n = (-1)^n$. Notiamo facilmente che:
    \[\begin{array}{ccc}
        a_1 = -1 & \qquad\qquad & a_2 = 1 \\
        a_3 = -1 & \qquad\qquad & a_4 = 1 \\
        a_5 = -1 & \qquad\qquad & a_6 = 1 \\
        \vdots   & \qquad\qquad & \vdots \\
        a_{2k+1} = -1 & \qquad\qquad & a_{2k} = 1 \\
    \end{array}\]

    In altre parole, all'interno della successione risiedono due \textit{sotto-successioni}, una data dagli indici pari della successione e l'altra data dagli indici dispari. Tali sotto-successioni possono essere modellate come una composizione tra la successione $a_n$ ed una successione strettamente crescente che definisca gli indici da considerare, ad esempio $b_k = 2k$:
    \[a_{b_k} = (-1)^{2k} = ((-1)^2)^k = 1^k = 1\]

    \begin{frameddefn}{Sotto-successione}
        Data una successione $a_n : \N \to \R : n \to a(n)$ ed una successione strettamente crescente $b_k : \N \to \R : k \to b(k)$, definiamo la \textbf{sotto-successione} di $a_n$ su $b_k$ come la composizione delle successioni $a_n$ e $b_k$:
        \[a_{b_k} : \N \to \R : k \to a(b(k))\]
    \end{frameddefn}
    
    Il concetto di sotto-successione ci permette di definire degli stretti legami tra i limiti di funzione e i limiti di successione. Ad esempio, esse ci permettono di affermare che ogni insieme infinito e limitato $S \subseteq \R$ ammette \textbf{almeno un punto di accumulazione}. Tale affermazione può essere riformulata nel seguente teorema ad essa equivalente (ossia l'affermazione implica il teorema e il teorema implica l'affermazione).
    
    \begin{framedthm}{Teorema di Bolzano-Weierstrass}
        Data una successione $a_n : \N \to \R$, se $a_n$ è limitata allora esiste almeno una sotto-successione $a_{b_k}$ convergente per $k \to +\infty$. 

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    Ad esempio, la successione $a_{n} = (-1)^n$ è limitata in quanto $\abk{(-1)^n} = 1$ per ogni $n \in \N$. Per il teorema di Bolzano-Weierstrass, dunque, deve esistere almeno una sotto-successione che converga per $n \to +\infty$. Difatti, possiamo trovare ben due sotto-successioni convergenti. Date le successioni $b_k = 2k$ e $c_h = 2h+1$, abbiamo che:
    \[\lim_{k \to +\infty} a_{b_k} = (-1)^{2k} = 1 \qquad \lim_{h \to +\infty} a_{c_h} = (-1)^{2h+1} = -1\]

    Inoltre, essendo le successioni delle funzioni, su di esse vale anche il \nameref{unique_lim}. Un diretto corollario di tale teorema risulta essere la seguente affermazione: se una successione tende ad un determinato valore $\ell$, ogni sua sotto-successione dovrà necessariamente tendere allo stesso valore.

    \begin{framedthm}{Limiti di sotto-successioni}
        Data una successione $a_n : \N \to \R$, se si verifica che:
        \[\lim_{n \to +\infty} a_n = \ell\]

        allora per ogni sotto-successione $a_{b_k}$ si ha che:
        \[\lim_{k \to +\infty} a_{b_k} = \ell\]

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    La parte interessante del risultato risiede nella sua \textit{affermazione contronominale}: se due sotto-successioni $a_{b_k}$ e $a_{c_h}$ tendono a due valori distinti $\ell, \ell'$ allora è impossibile che la successione $a_n$ abbia limite in quanto il limite debba essere unico. Ad esempio, abbiamo visto come date le successioni $a_n = (-1)^n, b_k = 2k$ e $c_h = 2h+1$ si abbia che $a_{b_k} \to -1$ e che $a_{c_h} \to 1$, dunque è impossibile che $a_n$ ammetta un limite.

    Vediamo ora il cosiddetto \textbf{teorema ponte}, il quale mette in stretta relazione il mondo dei limiti di funzione e il mondo dei limiti di successione (da cui il nome del teorema, una sorta di ponte tra i due mondi). Tale teorema può essere utilizzato per dare una \textit{seconda definizione} di limite di funzione tramite il concetto di limiti di successioni.

    \begin{framedthm}{Teorema ponte}
        Sia $f : I \to \R$ e un sia $x_0$ un punto di accumulazione in $I$ (oppure $\pm \infty$). Si verifica che:
        \[\lim_{x \to x_0} f(x) = \ell \text{ (oppure $\pm \infty$)}\]
        se e solo se per ogni successione $a_n : \N \to \R$ tale che $a_n \to x_0$ quando $n \to +\infty$ si ha anche che:
        \[\lim_{n \to +\infty} f(a_n) = \ell \text{ (oppure $\pm \infty$)}\]

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    Per comprendere meglio il teorema, consideriamo la funzione $f(x) = \frac{1}{x^2}$. Dato il punto di accumulazione $x_0 = 0$, sappiamo che:
    \[\lim_{x \to 0} \frac{1}{x^2} = +\infty\]

    Consideriamo quindi la successione $a_n = \frac{1}{n}$. Chiaramente, per $n \to +\infty$ si ha che $a_n \to 0$. Per tanto, tramite il teorema ponte sappiamo che:
    \[\lim_{n \to +\infty} \frac{1}{\rbk{\frac{1}{n}}^2} = +\infty\]

    A questo punto una domanda sorge spontanea: non potremmo ottenere lo stesso risultato tramite un cambio di variabile? Ad esempio, ponendo $y = \frac{1}{x}$ avremmo comunque che:
    \[\lim_{y \to +\infty} \frac{1}{\rbk{\frac{1}{y}}^2} = +\infty\]

    La domanda è lecita e la risposta risulta anche corretta. Tuttavia, la potenza del teorema ponte risiede nel fatto che l'affermazione debba valere \textit{per ogni} successione che tende al punto di accumulazione. Ancora una volta, l'affermazione contronominale del teorema risulta più interessante: se due successioni che soddisfano la proprietà fanno tendere il limite a due valori diversi allora il limite della funzione non può esistere. Questo ci permette di dimostrare più semplicemente l'inesistenza di alcuni limiti.

    Ad esempio, consideriamo il seguente limite:
    \[\lim_{x \to +\infty} \sin x\]

    Date le due successioni $a_n = \frac{\pi}{2}+2n\pi$ e $b_n = -\frac{\pi}{2} + 2n\pi$, per $n \to +\infty$ abbiamo che $a_n, b_k \to +\infty$. Per tanto, tramite il teorema ponte il limite della composizione tra la funzione e le due successioni dovrebbe tendere allo stesso valore. Tuttavia, notiamo che:
    \[\lim_{n \to +\infty} \sin \rbk{\frac{\pi}{2}+2n\pi} = \lim_{n \to +\infty} \sin \rbk{\frac{\pi}{2}} = 1\]
    mentre:
    \[\lim_{n \to +\infty} \sin \rbk{-\frac{\pi}{2}+2n\pi} = \lim_{n \to +\infty} \sin \rbk{-\frac{\pi}{2}} = -1\]

    dunque il limite per $x \to +\infty$ di $\sin x$ non può esistere. Il teorema ponte, inoltre, ci permette di giustificare le assunzioni fatte nella \Cref{ordini}: quando $x \to +\infty$, la successione $a_n = n$ tende a $+\infty$, dunque possiamo "sostituire" i valori reali con i valori naturali grazie al teorema ponte (tali assunzioni sono possibili \underline{solo se} siamo certi che il limite esista).

    \newpage


    \section{Asintoti di una funzione}

    Consideriamo la seguente funzione $f(x) = \frac{x-3}{x-2}$. Quando $x \to 2^{+}$ e $x \to 2^{-}$, notiamo facilmente che:
    \[\lim_{x \to 2^+} \frac{x-3}{x-2} = \lim_{x \to 2^+} \frac{2^+ - 3}{2^+-2} = \lim_{x \to 2^+} \frac{-1^+}{0^+} = -\infty\]
    mentre:
    \[\lim_{x \to 2^-} \frac{x-3}{x-2} = \lim_{x \to 2^-} \frac{2^- - 3}{2^--2} = \lim_{x \to 2^-} \frac{-1^-}{0^-} = +\infty\]

    Per $x \to 2$, dunque, la funzione sembra schizzare verso $\pm \infty$.
    \begin{figure}[H]
        \centering

        \includegraphics[scale=0.75]{images/asint_v.png}
    \end{figure}

    Notiamo quindi che per $x \to 2$ la funzione $f(x)$ tende ad avvicinarsi alla retta $x = 2$, senza mai toccarla (poiché ovviamente $2 \notin \mathrm{Dom}(f)$). Quando la funzione assume tale comportamento, tale retta viene detta \textbf{asintoto verticale} di $f$.

    \begin{frameddefn}{Asintoto verticale}
        Data la funzione $f : I \to \R$ e un punto di accumulazione $x_0 \in I$, diciamo che la retta $x = x_0$ è un \textbf{asintoto verticale} di $f$ se di verifica che:
        \[\lim_{x \to x_0^+} f(x) = \pm \infty \text{\quad oppure \quad} \lim_{x \to x_0^-} f(x) = \pm \infty\]
    \end{frameddefn}

    Tali asintoti si verificano solitamente agli \textbf{estremi del campo di esistenza}, ma non è detto che esistano in ogni estremo. Una funzione può godere anche di altre tipologie di asintoto. Ad esempio, abbiamo già visto come alcune funzioni convergano ad un valore finito quando $x \to \pm \infty$. Ad esempio, abbiamo che:
    \[\lim_{x \to +\infty} \frac{x-3}{x-2} = 1 \qquad\qquad \lim_{x \to -\infty} \frac{x-3}{x-2} = 1\]
    dunque per $x \to \pm \infty$ abbiamo che $f(x) \to 1$, dunque la funzione tende ad avvicinarsi alla retta $y = 1$, senza mai toccarla. In questo caso, diciamo che tale retta è un \textbf{asintoto orizzontale} di $f$. 
    
    \begin{figure}[H]
        \centering

        \includegraphics[scale=0.7]{images/asint_o.png}
    \end{figure}
    

    \begin{frameddefn}{Asintoto orizzontale}
        Data la funzione $f : I \to \R$ e un valore $\ell \in \R$, diciamo che la retta $y = \ell$ è un \textbf{asintoto orizzontale} di $f$ se di verifica che:
        \[\lim_{x \to +\infty} f(x) = \ell \text{ oppure } \lim_{x \to -\infty} f(x) = \ell\]
    \end{frameddefn}

    \begin{framedobs}{Asintoti multipli}
        Una funzione potrebbe avere più di un asintoto verticale e massimo due asintoti orizzontali.
    \end{framedobs}

    Consideriamo ad esempio la funzione $f(x) = \dfrac{x-3}{x^2-6x+8}$. Notiamo che il denominatore possa essere riscritto come $(x-2)(x-4)$. Per tanto, abbiamo che $2,4 \notin \mathrm{Dom}(f)$. Studiamo quindi i limiti della funzione in tali due punti:
    \begin{itemize}
        \item Per $x \to 2$ abbiamo che:
        \[\lim_{x \to 2^+} \frac{x-3}{(x-2)(x-4)} = \lim_{x \to 2^+} \frac{2^+-3}{(2^+-2)(2^+-4)} = \lim_{x \to 2^+} \frac{-1^+}{(0^+)(-2^+)} = +\infty\]
        e che:
        \[\lim_{x \to 2^-} \frac{x-3}{(x-2)(x-4)} = \lim_{x \to 2^-} \frac{2^+-3}{(2^--2)(2^--4)} = \lim_{x \to 2^-} \frac{-1^-}{(0^-)(-2^-)} = -\infty\]

        \item Per $x \to 4$ abbiamo che:
        \[\lim_{x \to 4^+} \frac{x-3}{(x-2)(x-4)} = \lim_{x \to 4^+} \frac{4^+-3}{(4^+-2)(4^+-4)} = \lim_{x \to 4^+} \frac{1^+}{(2^+)(0^+)} = +\infty\]
        e che:
        \[\lim_{x \to 4^-} \frac{x-3}{(x-2)(x-4)} = \lim_{x \to 4^-} \frac{4^+-3}{(4^--2)(4^--4)} = \lim_{x \to 4^-} \frac{1^-}{(2^-)(0^-)} = -\infty\]
    \end{itemize}

    dunque $x = 2$ e $x = 4$ sono due asintoti verticali della funzione.
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.75]{images/as_1.png}
    \end{figure}
    
    Consideriamo ora la seguente funzione $f(x) = \dfrac{2}{1+e^x}$. Per $x \to +\infty$ abbiamo che:
    \[\lim_{x \to +\infty} \dfrac{2}{1+e^x} = \lim_{x \to +\infty} \dfrac{2}{e^x\rbk{\frac{1}{e^x}-1}} = \lim_{x \to +\infty} -\dfrac{2}{e^x} = 0\]

    mentre per $x \to -\infty$ abbiamo che:
    \[\lim_{x \to -\infty} \dfrac{2}{1+e^x} = \lim_{y \to +\infty} \dfrac{2}{1+\frac{1}{e^y}} = \lim_{y \to +\infty} \dfrac{2}{1+0} = 2\]
    dove $y = -x$, dunque $y = 0$ e $y = 2$ sono due asintoti orizzontali della funzione.
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.75]{images/as_2.png}
    \end{figure}

    Esiste anche un terzo tipo di asintoto più complesso dei due precedenti, ossia l'\textbf{asintoto obliquo}. Intuitivamente, tale asintoto corrisponde ad una retta obliqua $g(x) = mx+q$ verso cui la funzione tende ad avvicinarsi. Tramite il concetto di limiti, ciò è esprimibile come:
    \[\lim_{x \to \pm\infty} f(x) = \lim_{x \to +\infty} mx+q\]
    Dunque, tramite le proprietà dei limiti ciò equivale a dire che: 
    \[\lim_{x \to \pm\infty} f(x) - (mx+q) = 0\]

    \begin{frameddefn}{Asintoto obliquo}
        Data la funzione $f : I \to \R$ e due valori $m,q \in \R$, diciamo che la retta $mx+q$  è un \textbf{asintoto obliquo} di $f$ se di verifica che:
        \[\lim_{x \to \pm\infty} f(x) - (mx+q) = 0\]
    \end{frameddefn}

    Consideriamo ad esempio la seguente funzione $f(x) = \dfrac{x^2}{x-1}$. Tramite una rivelazione astrale, ci viene detto che la retta $g(x) = x+1$ sia asintoto obliquo di tale funzione. Verifichiamo quindi che ciò sia vero:
    \[\lim_{x \to +\infty} \frac{x^2}{x-1} - (x+1) = \lim_{x \to +\infty} \frac{x^2-(x+1)(x-1)}{x-1} = \lim_{x \to +\infty} \frac{x^2-(x^2-1)}{x-1} = \lim_{x \to +\infty} \frac{1}{x-1} = 0\]

    \newpage

    Difatti, graficamente abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.75]{images/as_3.png}
    \end{figure}

    Ma come possiamo trovare un asintoto obliquo senza dover pregare il signore per ricevere una verità rivelata? Tramite semplici passi algebrici possiamo ricavare delle "formule". Data una retta $mx+q$, sappiamo il termine $m$ detta l'inclinazione di tale retta, mentre il termine $q$ detta il suo spostamento verticale. In particolare, la retta $g(x) = mx$ e la retta $h(x) = mx+q$ avranno la stessa identica inclinazione. Possiamo quindi ignorare il termine $q$ per poter trovare il valore di $m$:
    \[\lim_{x \to \pm\infty} f(x) - mx = 0 \implies \lim_{x \to \pm\infty} f(x) = \lim_{x \to \pm\infty} mx \]
    \[\implies \lim_{x \to \pm\infty} \frac{f(x)}{x} = \lim_{x \to \pm\infty} m \implies \lim_{x \to \pm\infty} \frac{f(x)}{x} = m\]

    A questo punto, sfruttiamo il termine $m$ trovato per calcolare il termine $q$:
    \[\lim_{x \to \pm\infty} f(x) - (mx+q) = 0\implies \lim_{x \to \pm\infty} f(x) - mx - q  = 0 \implies \lim_{x \to \pm\infty} f(x) - mx = q\]

    \begin{framedprop}{Calcolo di un asintoto obliquo}
        Data la funzione $f : I \to \R$ e due valori $m,q \in \R$, se $mx+q$ è asintoto obliquo di $f$ per $x \to +\infty$ (analogo per $x \to -\infty$) allora si ha che:
        \[\lim_{x \to \infty} \frac{f(x)}{x} = m \text{\quad \quad \quad} \lim_{x \to +\infty} f(x) - mx = q\]

    \end{framedprop}

    In particolare, notiamo che se $m = 0$ allora banalmente abbiamo che:
    \[\lim_{x \to \pm\infty} f(x) - mx = q \implies \lim_{x \to \pm\infty} f(x) = q\]
    dunque l'asintoto obliquo decade in un asintoto orizzontale. Difatti, l'asintoto orizzontale risulta essere solo un caso particolare di asintoto obliquo. Tuttavia, ciò ci permette di stabilire che essi si escludano a vicenda.

    \begin{framedobs}{}
        Data la funzione $f : I \to \R$, se esiste un asintoto orizzontale per $x \to +\infty$ allora non esiste un asintoto obliquo per $x \to +\infty$ (analogo per $x \to -\infty$).
    \end{framedobs}

    \quad

    \section{Continuità e discontinuità}

    La grande maggior parte delle funzioni reali gode di una proprietà gradevole all'occhio umano: la loro rappresentazione tramite grafico appare come un'unica linea, la quale può essere eventualmente anche curva. Tale concetto viene detto \textbf{continuità} della funzione in un intervallo.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/func6.png}

        \caption{La funzione $f(x) = x^2$ è continua su tutto $\R$}
    \end{figure}

    Formalmente, il concetto di continuità può essere definito tramite il concetto di limite: quando una funzione è continua in un intervallo $I \subseteq \R$, il valore che la funzione assume all'avvicinarsi verso $x_0$ è esattamente uguale al valore assunto in $x_0$.

    \begin{frameddefn}{Continuità}
        Data la funzione $f : I \to \R$, diciamo che $f$ è \textbf{continua} se per ogni punto di accumulazione $x_0 \in I$ si verifica che:
        \[\lim_{x \to x_0} f(x) = f(x_0)\]
    \end{frameddefn}
    
    Dalla definizione data di continuità derivano tre possibili \textbf{tipi di discontinuità}:
    \begin{enumerate}
        \item \textbf{Discontinuità di prima specie}: il limite sinistro e destro della funzione sono finiti ma diversi tra loro, ossia:
        \[\lim_{x \to x_0^+} f(x) \neq \lim_{x \to x_0^-}\]
        Quando ciò si verifica, il punto $x_0$ viene detto \textit{punto di salto}, poiché il grafico della funzione appare come spezzato in due parti 
        

        \item \textbf{Discontinuità di seconda specie}: almeno uno tra il limite sinistro o destro della funzione non esiste o è divergente, ossia:
        \[\lim_{x \to x_0^+} f(x) = \nexists, \pm \infty \text{\quad oppure \quad} \lim_{x \to x_0^-} = \nexists, \pm \infty\]

        Ogni asintoto verticale è una discontinuità di seconda specie (ma non è detto il contrario).

        \item \textbf{Discontinuità di terza specie}: il limite sinistro o destro della funzione non esiste o è divergente, ossia:
        \[\lim_{x \to x_0^+} f(x) = \lim_{x \to x_0^-} \neq f(x_0)\]

        Quando ciò si verifica, il punto $x_0$ viene detto \textit{discontinuità eliminabile}, poiché il grafico della funzione appare continuo fatta eccezione di un singolo buco al suo interno
    \end{enumerate}

    Vediamo quindi un esempio di discontinuità di prima specie. Consideriamo la funzione $f(x) = \frac{\abs{x}}{x}$ nel punto $x_0 = 0$ abbiamo che:
    \[\lim_{x \to 0^+} \frac{\abs{x}}{x} = 1  \qquad\qquad \lim_{x \to 0^-} \frac{\abs{x}}{x} = -1 \]

    Graficamente abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.75]{images/disc_1.png}
    \end{figure}

    \newpage

    Tipico esempio di discontinuità di seconda specie risulta essere la funzione $f(x) = \frac{1}{x}$ in quanto nel punto $x_0 = 0$ abbiamo che:
    \[\lim_{x \to 0^+} \frac{1}{x} = +\infty \qquad\qquad \lim_{x \to 0^-} \frac{1}{x} = -\infty \]

    Graficamente abbiamo che:

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/func3.png}
    \end{figure}

    Infine, come discontinuità di terza specie possiamo considerare la funzione $f(x) = \frac{x^2}{x}$, in quanto nel punto $x_0 = 0$ abbiamo che:
    \[\lim_{x \to 0^+} \frac{x^2}{x} = \lim_{x \to 0^+} x = 0 \qquad \qquad \lim_{x \to 0^-} \frac{x^2}{x} = \lim_{x \to 0^-} x = 0\]
    
    ma sappiamo che $0 \notin \mathrm{Dom}(f)$, dunque è impossibile che i due limiti siano uguali a $f(0)$. Graficamente abbiamo che:

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.7]{images/disc_3.png}
    \end{figure}

    \quad

    \section{Teoremi sulla continuità}

    Una volta formalizzato il concetto di continuità, risulta evidente che se la funzione sia continua in un punto $x_0$ e si verifica che $f(x_0) > 0$ allora per tutti i punti $x$ sufficientemente vicini a $x_0$ debba valere che $f(x) > 0$ (oppure $f(x) < 0$  se $f(x_0) < 0$) In altre parole, se la funzione è continua e in un punto assume valore positivo o negativo allora anche attorno a quel punto la funzione assumerà lo stesso segno.
    
    \begin{framedthm}{Teorema della permanenza del segno}
        Data la funzione $f : I \to \R$, dove $f$ è continua, e un punto $x_0 \in I$ allora si ha che:
        \begin{itemize}
            \item Se $f(x_0) > 0$ allora $\exists \delta > 0$ tale che $\forall x \in I_{\delta}(x_0)$ valga $f(x) > 0$
            \item Se $f(x_0) < 0$ allora $\exists \delta > 0$ tale che $\forall x \in I_{\delta}(x_0)$ valga $f(x) < 0$
        \end{itemize}
    \end{framedthm}

    \begin{proof}
        Se la funzione è continua in $I$, e in particolare in $x_0$, allora si ha che:
        \[\lim_{x \to x_0} f(x) = f(x_0)\]

        Per definizione di limite, dunque, ciò implica che $\forall \varepsilon > 0$ esiste $\delta > 0$ tale che:
        \[\abs{x-x_0} < \delta \implies \abs{f(x) - f(x_0)} < \varepsilon\]

        Poiché ciò vale per ogni $\varepsilon > 0$, consideriamo $\varepsilon' := \frac{\abs{f(x_0)}}{2}$. Poiché $\varepsilon > 0$, deve esistere $\delta' > '$ tale che:
        \[\abs{x-x_0} < \delta' \implies \abs{f(x) - f(x_0)} < \varepsilon' = \frac{\abs{f(x_0)}}{2}\]

        da cui otteniamo che:
        \[f(x_0) - \frac{\abs{f(x_0)}}{2} < f(x) < f(x_0) + \frac{\abs{f(x_0)}}{2}\]

        Supponiamo quindi che $f(x_0) > 0$, dunque $\abs{f(x_0)} = f(x_0)$. Otteniamo che:
        \[f(x_0) - \frac{f(x_0)}{2} < f(x) < f(x_0) + \frac{f(x_0)}{2} \implies 0 < \frac{f(x_0)}{2} < f(x) < \frac{3 f(x_0)}{2} \]

        dunque $f(x) > 0$ per ogni $x \in I_{\delta'}(x_0)$. Supponiamo invece che $f(x_0) < 0$, dunque $\abs{f(x_0)} = -f(x_0)$. Otteniamo che:
        \[f(x_0) + \frac{f(x_0)}{2} < f(x) < f(x_0) - \frac{f(x_0)}{2} \implies \frac{3f(x_0)}{2} < f(x) < \frac{f(x_0)}{2} < 0 \]

        dunque $f(x) < 0$ per ogni $x \in I_{\delta'}(x_0)$.
    \end{proof}

    Supponiamo ora che una funzione $f : I \to \R$ sia continua che che dati due punti $a,b \in I$ si verifichi che $f(a) < 0$ e che $f(b) > 0$. Per il teorema della permanenza del segno, tutti i punti $x$ attorno a  $f(a)$ saranno anch'essi negativi, mentre tutti i punti $y$ attorno a $f(b)$ saranno positivi. Applicando lo stesso ragionamento su $x$ e  $y$, il risultato viene propagato fino a che non si arriverà ad un punto $c$ la funzione dovrebbe essere sia positiva che negativa, il che è impossibile, dunque necessariamente $f(c) = 0$.

    \begin{framedthm}{Teorema di esistenza degli zeri}
        Data la funzione $f : I \to \R$, dove $f$ è continua, e due punti $a,b \in I$ tali che $f(a) < 0$ e $f(b) > 0$ oppure tali che $f(a) > 0$ e $f(b) < 0$, esiste almeno un punto $c \in [a,b]$ tale che $f(c) = 0$. 
    \end{framedthm}

    \begin{proof}
        Dimostriamo il teorema per il caso in cui $f(a) < 0$ e $f(b) > 0$ (l'altro caso è analogo). Consideriamo il seguente \textbf{algoritmo di bisezione}:
        \begin{enumerate}
            \item Poni $A_0 = a$ e $B_0 = b$.
            \item Poni $C_0 = \frac{A_0+B_0}{2}$
            \item Ripeti i seguenti passaggi finché $f(C_i) \neq 0$:
            \begin{enumerate}
                \item Se $f(C_i) > 0$ allora poni $A_{i+1} = A_{i}$ e $B_{i+1} = C_i$.
                \item Se $f(C_i) < 0$ allora poni $A_{i+1} = C_i$ e $B_{i+1} = B_i$.
                \item Poni $C_{i+1} = \frac{A_i+B_i}{2}$
            \end{enumerate}
        \end{enumerate}

        Consideriamo la prima iterazione dell'algoritmo. Se $f(C_0) > 0$ allora poniamo $A_1 = A_0 = a$ e $B_1 = C_0 = \frac{a+b}{2}$. Viceversa, se $f(C_0) < 0$ allora poniamo $A_1 = C_0 = \frac{a+b}{2}$ e $B_1 = B_0 = b$. In entrambi i casi, chiaramente abbiamo che $a = A_0 \leq A_1 \leq C_0 \leq B_1 \leq B_0 = b$ e l'intervallo $[A_1, B_1]$ ha ampiezza $\frac{\abs{b - a}}{2}$.

        Applicando la stessa logica per ogni iterazione dell'algoritmo, all'$n$-esima iterazione avremo che:
        \[a = A_0 \leq A_1 \leq \ldots \leq A_n \leq C_n \leq B_n \leq \ldots \leq B_1 \leq B_0 = b\]
        e che l'intervallo $[A_n, B_n]$ abbia ampiezza $\frac{\abs{b - a}}{2^n}$. Vengono quindi generate due successioni $A_0, A_1, A_2, \ldots$, la quale è crescente, e $B_0, B_1, B_2, \ldots$ la quale è decrescente. In particolare, abbiamo che:
        \[\lim_{n \to +\infty} A_n = ()\mathrm{sup}(\{A_n \mid n \in \N\}) \qquad\qquad \lim_{n \to +\infty} B_n = \mathrm{inf}(\{A_n \mid n \in \N\})\]

        Siano quindi $p =  \mathrm{sup}(\{A_n \mid n \in \N\})$ e $q =  \mathrm{inf}(\{A_n \mid n \in \N\})$. Abbiamo che:
        \[a = A_0 \leq A_1 \leq \ldots \leq A_n \leq p \leq C_n \leq q \leq B_n \leq \ldots \leq B_1 \leq B_0 = b\]
        dunque per ogni $n \in \N$ si verifica che $\abs{p-q} < \abs{B_n-A_n} = frac{\abs{b - a}}{2^n}$, cosa che è possibile solo se $p-q = 0$, dunque $p = q$. Concludiamo quindi che:
        \[\lim_{n \to +\infty} A_n = \lim_{n \to +\infty} B_n\]
        
        Sia quindi $c = p$. Poiché $A_n \to c$ per $n \to +\infty$, per il teorema ponte e per continuità di $f$ abbiamo che:
        \[\lim_{n \to +\infty} f(A_n) = \lim_{x \to c} f(x) = f(c)\]

        Inoltre poiché per ogni $n \in \N$ vale che $f(A_n) \leq 0$ e che $f(B_n) \geq 0$, abbiamo che: 
        \[0 \geq \lim_{n \to +\infty} f(A_n) = f(c) = \lim_{n \to +\infty} f(B_n) \geq 0\]
        concludendo che $f(c) = 0$
        
    \end{proof}

    L'algoritmo di bisezione permette quindi di trovare gli zeri di una funzione. Tuttavia, è importante precisare che non sempre l'algoritmo possa \textbf{terminare} in un numero finito di passi. Ad esempio, se $x_0 \in \R - \Q$ è uno zero della funzione allora sarà impossibile per l'algoritmo raggiungere esattamente il valore $x_0$. In questi casi, l'algoritmo di bisezione viene utilizzato sostituendo la condizione $f(C_i) \neq 0$ con la condizione $\abs{f(C_i)} < \varepsilon$ dove $\varepsilon$ è un numero reale sufficientemente piccolo affinché il risultato restituito dall'algoritmo sia una buona approssimazione dello zero della funzione.

    \begin{figure}[H]
        \centering

        \includegraphics[scale=0.6]{images/bisection.png}

        \textit{Esempio di esecuzione dell'algoritmo di bisezione}
    \end{figure}

    \newpage

    Infine, tramite il teorema dell'esistenza degli zeri possiamo ottenere altri due risultati interessante, i quali, sebben apparentemente scontati,  costituiscono due dei principali risultati dell'analisi matematica.

    \begin{framedthm}{Teorema dei valori intermedi}
        Data una funzione $f : I \to \R$, dove $f$ è continua, ed un intervallo $[a,b] \subseteq I$, la funzione assume tutti i valori tra $f(a)$ e $f(b)$, ossia:
        \[\forall y \in [f(a), f(b)] \; \exists x \in I \text{ tale che } y = f(y)\]

        \textit{Nota}: utilizziamo l'intervallo $[f(a), f(b)]$ in quanto assumiamo che $f(a) \leq f(b)$, il teorema vale anche per l'intervallo $[f(b), f(a)]$ con $f(b) \leq f(a)$.
    \end{framedthm}

    \begin{proof}
        Assumiamo che $f(a) \leq f(b)$ (dimostrazione analoga se $f(b) \leq f(a)$). Per ogni $y \in [f(a), f(b)]$ definiamo la funzione $g_y(x) = f(x) - y$. Poiché $f$ è continua, ne segue chiaramente che anche ogni $g_y$ sia continua. Inoltre, dato che $f(a) \leq y \leq f(b)$:
        \begin{itemize}
            \item Se $y = f(a)$ allora $g_y(a) = f(a) - f(a) = 0$
            \item Se $y = f(b)$ allora $g_y(b) = f(b) - f(b) = 0$
            \item Se $f(a) < y < f(b)$ allora $g_y(a) = f(a) - y < 0$ mentre $g_y(b) = f(b) - y > 0$, dunque per il teorema dell'esistenza degli zeri ne segue che $\exists c \in [a,b]$ tale che $g_y(c) = 0$.
        \end{itemize}

        In ognuno dei tre casi possibili, per ogni $y \in [f(a), f(b)]$ esiste $x \in [a,b]$ tale che $g_y(x) = f(x) - y = 0$, ma allora ciò implica che $f(x) = y$.
    \end{proof}

    \begin{framedthm}{Teorema di Weierstrass}
        Data una funzione $f : I \to \R$, dove $f$ è continua, ed un intervallo $[a,b] \subseteq I$, esistono due valori $x_{min}, x_{max} \in [a,b]$, detti rispettivamente \textbf{minimo relativo} e \textbf{massimo relativo} in $[a,b]$, tali che $\forall x \in [a,b]$ si abbia che $f(x_{min}) \leq f(x) \leq f(x_{max})$. 
    \end{framedthm}

    \begin{proof}
        Sia $S$ la restrizione di $\mathrm{Im}(f)$ su $[a,b]$, ossia $S = \{f(x) \mid x \in [a,b]\}$. Poiché tale insieme contiene un numero finito di elementi, esisteranno necessariamente almeno un maggiorante ed almeno un minorante. Siano quindi $M = \mathrm{sup}(S)$ e $m = \mathrm{inf}(S)$.
        
        Per ogni $n \in \N$, consideriamo $M - \frac{1}{n}$. Poiché per definizione di estremo superiore $M$ è il minimo maggiorante di $S$, ne segue che $\exists f(x) \in S$ tale che $M-\frac{1}{n} < f(x)$. Sia quindi $a_n : \N \to \R$ la successione tale che $a_1, a_2, \ldots$ siano dei valori per cui $M - \frac{1}{n} < f(a_n)$. Abbiamo quindi che:
        \[M-\frac{1}{n} < f(a_n) \leq M \implies \lim_{n \to +\infty} M-\frac{1}{n} < \lim_{n \to +\infty} f(a_n) \leq \lim_{n \to +\infty} M \implies \lim_{n \to +\infty} f(a_n) = M\]

        Inoltre, poiché $M-\frac{1}{n} < f(a_n) \leq M$ sappiamo che la successione $a_n$ risulta quindi essere limitata. Dunque, per il teorema di Bolzano-Weierstrass, deve esistere una sotto-successione $a_{b_k}$ che converga ad un certo valore $x_1 \in [a,b]$ per $k \to \infty$. Per il teorema ponte e per continuità di $f$ abbiamo quindi che:
        \[\lim_{k \to +\infty} f(a_{b_k}) = \lim_{x \to x_1} f(x) = f(x_1)\]
        
        Infine, poiché $a_{b_k}$ è una sotto-successione di $a_n$, esse devono necessariamente convergere allo stesso limite, concludendo che $M = f(x_1)$ e quindi che $\forall x \in [a,b]$ valga che $f(x) \leq f(x_1)$. Tramite la successione $b_n : \N \to \R$ tale che $b_1, b_2, \ldots$ siano dei valori per cui $f(b_n) < M + \frac{1}{n}$, procedendo analogamente arriviamo a dimostrare che $\exists x_2 \in [a,b]$ tale che $\forall x \in [a,b]$ valga che $f(x_2) \leq f(x)$.

    \end{proof}

    \begin{framedcor}{}
        Data una funzione $f : I \to \R$, dove $f$ è continua e $I$ non è illimitato, la funzione assume tutti i valori tra $f(x_{min})$ e $f(x_{max})$, dove $x_{min}, x_{max}$ sono rispettivamente il minimo e il massimo relativo di $f$ in $I$

        \textit{(segue dai due teoremi precedenti)}
    \end{framedcor}

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.75]{images/min_max.png}
    \end{figure}

    \newpage

    \section{Esercizi svolti}

    \begin{framedprob}{}
        Dimostrare tramite la definizione topologica di limite che:
        \[\lim_{x \to 1} \frac{1}{(x-1)^2} = +\infty\]
    \end{framedprob}


    \textit{Soluzione:}

    Consideriamo un valore $\delta > 0$ tale
    \[0 < \abs{x-1} < \delta\]

    Osserviamo come:
    \[\abs{x-1} < \delta \implies \sqrt{(x-1)^2} = \abs{x-1} < \delta \implies (x-1)^2 < \delta^2 \implies \frac{1}{(x-1)^2} > \frac{1}{\delta^2}\]
        
    Supponiamo quindi che $\delta < 1$. Notiamo che:
    \[\abs{x-1} < \delta < 1 \implies \frac{1}{(x-1)^2} > \frac{1}{\delta^2} > 1\]

    Di conseguenza, per i valori $M \leq 1$ è sufficiente considerare un qualsiasi valore $\delta < 1$ affinché si abbia che:
    \[\abs{x-1} < \delta < 1 \implies \frac{1}{(x-1)^2} > \frac{1}{\delta^2} > 1 \geq M\]

    Consideriamo ora i valori $M > 1$. Ponendo $\delta = \frac{1}{\sqrt{M}}$, notiamo che $\delta < 1$. Ma allora, tramite il risultato precedente abbiamo che:
    \[\abs{x-1} < \delta < 1 \implies \frac{1}{(x-1)^2} > \frac{1}{\delta^2} = M\]

    Ricapitolando, per ogni $M$ tale che $M \leq 1$ possiamo scegliere un qualsiasi valore $\delta < 1$ affinché valga la condizione, mentre per ogni $M$ tale che $M > 1$ possiamo porre $\delta = \frac{1}{\sqrt{M}}$ affinché la condizione sia soddisfatta, concludendo che:
    \[\lim_{x \to 1} \frac{1}{(x-1)^2} = +\infty\]

    \newpage

    \begin{framedprob}{}
        Dimostrare tramite la definizione topologica di limite che:
        \[\lim_{x \to -\infty} e^x = 0\]
    \end{framedprob}

    \textit{Soluzione:}

    Notiamo facilmente come:
    \[\abs{e^x - 0} < \varepsilon \iff e^x < \varepsilon \iff x < \ln \varepsilon\]

    Di conseguenza, $\forall \varepsilon > 0$ possiamo porre $N = \ln \varepsilon$ affinché si abbia che:
    \[x < N = \ln \varepsilon \implies \abs{e^x - 0} < \varepsilon\]

    Dunque concludiamo che:
    \[\lim_{x \to -\infty} e^x = 0\]

    \begin{framedprob}{}
        Valutare i seguenti limiti:
        \begin{enumerate}
            \item $\lim\limits_{x \to +\infty} x^4+12x^2-6x$
            \item $\lim\limits_{x \to +\infty} \dfrac{x^7+x^4+3}{2x^6+1}$
            \item $\lim\limits_{x \to 0} \dfrac{x^2+1}{x+7}$
            \item $\lim\limits_{x \to 0} \dfrac{x^5+2x}{x^4+3x^2+x}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzioni:}

    \begin{enumerate}
        \item Sostituendo $x \to +\infty$, otteniamo la forma indeterminata $\infty- \infty$. Tuttavia, raggruppando abbiamo che:
        \[\lim\limits_{x \to +\infty} x^4+12x^2-6x = \lim\limits_{x \to +\infty} x^4\rbk{1+\frac{12}{x^2}-\frac{6}{x^3}} = \lim\limits_{x \to +\infty} x^4 (1 + o(1) - o(1)) = +\infty\]

        \item Sostituendo $x \to +\infty$, otteniamo la forma indeterminata $\frac{\infty}{\infty}$. Tuttavia, raggruppando abbiamo che:
        \[\lim_{x \to +\infty} \frac{x^7+x^4+3}{2x^6+1} = \lim_{x \to +\infty} \frac{x^7 \rbk{1+\frac{1}{x^3}-\frac{3}{x^7}}}{x^6 \rbk{2+\frac{1}{x^6}}} = \lim_{x \to +\infty} \frac{x^7 \rbk{1+o(1) + o(1)}}{x^6 \rbk{2+o(1)}} = \]
        \[\lim_{x \to +\infty} \frac{x^7}{x^6} = \lim_{x \to +\infty} x= +\infty\]

        \item Sostituendo $x \to 0$ riusciamo a valutare direttamente il limite:
        \[\lim\limits_{x \to 0} \dfrac{x^2+1}{x+7} = \lim\limits_{x \to 0} \frac{0^2+1}{0+7} = \frac{1}{7}\]

        \item Sostituendo $x \to 0$, otteniamo la forma indeterminata $\frac{0}{0}$. Difatti, il valore 0 risulta essere radice di entrambi polinomi. Raggruppando abbiamo quindi che:
        \[\lim\limits_{x \to 0} \dfrac{x^5+2x}{x^4+3x^2+x} = \lim\limits_{x \to 0} \dfrac{x(x^4+2)}{x(x^3+3x+1)} = \lim\limits_{x \to 0} \dfrac{x^4+2}{x^3+3x+1} = \frac{0+2}{0+0+1} = 2\]
    \end{enumerate}

    \begin{framedprob}{}
        Valutare i seguenti limiti:
        \begin{enumerate}
            \item $\lim\limits_{x \to 1^-} \dfrac{x^2}{x-1}$
            \item $\lim\limits_{x \to 2^+} \dfrac{x-3}{x^2-6x+8}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}

    \begin{enumerate}
        \item Sostituendo $x \to 1^-$, notiamo che:
        \[\lim_{x \to 1^+} \dfrac{x^2}{x-1} = \lim_{x \to 1^+} \dfrac{(1^-)^2}{1^--1} = \lim_{x \to 1^+} \dfrac{1^+}{0^-} = -\infty\]

        \item Sostituendo $x \to 2^+$, notiamo che:
        \[\lim\limits_{x \to 2^+} \dfrac{x-3}{x^2-6x+8} = \lim\limits_{x \to 2^+} \dfrac{2^+-3}{(2^+)^2-6(2^+)+8} = \lim\limits_{x \to 2^+} \dfrac{-1^+}{4^+-12^++8} = \lim\limits_{x \to 2^+} \dfrac{-1^+}{12^+-12^+}\]
        Poiché la notazione $\alpha^+$ indica che il numero sia in realtà $\alpha + \varepsilon$ per un certo $\varepsilon \in \R^+$ molto piccolo, non possiamo determinare bene il risultato del limite: entrambi i due valori $12^+$ corrispondono a $12+\varepsilon_1$ e $12+\varepsilon_2$, ma quale tra $\varepsilon_1, \varepsilon_2$ è più grande? Il risultato della sottrazione sarebbe $0^+$ o $0^-$?

        Dobbiamo quindi cercare un altro approccio. Notiamo che $2$ sia radice di $x^2-6x+8$. Difatti, abbiamo che $x^2-6x+8 = (x-2)(x-4)$. Proviamo quindi a valutare nuovamente il limite scomponendo prima il denominatore:
        \[\lim\limits_{x \to 2^+} \dfrac{x-3}{x^2-6x+8} = \lim\limits_{x \to 2^+} \dfrac{x-3}{(x-2)(x-4)} = \lim_{x \to 2^+} \frac{2^+-3}{(2^+-2)(2^+-4)} = \lim_{x \to 2^+} \frac{-1^+}{(0^+)(-2^+)}\]

        A questo punto, notiamo che $(0^+)(-2^+) = 0^-$ poiché stiamo moltiplicando $0^+$ per un valore negativo. Analogamente, abbiamo che $\frac{-1^+}{0^-} = \frac{1}{0^+}$. Per tanto, concludiamo che:
        \[\lim\limits_{x \to 2^+} \dfrac{x-3}{x^2-6x+8} = \lim_{x \to 2^+} \frac{-1^+}{(0^+)(-2^+)} = \lim_{x \to 2^+} \frac{-1^+}{0^-} = \lim_{x \to 2^+} \frac{1}{0^+} = +\infty\]

    \end{enumerate}


    \begin{framedprob}{}
        Valutare i seguenti limiti:
        \begin{enumerate}
            \item $\lim\limits_{x \to 0} \dfrac{x^3+3x^2+4x}{x^5+2x^2}$
            \item $\lim\limits_{x \to +\infty} e^{\frac{x+1}{2x-4}}$
            \item $\lim\limits_{x \to +\infty} \sqrt{x^2 + 4x+6} + \sqrt{x^2 +2}$
            \item $\lim\limits_{x \to +\infty} \sqrt{x^2 + 4x+6} - \sqrt{x^2 +2}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}
    \begin{enumerate}
        
        \item Sostituendo $x \to 0$, otteniamo la forma indeterminata $\frac{0}{0}$. Difatti, il valore 0 risulta essere radice di entrambi polinomi. Raggruppando abbiamo quindi che:
        \[\lim\limits_{x \to 0} \dfrac{x^3+3x^2+4x}{x^5+2x^2} = \lim\limits_{x \to 0} \dfrac{x(x^2+3x+4)}{x^2(x^3+2)} = \lim\limits_{x \to 0} \dfrac{x^2+3x+4}{x(x^3+2)} = \lim\limits_{x \to 0}\frac{4}{x} = \nexists\]

        \item Sostituendo $x \to +\infty$, otteniamo la forma indeterminata $\frac{\infty}{\infty}$. Tuttavia, notiamo che:
        \[\lim_{x \to +\infty} \frac{x+1}{2x-4} = \lim_{x \to +\infty} \frac{x\rbk{1+\frac{1}{x}}}{x\rbk{2-\frac{4}{x}}} = \lim_{x \to +\infty} \frac{1}{2} = \frac{1}{2}\]

        Ponendo $y = \frac{x+1}{2x-4}$, dunque, abbiamo che:
        \[\lim\limits_{x \to +\infty} e^{\frac{x+1}{2x-4}} = \lim_{y \to \frac{1}{2}} e^y = \sqrt{e}\]

        \item Raggruppando internamente alle radici abbiamo che:
        \[\lim\limits_{x \to +\infty} \sqrt{x^2 + 4x+6} + \sqrt{x^2 +2} = \lim\limits_{x \to +\infty} \sqrt{x^2 \rbk{1+ \frac{4}{x}+\frac{6}{x^2}}} + \sqrt{x^2 \rbk{1+\frac{2}{x^2}}} = \]
        \[\lim\limits_{x \to +\infty} \sqrt{x^2} + \sqrt{x^2} = \lim\limits_{x \to +\infty} \abs{x} + \abs{x} = +\infty\]


        \item Procedendo come per l'esercizio precedente abbiamo che:
        \[\lim\limits_{x \to +\infty} \sqrt{x^2 + 4x+6} - \sqrt{x^2 +2} = \lim\limits_{x \to +\infty} \sqrt{x^2 \rbk{1+ \frac{4}{x}+\frac{6}{x^2}}} - \sqrt{x^2 \rbk{1+\frac{2}{x^2}}} = \]
        \[\lim\limits_{x \to +\infty} \sqrt{x^2} - \sqrt{x^2} = \lim\limits_{x \to +\infty} \abs{x} - \abs{x} = \infty - \infty\]

        ottenendo quindi una forma indeterminata. Per risolvere il problema, possiamo sfruttare la regola della differenza tra quadrati, ossia $(a-b)(a+b) = a^2-b^2$:
        \[\lim\limits_{x \to +\infty} \sqrt{x^2 + 4x+6} - \sqrt{x^2 +2} = \lim\limits_{x \to +\infty} (\sqrt{x^2 + 4x+6} - \sqrt{x^2 +2}) \frac{\sqrt{x^2 + 4x+6} + \sqrt{x^2 +2}}{\sqrt{x^2 + 4x+6} + \sqrt{x^2 +2}} =\]
        \[\lim\limits_{x \to +\infty} \frac{(\sqrt{x^2 + 4x+6})^2 - (\sqrt{x^2 +2})^2}{\sqrt{x^2 + 4x+6} + \sqrt{x^2 +2}} = \lim\limits_{x \to +\infty} \frac{x^2 + 4x+6 - x^2 +2}{\sqrt{x^2 + 4x+6} + \sqrt{x^2 +2}}\]
        \[= \lim\limits_{x \to +\infty} \frac{4x+8}{\sqrt{x^2 + 4x+6} + \sqrt{x^2 +2}} = \lim\limits_{x \to +\infty} \frac{x\rbk{4+\frac{8}{x}}}{\abs{x} - \abs{x}} = \lim\limits_{x \to +\infty} \frac{4x}{2x} = 2\]
    \end{enumerate}

    \begin{framedprob}{}
        Valutare i seguenti limiti:
        \begin{enumerate}
            \item $\lim\limits_{x \to 0^+} x \ln x$
            \item $\lim\limits_{x \to +\infty} \dfrac{e^{2x} + x^6 + \log_2(x)}{\ln^3(x)+x^3}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}

    \begin{enumerate}
        \item Sostituendo direttamente $x \to 0^+$ otteniamo la forma indeterminata $0 \cdot \infty$. Ponendo $y = \ln x$ abbiamo che:
        \[\lim\limits_{x \to 0^+} x \ln x = \lim_{y \to -\infty} e^y y\]

        Ponendo $z = -y$, infine, abbiamo che:
        \[\lim\limits_{x \to 0^+} x \ln x = \lim_{y \to -\infty} e^y y = \lim_{z \to +\infty} e^{-z} (-z) = \lim_{z \to +\infty} -\frac{z}{e^z} = 0\]

        \item Sostituendo direttamente $x \to +\infty$ otteniamo la forma indeterminata $\frac{\infty}{\infty}$. Raggruppando abbiamo che:
        \[\lim\limits_{x \to +\infty} \frac{e^{2x} + x^6 + \log_2(x)}{\ln^3(x)+x^3} = \lim\limits_{x \to +\infty} \frac{e^{2x} \rbk{1+ \frac{x^6}{e^{2x}} + \frac{\log_2(x)}{e^{2x}}}}{x^3\rbk{1+\frac{\ln^3(x)}{x^3}}} = \]
        \[\lim\limits_{x \to +\infty} \frac{e^{2x} \rbk{1+ o(1) + o(1)}}{x^3\rbk{1+o(1)}} = \lim\limits_{x \to +\infty} \frac{e^{2x}}{x^3} = +\infty\]

    \end{enumerate}

    \newpage

    \begin{framedprob}{}
        Valutare i seguenti limiti:
        \begin{enumerate}
            \item $\lim\limits_{x \to 0} \dfrac{1-e^{x^2}}{\sin(x^2)}$
            \item $\lim\limits_{x \to 0} \dfrac{\cos(x^2) - 1}{x^2(1-\cos x)}$
            \item $\lim\limits_{x \to +\infty} x^3 \ln (1+e^{-6x})$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzione:}

    \begin{enumerate}
        \item Ponendo $y = x^2$ e ricordando i principali limiti notevoli notiamo che:
        \[\begin{split}
            \lim\limits_{x \to 0} \frac{1-e^{x^2}}{\sin(x^2)} &= \lim\limits_{y \to 0} \frac{1-e^{y}}{\sin y}\\
            &= \lim\limits_{y \to 0} \frac{1-e^{y}}{\sin y} \cdot \frac{y}{y} \\
            &= \lim\limits_{y \to 0} \frac{1-e^{y}}{y} \cdot \frac{y}{\sin y} \\
            &= \lim\limits_{y \to 0} \frac{1-e^{y}}{y} \cdot 1 \\
            &= \lim\limits_{y \to 0} \frac{-(-(1-e^y))}{y} \\
            &= \lim\limits_{y \to 0} -\frac{e^{y}-1}{y} \\
            &= -1 
        \end{split}\]

        \item Ponendo $y = x^2$ e ricordando i principali limiti notevoli notiamo che:
        \[\begin{split}
            \lim\limits_{x \to 0} \dfrac{\cos(x^2) - 1}{x^2(1-\cos x)} &= \lim\limits_{x \to 0} -\dfrac{1-\cos(x^2)}{x^2(1-\cos x)} \\
           &= \lim\limits_{x \to 0} \dfrac{\cos(x^2) - 1}{x^2(1-\cos x)} \cdot \frac{x^2}{x^2} \\
           &= \lim\limits_{x \to 0} \dfrac{x^2}{1-\cos x} \cdot \frac{\cos(x^2) - 1}{x^4} \\
           &= \lim\limits_{x \to 0} 2 \cdot \frac{\cos(x^2) - 1}{x^4} \\
           &= \lim\limits_{y \to 0} 2 \cdot \frac{\cos(y) - 1}{y^2} \\
           &= \lim\limits_{y \to 0} (-2) \cdot \frac{1-\cos(y)}{y^2} \\
           &= \lim\limits_{y \to 0} (-2) \cdot \frac{1}{2} \\
           &= -1
        \end{split}\]

        \item Ponendo $y = e^{-6x}$ e ricordando i principali limiti notevoli notiamo che:
        \[\begin{split}
            \lim\limits_{x \to +\infty} x^3 \ln (1+e^{-6x}) &= \lim\limits_{y \to 0} \rbk{-\frac{\ln y}{6}}^3 \ln (1+y) \\
            &= \lim\limits_{y \to 0} \rbk{-\frac{\ln y}{6}}^3 \ln (1+y) \cdot \frac{y}{y} \\
            &= \lim\limits_{y \to 0} y\rbk{-\frac{\ln y}{6}}^3 \cdot \frac{\ln (1+y)}{y} \\
            &= \lim\limits_{y \to 0} y\rbk{-\frac{\ln y}{6}}^3 \cdot 1 \\
            &= \lim\limits_{x \to +\infty} e^{-6x}\rbk{-\frac{\ln \rbk{e^{-6x}}}{6}}^3 \\
            &= \lim\limits_{x \to +\infty} \frac{x^3}{e^{6x}} \\
            &= 0
        \end{split}\]

    \end{enumerate}

    \begin{framedprob}{}
        Dimostrare che il seguente limite non esiste:
        \[\lim_{x \to +\infty} x\cos x\]
    \end{framedprob}

    \textit{Soluzione:}

    Consideriamo le seguenti due successioni $a_n = 2n\pi$ e $b_n = \pi + 2n\pi$. Notiamo che per $n \to +\infty$ si abbia che $a_n, b_n \to +\infty$. Notiamo che:
    \[\lim_{n \to +\infty}  2n\pi \cos \rbk{2n\pi} = \lim_{n \to +\infty}  2n\pi \cos \rbk{0} = \lim_{n \to +\infty}  2n\pi = +\infty\]
    mentre:
    \[\lim_{n \to +\infty}  (\pi+2n\pi) \cos \rbk{\pi+2n\pi} = \lim_{n \to +\infty}  (\pi + 2n\pi) \cos \rbk{\pi} =  \lim_{n \to +\infty}  -\pi-2n\pi = -\infty\]

    dunque per il teorema ponte ne segue necessariamente che
    \[\lim_{x \to +\infty} x\cos x = \nexists\]

    \newpage


    \begin{framedprob}{}
        Determinare gli asintoti delle seguenti funzioni:
        \begin{enumerate}
            \item $f(x) = xe^x$
            \item $f(x) = \dfrac{x^3}{x^2-1}$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzioni:}

    \begin{enumerate}
        \item Il campo di esistenza della funzione $f(x)$ risulta essere $\R$, dunque non abbiamo asintoti verticali da studiare. Procediamo quindi con gli asintoti orizzontali. Per $x \to +\infty$, facilmente abbiamo che:
        \[\lim_{x \to +\infty} xe^x = +\infty\]
        per $x \to -\infty$, invece, ponendo $y = -x$ abbiamo che:
        \[\lim_{x \to -\infty} xe^x = \lim_{y = +\infty} -\frac{y}{e^y} = 0\]
        Per tanto, concludiamo che $f(x)$ abbia un asintoto orizzontale $y = 0$ per $x \to -\infty$. Poiché esiste tale asintoto orizzontale, per $x \to -\infty$ siamo sicuri che non esista un asintoto obliquo. Per $x \to +\infty$, invece, non esiste un asintoto orizzontale, dunque quindi la presenza di un asintoto obliquo per $x \to +\infty$:
        \[\lim_{x \to +\infty} \frac{xe^x}{x} = \lim_{x \to +\infty} e^x = +\infty\]
        dunque non esiste un asintoto obliquo per $x \to +\infty$. Quindi, in $f(x)$ esiste un unico asintoto $y = 0$.

        \item Notiamo che $f(x) = \dfrac{x^3}{x^2-1} = \dfrac{x^3}{(x+1)(x-1)}$, dunque il campo di esistenza della funzione $f(x)$ risulta essere $\R-\{1,-1\}$. Studiamo quindi iò limite per $x \to 1^+$:
        \[\lim_{x \to 1^+} \dfrac{x^3}{(x+1)(x-1)} = \lim_{x \to 1^+} \dfrac{(1^+)^3}{(1^++1)(1^+-1)} = \lim_{x \to 1^+} \dfrac{1^+}{(2^+)(0^+)} = +\infty\]

        dunque $x = 1$ è un asintoto verticale di $f(x)$. Evitiamo di studiare il limite per $x \to 1^-$ in quanto avremmo due opzioni: il limite tende a $\pm \infty$ oppure ad un valore $\ell$, ma nel primo caso otterremmo di nuovo che $x = 0$ sia asintoto verticale, mentre nel secondo caso non concluderemmo nulla. Per tanto, non otterremmo alcuna nuova informazione in entrambi i casi. Vediamo quindi cosa succede per $x \to (-1)^+$:
        \[\lim_{x \to (-1)^+} \dfrac{x^3}{(x+1)(x-1)} = \lim_{x \to (-1)^+} \dfrac{((-1^)+)^3}{((-1)^++1)((-1)^+-1)} = \lim_{x \to (-1)^+} \dfrac{(-1^)+}{(0^+)(-2^+)} = +\infty\]
        dunque $x = -1$ è un asintoto verticale di $f(x)$.

        \newpage
        
        Procediamo quindi con gli asintoti orizzontali. Per $x \to +\infty$, facilmente abbiamo che:
        \[\lim_{x \to +\infty} \dfrac{x^3}{x^2-1} = +\infty\]
        mentre per $x \to -\infty$ abbiamo che:
        \[\lim_{x \to -\infty} \dfrac{x^3}{x^2-1} = -\infty\]

        Per tanto, $f(x)$ non presenza asintoti orizzontali. Verifichiamo quindi l'esistenza di un asintoto obliquo per $x \to +\infty$:
        \[\lim_{x \to +\infty} \dfrac{x^3}{(x^2-1)x} = \lim_{x \to +\infty} \dfrac{x^3}{x^3-x} = 1\]

        dunque $m = 1$ e:
        \[\lim_{x \to +\infty} \dfrac{x^3}{x^2-1} - x = \lim_{x \to +\infty} \dfrac{x^3-(x^2-1)x}{x^3-x} = 1\]
        dunque $y = x+1$ risulta essere asintoto obliquo. Analogamente, l'esistenza di un asintoto obliquo per $x \to -\infty$:
        \[\lim_{x \to -\infty} \dfrac{x^3}{(x^2-1)x} = \lim_{x \to -\infty} \dfrac{x^3}{x^3-x} = 1\]

        dunque $m = 1$ e:
        \[\lim_{x \to -\infty} \dfrac{x^3}{x^2-1} - x = \lim_{x \to -\infty} \dfrac{x^3-(x^2-1)x}{x^3-x} = 1\]
        dunque otteniamo ancora una volta l'asintoto obliquo $y = x+1$.
    \end{enumerate}

    \newpage

    \begin{framedprob}{}
        Data la funzione $f(x) = x^5 - x^2 + 5$, approssimare lo zero della funzione situato nell'intervallo $[-2,-1]$ con un punto $x_0$ tale che $\abs{f(x_0)} < 0.1$.
    \end{framedprob}

    \textit{Soluzione:}

    Notiamo che $f(-2) = -31 < 0$ e che $f(-1) = 3 > 0$, dunque possiamo applicare l'algoritmo di bisezione:
    \begin{enumerate}
        \item Poniamo $A_0 = -2$ e $B_0 = -1$, dunque $C_1 = \frac{A_0+B_0}{2} = -\frac{3}{2}$
        \item Poiché $f(C_1) = -\frac{155}{32} = -4.843750$, poniamo $A_1 = -\frac{3}{2}$ e $B_1 = -1$, dunque $C_2 = \frac{A_1+B_1}{2} = -\frac{5}{4}$
        \item Poiché $f(C_2) = -\frac{395}{1024} = 0.385742$, poniamo $A_2 = -\frac{3}{2}$ e $B_2 = -\frac{5}{4}$, dunque $C_3 = \frac{A_2+B_2}{2} = -\frac{11}{8}$
        \item Poiché $f(C_3) = -\frac{59163}{32768} = -1.805511$, poniamo $A_3 = -\frac{11}{8}$ e $B_3 = -\frac{5}{4}$, dunque $C_4 = \frac{A_3+B_3}{2} = -\frac{21}{16}$
        \item Poiché $f(C_4) = -\frac{647557}{1048576} \approx -0.617558$, poniamo $A_4 = -\frac{21}{16}$ e $B_4 = -\frac{5}{4}$, dunque $C_3 = \frac{A_4+B_4}{2} = -\frac{41}{32}$
        \item Poiché $f(C_4) = -\frac{3167049}{33554432} \approx -0.094385$, abbiamo che $\abs{f(C_4)} < 0.1$
    \end{enumerate}
    dunque, concludiamo che $x_0 = -\frac{41}{32}$.


    \addtocontents{toc}{\protect\newpage}
    \chapter{Derivate di funzioni}

    \section{Intuizione e definizione}

    Consideriamo due punti $(x_0,y_0)$ e $(x_1,y_1)$. Un banale risultato ricavabile tramite la geometria elementare ci dice che esiste un'unica retta passante tra tali punti e che la sua equazione è dettata da:
    \[r(x) = y_0 + \frac{y_1-y_0}{x_1-x_0}(x-x_0)\]
    Consideriamo ora una funzione $f(x)$. Dati due punti $A = (x_0,f(x_0))$ e $B = (x_1,f(x_1))$, la retta passante per essi è quindi data da:
    \[r(x) = f(x_0) + \frac{f(x_1)-f(x_0)}{x_1-x_0}(x-x_0)\]

    Il termine $\frac{f(x_1)-f(x_0)}{x_1-x_0}$, detto \textbf{rapporto incrementale} tra $A$ e $B$, definisce la pendenza di tale retta.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/der_1.png}
    \end{figure}

    Consideriamo ora il punto $C = \rbk{x_0 + \frac{x_1-x_0}{2}, f(x_0 + \frac{x_1-x_0}{2})}$. La retta passante tra $A$ e $C$ corrisponderà a:
    \[r'(x) = f(x_0) + \frac{f(x_0 + \frac{x_1-x_0}{2})-f(x_0)}{x_0 + \frac{x_1-x_0}{2}-x_0}(x-x_0)\]

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{images/der_2.png}
    \end{figure}

    Sia quindi $C_n = \rbk{x_0 + \frac{x_1-x_0}{2^n}, f(x_0 + \frac{x_1-x_0}{2^n})}$ per ogni $n \in \N$. Notiamo che per $n \to +\infty$, il punto $C_n$ tende a diventare esattamente uguale al punto $A$. Di conseguenza, la retta passante tra $A$ e $C_n$ tende a diventare la retta tangente ad $A$ su $f$:
    \[t(x) = \lim_{n \to +\infty} f(x_0) + \frac{f(x_0 + \frac{x_1-x_0}{2^n})-f(x_0)}{x_0 + \frac{x_1-x_0}{2^n}-x_0}(x-x_0)\]

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/der_3.png}

        \textit{In rosa la retta tangente ad $A$ su $f$}
    \end{figure}

    Chiaramente, per $n \to +\infty$ abbiamo che $\frac{x_1-x_0}{2^n} \to 0$. Passando tramite il teorema ponte, in forma più generale possiamo dire che:
    \[t(x) = \lim_{h \to 0} f(x_0) + \frac{f(x_0 + h)-f(x_0)}{x_0 + h-x_0}(x-x_0) = \lim_{h \to 0} f(x_0) + \frac{f(x_0 + h)-f(x_0)}{h}(x-x_0)\]

    \begin{frameddefn}{Derivata}
        Data la funzione $f : I \to \R$ e un punto di accumulazione $x_0 \in I$, diciamo che $f$ è \textbf{derivabile} in $x_0$ se il seguente limite:
        \[\lim_{h \to 0} \frac{f(x_0 + h)-f(x_0)}{h}\]
        esiste ed è finito. Inoltre, definiamo la \textbf{derivata} di $f$ in $I$ come la funzione:
        \[f'(x) := \lim_{h \to 0} \frac{f(x + h)-f(x)}{h}\]
        dove $\mathrm{Dom}(f') = \{x \in I \mid f \text{ è derivabile in } x\}$
    \end{frameddefn}

    In generale, diciamo che la \textbf{miglior approssimazione lineare} di $f$ in $x_0$ è una retta $r(x) = f(x_0) + m(x-x_0)$ che soddisfa la seguente proprietà:
    \[\lim_{x \to x_0} \frac{f(x) - r(x)}{x-x_0} = 0\]
    
    Notiamo tuttavia che:
    \[\begin{split}
        0 &= \lim_{x \to x_0} \frac{f(x) - r(x)}{x-x_0} \\
        &= \lim_{x \to x_0} \frac{f(x) - f(x_0) - m(x-x_0)}{x-x_0}\\
        &= \lim_{x \to x_0} \frac{f(x) - f(x_0)}{x-x_0} - m\\
        &= \lim_{h \to 0} \frac{f(x_0+h) - f(x_0)}{h} - m\\
        &= f'(x_0) - m\\
    \end{split}\]
    dove $h = x-x_0$, dunque otteniamo che $f'(x_0) = m$. In altre parole, la retta tangente $t(x) = f(x_0) + f'(x_0)(x-x_0)$ è l'unica miglior approssimazione lineare di $f$ in $x_0$. 

    \newpage

    \begin{framedthm}{Derivabilità e continuità}
        Data la funzione $f : I \to \R$, se $f$ è derivabile in $I$ allora è continua in $I$  
    \end{framedthm}

    \begin{proof}
        Dobbiamo mostrare che se $f$ è derivabile in $I$ allora $\forall x_0 \in I$ vale che:
        \[\lim_{x \to x_0} f(x) = f(x_0) \iff \lim_{x \to x_0} f(x) - f(x_0) = 0\]

        Notiamo quindi che:
        \[\lim_{x \to x_0} f(x) - f(x_0) = \lim_{x \to x_0} (f(x) - f(x_0))\frac{x-x_0}{x-x_0} = \lim_{h \to 0} (f(x) - f(x_0))\frac{h}{h}\]
        dove $h = x-x_0$. Poiché $f$ è derivabile in $x_0$, abbiamo che:
        \[\lim_{x \to x_0} f(x) - f(x_0) = \lim_{h \to 0} \frac{(f(x) - f(x_0))}{h} \cdot h= \lim_{h \to 0} f'(x_0){h} = 0\]
        concludendo che $f$ sia continua in $I$.
    \end{proof}

    \quad

    \section{Derivate notevoli}

    Come per i limiti notevoli, studiamo le derivate delle funzioni elementari. Prima di tutto, consideriamo la funzione costante $f(x) = c$ per qualche $c \in \R$. Notiamo facilmente che $\forall x \in \R$ si abbia che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{c-c}{h} = 0\]
    dunque la derivata di una funzione costante risulta sempre essere la funzione nulla.

    \begin{framedprop}{Derivata di funzione costante}
        Data la funzione $f(x) = c$ per qualche $c \in \R$, abbiamo che $f'(x) = 0$.
    \end{framedprop}
    
    Consideriamo ora invece la funzione $f(x) = x$. Abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{x+h-x}{h} = \lim_{h \to 0} \frac{h}{h} = 1\]

    Consideriamo ora invece la funzione $f(x) = x^2$. Abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{(x+h)^2-x^2}{h} = \lim_{h \to 0} \frac{x^2+2xh+h^2-x^2}{h} = \lim_{h \to 0} 2x+h = 2x\]

    Per la funzione $f(x) = x^3$, invece, abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{(x+h)^3-x^3}{h} = \lim_{h \to 0} \frac{x^3+3x^2h+3xh^2+h^3-x^3}{h} = 3x^2\]

    Notiamo quindi la presenza di un pattern: data la funzione $f(x) = x^n$ con $n \in \N$, la sua derivata sembra essere $f'(x) = nx^{n-1}$. Difatti, ciò risulta vero. Tuttavia, possiamo dimostrare anche un risultato molto più forte: l'esponente può essere persino reale!

    \begin{framedprop}{Derivata di potenza reale}
        Data la funzione $f(x) = x^{\alpha}$ per qualche $\alpha \in \R$, abbiamo che $f'(x) = \alpha x^{\alpha-1}$.
    \end{framedprop}

    \begin{proof}
        La dimostrazione richiede passaggi algebrici molto specifici per poter sfruttare i limiti notevoli conosciuti. Data $f(x) = x^\alpha$ abbiamo che:
        \[\begin{split}
            \lim_{h \to 0} \frac{f(x+h)-f(x)}{h} &= \lim_{h \to 0} \frac{(x+h)^\alpha-x^\alpha}{h} \\
            &= \lim_{h \to 0} x^\alpha \cdot \frac{\rbk{\frac{x+h}{x}}^\alpha-1}{h} \\
            &= \lim_{h \to 0} x^\alpha \cdot \frac{\rbk{1+\frac{h}{x}}^\alpha-1}{h} \\
        \end{split}\]
        \[\begin{split}
            &= \lim_{h \to 0} x^\alpha \cdot \frac{e^{\alpha \ln \rbk{1+\frac{h}{x}}}-1}{h} \\
            &= \lim_{h \to 0} x^\alpha \cdot \frac{e^{\alpha \ln \rbk{1+\frac{h}{x}}}-1}{h} \cdot \frac{\alpha \ln \rbk{1+\frac{h}{x}}}{\alpha \ln \rbk{1+\frac{h}{x}}}\\
        \end{split}\]

        Tramite il cambio di variabile e i limiti notevoli sappiamo che:
        \[\lim_{h \to 0} \frac{e^{\alpha \ln \rbk{1+\frac{h}{x}}}-1}{\alpha \ln \rbk{1+\frac{h}{x}}} = \lim_{y \to 0} \frac{e^y-1}{y} = 1\]

        dunque abbiamo che:
        \[\begin{split}
            \lim_{h \to 0} \frac{f(x+h)-f(x)}{h} &= \lim_{h \to 0} x^\alpha \cdot \frac{e^{\alpha \ln \rbk{1+\frac{h}{x}}}-1}{h} \cdot \frac{\alpha \ln \rbk{1+\frac{h}{x}}}{\alpha \ln \rbk{1+\frac{h}{x}}}\\
            &= \lim_{h \to 0} x^\alpha \cdot \frac{\alpha \ln \rbk{1+\frac{h}{x}}}{h}\\
            &= \lim_{h \to 0} x^{\alpha-1} \cdot \frac{\alpha \ln \rbk{1+\frac{h}{x}}}{\frac{h}{x}}\\
        \end{split}\]

        Tramite il cambio di variabile e i limiti notevoli sappiamo che:
        \[\lim_{h \to 0} \frac{\ln \rbk{1+\frac{h}{x}}}{\frac{h}{x}} = \lim_{z \to 0} \frac{\ln(1+z)}{z} = 1\]

        dunque abbiamo che:
        \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} x^{\alpha-1} \cdot \frac{\alpha \ln \rbk{1+\frac{h}{x}}}{\frac{h}{x}} = \lim_{h \to 0} x^{\alpha-1}\alpha = \alpha x^{\alpha-1}\]
    \end{proof}

    Passiamo ora alle funzioni esponenziali. Data $f(x) = e^x$, abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{e^{x+h}-e^x}{h} = \lim_{h \to 0} e^{x} \cdot \frac{e^h - 1}{h} = \lim_{h \to 0} e^x = e^x\]

    Per un esponenziale generico $f(x) = \alpha^x$ con $\alpha > 0$ similmente abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{e^{(x+h)(\ln \alpha)}- e^{x(\ln \alpha)}}{h} = \lim_{h \to 0} e^{x(\ln \alpha)} \cdot \frac{e^{h(\ln \alpha)} - 1}{h} \cdot \frac{\ln \alpha}{\ln \alpha} \]
    \[= \lim_{h \to 0} e^{x(\ln \alpha)}(\ln \alpha) \cdot \frac{e^{h(\ln \alpha)} - 1}{h (\ln \alpha)} = \lim_{h \to 0} e^{x(\ln \alpha)}(\ln \alpha) = \alpha^x(\ln \alpha)\]

    \begin{framedprop}{Derivata di esponenziale}
        Data la funzione $f(x) = \alpha^x$ per qualche $\alpha > 0$, abbiamo che $f'(x) = \alpha^x (\ln \alpha)$.
    \end{framedprop}

    Per quanto riguarda le funzioni logaritmiche, invece, data $f(x) = \ln x$ abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{\ln(x+h)-\ln x}{h} = \lim_{h \to 0} \frac{\ln \rbk{\frac{x+h}{x}}}{h}\]
    \[= \lim_{h \to 0} \frac{\ln \rbk{1 + \frac{h}{x}}}{h} \cdot \frac{x}{x} = \lim_{h \to 0} \frac{1}{x} \cdot \frac{\ln \rbk{1 + \frac{h}{x}}}{\frac{h}{x}}= \lim_{h \to 0} \frac{1}{x}  = \frac{1}{x}\]

    Per un logaritmo generico $f(x) = \log_{\alpha} x$ con $\alpha > 0$ similmente abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{\log_{\alpha}(x+h)-\log_{\alpha} x}{h} = \lim_{h \to 0} \frac{\frac{\ln(x+h)}{\ln \alpha}- \frac{\ln x}{\ln \alpha}}{h} \]
    \[= \lim_{h \to 0} \frac{1}{\ln \alpha} \cdot \frac{\ln(x+h)-\ln x}{h} = \frac{1}{x \ln \alpha}\]

    \begin{framedprop}{Derivata di un logaritmo}
        Data la funzione $f(x) = \log_{\alpha} x$ per qualche $\alpha > 0$, abbiamo che $f'(x) = \frac{1}{x \ln \alpha}$.
    \end{framedprop}

    Passiamo ora alle funzioni trigonometriche. Per la funzione $f(x) = \sin x$ abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{\sin(x+h)-\sin(x)}{h} = \lim_{h \to 0} \frac{\sin(x) \cos(h) + \cos(x)\sin(h)-\sin(x)}{h}\]
    \[= \lim_{h \to 0} \frac{\sin(x) (\cos(h) - 1) + \cos(x)\sin(h)}{h} = \lim_{h \to 0} \sin(x) \frac{\cos(h) - 1}{h} + \cos(x)\frac{\sin(h)}{h} \]
    \[= \lim_{h \to 0} \sin(x) \cdot 0 + \cos (x) \cdot 1 = \cos x\]

    \begin{framedprop}{Derivata del seno}
        Data la funzione $f(x) = \sin x$, abbiamo che $f'(x) = \cos x$.
    \end{framedprop}

    Similmente, per la funzione $f(x) = \cos x$ abbiamo che:
    \[\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} = \lim_{h \to 0} \frac{\cos(x+h)-\cos(x)}{h} = \lim_{h \to 0} \frac{\cos(x) \cos(h) - \sin(x)\sin(h)-\cos(x)}{h}\]
    \[= \lim_{h \to 0} \frac{\cos(x) (\cos(h) - 1) - \sin(x)\sin(h)}{h} = \lim_{h \to 0} \cos(x) \frac{\cos(h) - 1}{h} - \sin(x)\frac{\sin(h)}{h} \]
    \[= \lim_{h \to 0} \cos(x) \cdot 0 - \sin (x) \cdot 1 = -\sin x\]

    \begin{framedprop}{Derivata del coseno}
        Data la funzione $f(x) = \cos x$, abbiamo che $f'(x) = -\sin x$.
    \end{framedprop}

    Di seguito forniamo una tabella riassuntiva di tutte le derivate notevoli analizzate:
    \begin{center}
        \begin{tabular}{lr|l}
            \multicolumn{2}{c}{\textbf{Funzione}} & \textbf{Derivata} \\
            \hline
            &&\\
            $f(x) = c$ & $\qquad \forall c \in \R$ & $f'(x) = 0$ \\
            &&\\
            $f(x) = x^{\alpha} $ & $\qquad \forall \alpha \in \R$ & $f'(x) = \alpha x^{\alpha-1}$ \\
            &&\\
            $f(x) = \alpha^x $ & $\qquad \forall \alpha > 0$ & $f'(x) = \alpha^x (\ln \alpha)$ \\
            &&\\
            $f(x) = \log_{\alpha} x $ & $\qquad \forall \alpha > 0$ & $f'(x) = \dfrac{1}{x \ln \alpha}$ \\
            &&\\
            $f(x) = \sin x $ & &$f'(x) = \cos x$ \\
            &&\\
            $f(x) = \cos x $ & &$f'(x) = -\sin x$
        \end{tabular}
    \end{center}

    \newpage

    \section{Proprietà delle derivate}

    Essendo le derivate un'applicazione dei limiti, risulta intuitivo immaginare che tramite le proprietà dei limiti sia possibile ottenere delle proprietà simili anche per le derivate. Ad esempio, data la funzione $k(x) = c f(x)$ per qualche $c \in \R$, abbiamo che:
    \[k'(x) = \lim_{h \to 0} \frac{k(x+h)-k(x)}{h} = \lim_{h \to 0} \frac{cf(x+h)-cf(x)}{h} = \lim_{h \to 0} c \cdot \frac{f(x+h)-f(x)}{h} = c f'(x)\]

    \begin{framedprop}{Regola del multiplo}
        Data la funzione $k(x) = cf(x)$ per qualche $c \in \R$, si ha che $k'(x) = cf'(x)$
    \end{framedprop}

    
    Similmente, per la funzione $k(x) = f(x) + g(x)$ abbiamo che:
    \[k'(x) = \lim_{h \to 0} \frac{k(x+h)-k(x)}{h} = \lim_{h \to 0} \frac{f(x+h)+g(x+h)-f(x)-g(x)}{h} \]
    \[= \lim_{h \to 0} \frac{f(x+h)+f(x)}{h} + \frac{g(x+h)-g(x)}{h} = f'(x)+g'(x)\]
    
    \begin{framedprop}{Regola della somma}
        Data la funzione $k(x) = f(x) + g(x)$, si ha che $k'(x) = f'(x)+g(x)$
    \end{framedprop}
    
    Ad esempio, data la funzione $f(x) = 4x^5 - x^2+ e^x$ abbiamo che:
    \[f'(x) = [4x^5]' + [-x^2]' + [e^x]' = 4 \cdot 5x^4 - 2x + e^x = 20x^4 - 2x + e^x\]

    Tuttavia, le cose non risultano sempre così semplici. Ad esempio, per la funzione $k(x) = f(x)g(x)$ non è vero che $k'(x) = f'(x) g'(x)$. Difatti, in realtà abbiamo che:
    \[\begin{split}
        k'(x) &= \lim_{h \to 0} \frac{k(x+h)-k(x)}{h} \\
        &= \lim_{h \to 0} \frac{f(x+h)g(x+h)-f(x)g(x)}{h} \\
        &= \lim_{h \to 0} \frac{f(x+h)g(x+h)-f(x)g(x) + f(x)g(x+h) - f(x)g(x+h)}{h} \\
        &= \lim_{h \to 0} g(x+h) \cdot \frac{f(x+h) - f(x)}{h} + f(x) \cdot \frac{g(x+h) + g(x)}{h} \\
        &= \lim_{h \to 0} g(x+h) f'(x) + f(x) g'(x) \\
        &= g(x) f'(x) + f(x) g'(x) \\
    \end{split}\]

    Ad esempio, data la funzione $f(x) = xe^x$, dunque, abbiamo che:
    \[f'(x) = [x]' \cdot e^x + x \cdot [e^x]' = e^x+x^ex = e^x(1+x)\]


    \begin{framedprop}{Regola del prodotto}
        Data la funzione $k(x) = f(x)g(x)$, si ha che $k'(x) = f'(x)g(x)+f(x)g'(x)$
    \end{framedprop}
    
    Consideriamo ora invece la funzione $k(x) = g(f(x))$:
    \[\begin{split}
        k'(x) &= \lim_{h \to 0} \frac{k(x+h)-k(x)}{h}\\
        &= \lim_{h \to 0} \frac{g(f(x+h))-g(f(x))}{h}\\
        &= \lim_{h \to 0} \frac{g(f(x+h))-g(f(x))}{f(x+h)-f(x)} \cdot \frac{f(x+h)-f(x)}{h}\\
        &= \lim_{h \to 0} \frac{g(f(x+h))-g(f(x))}{f(x+h) - f(x)} \cdot f'(x)\\
        &= \lim_{y \to 0} \frac{g(f(x)+y)-g(f(x))}{y} \cdot f'(x)\\
        &= g'(f(x)) \cdot f'(x)\\
    \end{split}\]

    dove $y = f(x+h) - f(x)$. Ad esempio, data la funzione $f(x) = \cos (x^3)$ abbiamo che:
    \[f'(x) = [\cos (z)]' \cdot [x^3]' = -\sin(z) \cdot 3x^2 = -3x^2\sin(x^2)\]
    dove $z = x^2$. 
    
    \begin{framedprop}{Regola della composizione (o della catena)}
        Data la funzione $k(x) = g(f(x))$, si ha che $k'(x) = g'(f(x))f'(x)$
    \end{framedprop}

    Tramite la regola del prodotto e della catena possiamo facilmente ricavare anche una regola per la divisione tra funzione:
    \[\arraycolsep=1.4pt\def\arraystretch{2}
    \begin{array}{rl}
        k'(x) &= \sbk{\dfrac{f(x)}{g(x)}}' \\
        &= \sbk{f(x)g(x)^{-1}}' \\
        &= [f(x)]' \cdot g(x)^{-1} + [g(x)^{-1}]' \cdot [f(x)]\\
        &= f'(x) \cdot g(x)^{-1} + [z^{-1}]' \cdot [g(x)]' \cdot f(x) \\
        &= f'(x) \cdot g(x)^{-1} -z^{-2} \cdot g'(x) f(x) \\
        &= f'(x) \cdot g(x)^{-1} -g(x)^{-2}g'(x) f(x) \\
        &= f'(x) g(x) g(x)^{-2} -g(x)^{-2}g'(x) f(x) \\
        &= \dfrac{f'(x) g(x) -g'(x) f(x)}{g(x)^2} \\
    \end{array}\]
    dove $z = g(x)$. Ad esempio, data la funzione $f(x) = \frac{x^2}{e^x}$ abbiamo che:
    \[f'(x) = \frac{[x^2]' \cdot e^x - x^2 \cdot [e^x]'}{e^{2x}} = \frac{2x e^x-x^2e^x}{e^{2x}} = \frac{x(2-x)}{e^x}\]

    \begin{framedprop}{Regola della divisione}
        Data la funzione $k(x) = \dfrac{f(x)}{g(x)}$, si ha che $k'(x) = \dfrac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$
    \end{framedprop}

    Infine, vediamo una regola che solitamente viene omessa poiché poco comune. Data una funzione $f(x)$ per cui esiste una funzione inversa $f^{-1}(x)$, abbiamo che:
    \[\sbk{f(f^{-1}(x))}' = [x]' \implies f'(f^{-1}(x))[f^{-1}(x)]'= 1 \implies [f^{-1}(x)]' = \frac{1}{f'(f^{-1}(x))}\]

    Ad esempio, data la funzione $f(x) = \arcsin x$ abbiamo che:
    \[f'(x) = \frac{1}{\cos(\arcsin x)} = \frac{1}{\sqrt{1-\sin^2(\arcsin x)}} = \frac{1}{\sqrt{1-x^2}}\]
    dove abbiamo sfruttato il fatto che $\cos y = \sqrt{1-\sin^2 y}$.

    \begin{framedprop}{Regola dell'inversa}
        Data la funzione $k(x) = f^{-1}(x)$, si ha che $k'(x) = \dfrac{1}{f'(k(x))}$
    \end{framedprop}

    Di seguito forniamo una tabella riassuntiva di tutte le proprietà analizzate:
    \begin{center}
        \begin{tabular}{lr|l}
            \multicolumn{2}{c}{\textbf{Funzione}} & \textbf{Derivata} \\
            \hline
            &&\\
            $k(x) = cf(x)$ & $\qquad \forall c \in \R$ & $k'(x) = cf'(x)$ \\
            &&\\
            $k(x) = f(x)+g(x) $ & & $k'(x) = f'(x)+g'(x)$ \\
            &&\\
            $k(x) = g(f(x)) $ & & $k'(x) = g'(f(x))f'(x)$ \\
            &&\\
            $k(x) = f(x)g(x)$ &  & $k'(x) = f'(x)g(x)+f(x)g'(x)$ \\
            &&\\
            $k(x) = \dfrac{f(x)}{g(x)} $ & & $k'(x) = \dfrac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$ \\
            &&\\
            $k(x) = f^{-1}(x)$ & &$k'(x) = \dfrac{1}{f'(k(x))}$ 
        \end{tabular}
    \end{center}


    \section{Massimi e minimi di una funzione}

    Nel primo capitolo abbiamo accennato il concetto di massimo e minimo di un insieme. Approfondiamo ora tale discorso nel caso delle funzioni. Prima di tutto distinguiamo in due tipologie di valore massimo e minimo di una funzione.

    \begin{frameddefn}{Punti di massimo e minimo relativi}
        Data una funzione $f : [a,b] \to \R$ e un punto $x_0 \in I$, diciamo che:
        \begin{itemize}
            \item $x_0$ è un \textbf{punto di massimo relativo} di $f$ se esiste un $\delta > 0$ tale che $\forall x \in I_{\delta}(x_0) \cap [a,b]$ si abbia che $f(x) \leq f(x_0)$
            \item $x_0$ è un \textbf{punto di minimo relativo} di $f$ se esiste un $\delta > 0$ tale che $\forall x \in I_{\delta}(x_0) \cap [a,b]$ si abbia che $f(x) \geq f(x_0)$
        \end{itemize}
    \end{frameddefn}

    In altre parole, i punti di massimo e minimo relativi corrispondono a quei punti per cui la funzione sale momentaneamente fino al suo massimo valore, per poi riscendere (o viceversa per i minimi). In alcuni casi, tali valori massimi e minimi potrebbero essere \textit{globali}, ossia potrebbe non esistere un punto della funzione che assuma valore maggiore di essi.

    \begin{frameddefn}{Punti di massimo e minimo assoluti}
        Data una funzione $f : [a,b] \to \R$ e un punto $x_0 \in I$, diciamo che:
        \begin{itemize}
            \item $x_0$ è un \textbf{punto di massimo assoluto} di $f$ se $\forall x \in [a,b]$ si abbia che $f(x) \leq f(x_0)$
            \item $x_0$ è un \textbf{punto di minimo assoluto} di $f$ se $\forall x \in [a,b]$ si abbia che $f(x) \geq f(x_0)$
        \end{itemize}
    \end{frameddefn}
    
    Consideriamo ad esempio il seguente grafico di funzione, compresa in un intervallo $[a,b]$:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/max_min.png}
    \end{figure}

    Il punto $x_1$ risulta essere un punto di massimo relativo, mentre il punto $x_2$ è un punto di minimo relativo. Notiamo inoltre come $f(b)$ sia il valore più alto in assoluto raggiunto dalla funzione, dunque $b$ è un punto di massimo assoluto. Inoltre, il punto $x_2$ risulta anche essere un punto di minimo assoluto.

    Non sempre una funzione possiede dei punti di massimo e minimo, relativi o assoluti che siano. Ad esempio, per la funzione $f(x) = x^3-x$ abbiamo che per $x \to \pm\infty$ si abbia che $f(x) \to +\pm\infty$, dunque non può esistere un massimo o minimo assoluto, ma esistono un punto di massimo e minimo relativo, ossia $x_1 = \frac{1}{\sqrt{3}}$ e $x_2 = -\frac{1}{\sqrt{3}}$.

    Vediamo ora come il concetto di derivata sia strettamente connesso con i concetti di massimo e minimo.

    \begin{framedthm}{Teorema di Fermat}
        Data una funzione $f: [a,b] \to \R$ e un punto $x_0 \in (a,b)$, se $x_0$ è un punto di massimo o minimo relativo di $f$ e $f$ è derivabile in $x_0$ allora $f'(x_0) = 0$.
    \end{framedthm}

    \begin{proof}
        Consideriamo il caso in cui $x_0$ sia un massimo relativo (dimostrazione analoga per i minimi relativi). Per definizione, sappiamo che $\exists \delta > 0$ tale che $\forall x \in I_{\delta}(x_0) \cap [a,b]$ valga che $f(x_0) \geq f(x)$. Inoltre, poiché $f'(x_0)$ è derivabile abbiamo che:
        \[f'(x_0) = \lim_{h \to 0^+} \frac{f(x_0+h)-f(x_0)}{h} = \lim_{h \to 0^-} \frac{f(x_0+h)-f(x_0)}{h}\]

        Quando $h > 0$ abbiamo che $f(x_0 + h) \leq f(x_0)$, dunque $f(x_0 + h) - f(x_0) \leq 0$, quindi concludiamo che:
        \[ f'(x_0) = \lim_{h \to 0^+} \frac{f(x_0+h)-f(x_0)}{h} \leq 0\]

        Quando invece $h < 0$ abbiamo comunque che $f(x_0 + h) \leq f(x_0)$, dunque $f(x_0 + h) - f(x_0) \leq 0$, quindi concludiamo:
        \[ f'(x_0) = \lim_{h \to 0^-} \frac{f(x_0+h)-f(x_0)}{h} \geq 0\]
        dunque necessariamente $f'(x_0) = 0$.
    \end{proof}

    La parte interessante di tale risultato risulta essere la sua \textit{contronominale}: se $f$ è derivabile in $x_0$ ma $f'(x_0)\neq 0$ allora sicuramente $x_0$ non è né un punto di massimo relativo né un punto di minimo relativo.

    \begin{frameddefn}{Punto critico}
        Data una funzione $f : [a,b] \to \R$ e un punto $x_0 \in [a,b]$ diciamo che $x_0$ è un \textbf{punto critico} (o \textit{punto stazionario}) di $f$ se si verifica che $f'(x_0) = 0$.
    \end{frameddefn}

    La nomenclatura di punto stazionario deriva da ciò che accade alla retta tangente $t(x) = f(x_0) + f'(x_0)(x-x_0)$, poiché quando $x_0$ è un punto critico si ha che $t(x) = f(x_0)$, dunque il rapporto incrementale rimane immobile.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/critical.png}
    \end{figure}
    
    \begin{framedthm}{Teorema di Rolle}
        Data una funzione $f : [a,b] \to \R$ continua in $[a,b]$ e derivabile in $(a,b)$, se si verifica che $f(a) = f(b)$ allora $\exists c \in (a,b)$ tale che $f'(c) = 0$.
    \end{framedthm}

    \begin{proof}
        Per il teorema di Weierstrass, sappiamo che $\exists x_{min},x_{max} \in [a,b]$ tali che $\forall x \in [a,b]$ si abbia che $f(x_{min}) f(x) \leq f(x_{max})$. Abbiamo quindi due casi:
        \begin{itemize}
            \item Se $f(x_{min}) = f(x_{max})$ allora necessariamente la funzione deve essere costante. Per tanto, dato un qualsiasi $x_0 \in (a,b)$ abbiamo che $f'(x_0) = 0$.
            \item Se $f(x_{min}) < f(x_{max})$ allora poiché per ipotesi $f(a) = f(b)$ abbiamo necessariamente che $x_{min}, x_{max} \in (a,b)$. Per il teorema di Fermat, concludiamo immediatamente che $f'(x_{max}), f'(x_{min}) = 0$.
        \end{itemize} 
    \end{proof}

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/rolle.png}
    \end{figure}
    

    \begin{framedthm}{Teorema di Lagrange}
        Data una funzione $f : [a,b] \to \R$ continua in $[a,b]$ e derivabile in $(a,b)$, esiste $c \in (a,b)$ tale che $f'(c) = \dfrac{f(b)-f(a)}{b-a}$
    \end{framedthm}

    \begin{proof}
        Consideriamo quindi la seguente funzione $F(x)$:
        \[F(x) = f(x) -  f(a) - \dfrac{f(b)-f(a)}{b-a}(x-a)\]

        la cui derivata corrisponde a:
        \[F'(x) = f'(x) - \dfrac{f(b)-f(a)}{b-a}\]

        Tale funzione soddisfa tutte le condizioni del teorema di Rolle:
        \begin{enumerate}
            \item $F(x)$ è continua in $[a,b]$
            \item $F(x)$ è derivabile in $(a,b)$
            \item $F(a) = F(b)$, poiché:
            \[F(a) = f(a) -  f(a) - \dfrac{f(b)-f(a)}{b-a}(a-a) = 0\]
            \[F(b) = f(b) -  f(a) - \dfrac{f(b)-f(a)}{b-a}(b-a) = 0\]
        \end{enumerate}

        Per tanto, deve esistere un punto $c \in (a,b)$ tale che $F'(c) = 0$. Di conseguenza, abbiamo che:
        \[0 = F'(c) = f'(c) - \dfrac{f(b)-f(a)}{b-a} \implies f'(c) = \dfrac{f(b)-f(a)}{b-a}\]
    \end{proof}

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/lagrange.png}
    \end{figure}

    \section{Monotonia di una funzione}

    Fino ad ora abbiamo evitato di porci la seguente domanda: ci poniamo la seguente domanda: perché viene detto rapporto incrementale? Dati due punti $x_0, x_1\in I$, sia $h > 0$ quel valore tale che $x_1 = x_0+h$. Consideriamo quindi il loro rapporto incrementale, indicato con $\ell$:
    \[\frac{f(x_1)-f(x)}{x_1-x_0} = \frac{f(x_0+h)-f(x)}{h}\]

    Supponiamo che $\ell > 0$. Poiché $h > 0$  deve necessariamente anche valere che $f(x_0+h)-f(x) \geq 0$ e dunque che $f(x_1) \geq f(x)$. In altre parole, quando $\ell > 0$ il valore della funzione cresce passando da $x_0$ a $x_1$. Analogamente, quando $\ell < 0$ il valore della funzione decresce. Supponiamo quindi che la funzione $f$ sia derivabile in $x_0$:
    \[f'(x_0) = \lim_{h \to 0^+} \frac{f(x_0+h)-f(x)}{h} = \lim_{h \to 0^-} \frac{f(x_0+h)-f(x)}{h}\]

    Supponiamo che $f'(x_0) > 0$. Quando $h \to 0^+$ abbiamo che $h > 0$, dunque necessariamente deve valere che $f(x+h) \geq f(x)$. Quando $h \to 0^-$, invece, abbiamo che $h < 0$, dunque necessariamente deve valere che $f(x+h) \leq f(x)$. Di conseguenza, concludiamo che se $f'(x_0) > 0$ allora la funzione risulta crescente in $x_0$. Con lo stesso ragionamento possiamo affermare che se $f'(x_0) < 0$ allora la funzione risulta decrescente in $x_0$. Rilassando le diseguaglianze involte, possiamo ottenere il seguente teorema più forte. 

    \begin{framedthm}{Criterio differenziale di monotonia}
        Data una funzione $f : [a,b] \to \R$ continua in $[a,b]$ e derivabile in $(a,b)$, si ha che:
        \begin{itemize}
            \item $\forall x \in (a,b)$ vale che $f'(x) \geq 0$ se e solo se $f$ è monotona crescente in $[a,b]$
            \item $\forall x \in (a,b)$ vale che $f'(x) \leq 0$ se e solo se $f$ è monotona decrescente in $[a,b]$
        \end{itemize}
    \end{framedthm}

    \begin{proof}
        Dimostriamo solo il caso inerente alla monotonia crescente (la dimostrazione dell'altro caso è analoga). Supponiamo che $f$ sia monotona crescente in $[a,b]$, ossia che $x_1, x_2 \in [a,b]$ tali che $x_1 \leq x_2$ valga $f(x_1) \leq f(x_2)$. Abbiamo quindi che $x_2-x_1 \geq 0$ e che $f(x_2) - f(x_1) \geq 0$, dunque:
        \[\frac{f(x_2)-f(x_1)}{x_2-x_1} \geq 0\]

        Ponendo $h = x_2-x_1$, poiché $f$ è derivabile in $(a,b)$ per $x_2 \to x_1$ abbiamo che:
        \[\lim_{x_2 \to x_1} \frac{f(x_2)-f(x_1)}{x_2-x_1} = \lim_{h \to 0} \frac{f(x_1+h)-f(x_1)}{h} = f'(x_1)\]
        Di conseguenza, per il teorema della permanenza del segno, deve valere che $f'(x_1) \geq 0$.

        Viceversa, supponiamo che $\forall x \in (a,b)$ vale che $f'(x) \geq 0$. Consideriamo due punti $x_1,x_2 \in [a,b]$ tali che $x_1 \leq x_2$. Sappiamo che $f$ è continua in $[a,b]$ e derivabile in $(a,b)$, dunque necessariamente essa è anche continua in $[x_1,x_2]$ e derivabile in $(x_1,x_2)$. Per il teorema di Lagrange, esiste un punto $c \in (x_1,x_2)$ tale che:
        \[f'(c) = \frac{f(x_2)-f(x_1)}{x_2-x_1}\]

        Poiché per ipotesi $f'(c) \geq 0$ e abbiamo assunto che $x_1 \leq x_2$, dunque $x_2-x_1 \geq 0$, deve necessariamente valere anche che $f(x_2) - f(x_1) \geq 0$, ossia che $f(x_1) \leq x_2$.
    \end{proof}

    Una versione più ristretta del teorema ci permette di stabilire che:
    \begin{itemize}
        \item $\forall x \in (a,b)$ vale che $f'(x) > 0$ se e solo se $f$ è strettamente crescente in $[a,b]$
        \item $\forall x \in (a,b)$ vale che $f'(x) < 0$ se e solo se $f$ è strettamente decrescente in $[a,b]$
    \end{itemize}

    L'importanza del teorema precedente risiede nel suo uso al fine di trovare i massimi e i minimi di una funzione. Data una funzione $f(x) : [a,b] \to \R$, supponiamo che esista un punto $x_0 \in [a,b]$ tale che $\forall x \in [a,x_0]$ si abbia che $f'(x) \geq 0$, mentre $\forall x \in [x_0, b]$ valga che $f'(x) \leq 0$. Poiché $x_0$ si trova in entrambi gli intervalli abbiamo che $f'(x_0) = 0$ sia l'unica possibilità dunque $x_0$ è necessariamente critico. Inoltre, per il criterio di monotonia differenziabile, sappiamo che la funzione deve essere monotona crescente per tutto $[a,x_0]$ e monotona decrescente per tutto $[x_0,b]$. Notiamo facilmente allora che $x_0$ sia necessariamente un punto di massimo relativo di $f$.

    \begin{framedcor}{}
        Data una funzione $f : [a,b] \to \R$ continua in $[a,b]$ e derivabile in $(a,b)$, si ha che:
        \begin{itemize}
            \item Se $\exists x_0 \in [a,b]$ tale che $\forall x_1, x_2 \in [a,b]$ con $x_1 < x_0 < x_2$ e con $f'(x_1) > 0 > f'(x_2)$ allora $x_1$ è un punto di massimo relativo di $f$
            \item Se $\exists x_0 \in [a,b]$ tale che $\forall x_1, x_2 \in [a,b]$ con $x_1 < x_0 < x_2$ e con $f'(x_1) < 0 < f'(x_2)$ allora $x_1$ è un punto di minimo relativo di $f$
        \end{itemize}
    \end{framedcor}

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{images/max_fermat.png}
    \end{figure}

    Consideriamo quindi la seguente funzione $f(x) = x^3-x^4 = x^3(1-x)$. Il suo campo di esistenza risulta chiaramente essere $\R$. Studiamo quindi il segno delle due sottofunzioni che compongono la funzione:
    \begin{itemize}
        \item Per $x^3 \geq 0$, ciò risulta essere vero quando $x \geq 0$.
        \item Per $1-x \geq 0$, ciò risulta essere vero quando $x \leq 1$ 
    \end{itemize}
    
    Tramite il grafico del segno abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{images/es20.png}
    \end{figure}

    dunque $f(x) \geq 0$ quando $0 \leq x \leq 1$. Calcoliamo quindi la derivata:
    \[f'(x) = 3x^2-4x^3 = x^2(3-4x)\]

    Studiamo quindi il segno delle due sottofunzioni che compongono la derivata:
    \begin{itemize}
        \item Per $x^2 \geq 0$, ciò risulta essere vero per ogni $x \in \R$.
        \item Per $3-4x \geq 0$, ciò risulta essere vero quando $x \leq \frac{3}{4}$ 
    \end{itemize}

    Tramite il grafico del segno abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{images/es21.png}
    \end{figure}
    dunque $f'(x) \geq 0$ quando $x \leq \frac{3}{4}$. Dato $\delta > 0$ molto piccolo, per ogni $x \leq \frac{3}{4}-\delta$ si ha che $f'(x) > 0$, mentre per ogni $x \geq \frac{3}{4}+\delta$ si ha che $f'(x) < 0$. Il punto $x_0 =  \frac{3}{4}$ risulta essere un massimo relativo della funzione nell'intorno $I_\delta(x_0)$. In particolare, tale punto risulta anche essere un massimo assoluto, poiché $f$ è strettamente crescente fino ad $x_0$ per poi divenire strettamente decrescente.

    \newpage

    Tramite le informazioni ricavate, possiamo abbozzare il grafico della funzione:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.65]{images/es22.png}
    \end{figure}

    \quad

    \section{Concavità e convessità di una funzione}

    Consideriamo il seguente grafico di funzione. Guardando la forma assunta dalla funzione, possiamo tracciare una linea che divida tale forma in due sotto-forme: una sorta di parabola verso il basso ed una sorta di parabola verso l'altro. In analisi, tali sotto-forme assunte dalla funzione vengono rispettivamente dette \textbf{concavità} e \textbf{convessità} della funzione.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.7]{images/convex1.png}
    \end{figure}

    Geometricamente, possiamo definire tali concetti come:
    \begin{itemize}
        \item La funzione $f$ è \textit{concava} in un intervallo $I$ se $\forall x_1,x_2 \in I$ il segmento che collega i punti $(x_1, f(x_1))$ e $(x_2, f(x_2))$ è contenuto interamente al di sotto del grafico della funzione
        \item La funzione $f$ è \textit{convessa} in un intervallo $I$ se $\forall x_1,x_2 \in I$ il segmento che collega i punti $(x_1, f(x_1))$ e $(x_2, f(x_2))$ è contenuto interamente al di sopra del grafico della funzione
    \end{itemize}

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.7]{images/convex2.png}
    \end{figure}
    
    Cerchiamo di trasformare tale definizione geometrica in una definizione analitica. Dati $x_1, x_2 \in I$, consideriamo la retta passante per $P_1 = (x_1, f(x_1))$ e $P_2 = (x_2, f(x_2))$, ossia $r(x) = f(x_1) + \frac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)$. Il segmento tra $P_1$ e $P_2$ sarà dato dai punti $(x, r(x))$ per ogni $x \in [x_1,x_2]$.

    Affinché la funzione sia concava, vogliamo che l'intero segmento sia al di sotto del grafico della funzione, dunque che $\forall x \in [x_1,x_2]$ valga che $f(x) \geq r(x)$.Analogamente, affinché la funzione sia convessa vogliamo che l'intero segmento sia al di sotto del grafico della funzione, dunque che $\forall x \in [x_1,x_2]$ valga che $f(x) \leq r(x)$

    \begin{frameddefn}{Concavità e convessità}
        Data $f:I \to \R$ e un intervallo $[a,b] \subseteq I$, diciamo che:
        \begin{itemize}
            \item $f$ è \textbf{convessa} in $[a,b]$ se dati $x_1,x_2 \in [a,b]$ si ha che:
            \[\forall x \in [x_1,x_2] \;\; f(x) \geq f(x_1) + \dfrac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)\]
            \item $f$ è \textbf{concava} in $[a,b]$ se dati $x_1,x_2 \in [a,b]$ si ha che:
            \[\forall x \in [x_1,x_2] \;\; f(x) \leq f(x_1) + \dfrac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)\]
        \end{itemize}
    \end{frameddefn}

    Restringendo alcuni vincoli possiamo dare anche una definizione di concavità e convessità strette:
    \begin{itemize}
        \item $f$ è \textbf{strettamente convessa} in $[a,b]$ se dati $x_1,x_2 \in [a,b]$ si ha che:
        \[\forall x \in (x_1,x_2) \;\; f(x) < f(x_1) + \dfrac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)\]
        \item $f$ è \textbf{concava} in $[a,b]$ se dati $x_1,x_2 \in [a,b]$ si ha che:
        \[\forall x \in (x_1,x_2) \;\; f(x) < f(x_1) + \dfrac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)\]
    \end{itemize}

    \begin{framedthm}{}
        Data $f:I \to \R$ e un intervallo $(a,b) \subseteq I$, le seguenti tre affermazioni sono equivalenti tra loro (ossia si implicano tutte a vicenda):
        \begin{enumerate}
            \item $f$ è (strettamente) convessa in $[a,b]$
            \item $f'$ è (strettamente) crescente in $[a,b]$
            \item $\forall x \in (a,b)$ vale che $f(x) \substack{\geq \\ (>)} f(x_0) + f'(x_0)(x-x_0)$
        \end{enumerate}

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    In particolare, siamo interessati alla seconda di tali affermazioni equivalenti. Nella sezione precedente abbiamo visto come la crescita di una funzione in un intervallo $[a,b]$ sia strettamente legata alla positività della sua derivata in quell'intervallo. In altre parole, studiando il segno della \textbf{derivata seconda}, ossia la derivata della derivata, della funzione iniziale. In generale, indichiamo la derivata seconda come $f''$.

    \begin{framedcor}{Criterio differenziale di convessità}
        Data $f : [a,b] \to \R$ continua in $[a,b]$ e derivabile due volte in $(a,b)$, si ha che:
        \begin{itemize}
            \item $\forall x \in (a,b)$ vale che $f''(x) \geq 0$ se e solo se $f$ è convessa in $[a,b]$
            \item $\forall x \in (a,b)$ vale che $f''(x) \leq 0$ se e solo se $f$ è concava  in $[a,b]$
        \end{itemize}
    \end{framedcor}

    \begin{frameddefn}{Punto di flesso}
        Data $f:I \to \R$ e un punto $x_0 \in I$, diciamo che $x_0$ è un \textbf{punto di flesso} se esistono due intervalli $(a,x_0), (x_0,b) \subseteq I$ tali che in $(a,x_0)$ la funzione è concava (o convessa) e in $(x_0,b)$ la funzione è convessa (o concava). 
    \end{frameddefn}

    I punti di flesso possono essere visti come i punti di massimo e minimo della derivata della funzione. Tale fatto risulta anche intuitivo: il punto in cui la concavità o convessità della funzione cambia viene raggiunto quando la crescita o decrescita della funzione raggiunge il suo picco massimo o minimo.

    \begin{framedcor}{}
        Data $f: [a,b] \to \R$ e un punto $x_0 \in (a,b)$, se $x_0$ è un punto di flesso e $f$ è derivabile due volte in $x_0$ allora $f''(x_0) = 0$.
    \end{framedcor}

    Consideriamo ad esempio la seguente funzione $f(x) = x^4-2x^3+x$. Il suo campo di esistenza risulta chiaramente essere $\R$. Riscriviamo il polinomio tramite le sue radici:
    \[f(x) = x^4-2x^3+x = x(x-1)\rbk{x-\frac{1}{2} - \frac{\sqrt{5}}{2}}\rbk{x-\frac{1}{2} + \frac{\sqrt{5}}{2}}\]
    per poi studiare il segno delle sottofunzioni che lo compongono:
    \begin{itemize}
        \item Per $x \geq 0$, ciò risulta essere vero quando $x \geq 0$
        \item Per $x-1 \geq 0$, ciò risulta essere vero quando $x \geq 1$
        \item Per $x-\frac{1}{2} - \frac{\sqrt{5}}{2} \geq 0$, ciò risulta essere vero quando $x \geq \frac{1}{2} + \frac{\sqrt{5}}{2}$
        \item Per $x-\frac{1}{2} + \frac{\sqrt{5}}{2} \geq 0$, ciò risulta essere vero quando $x \geq \frac{1}{2} - \frac{\sqrt{5}}{2}$
    \end{itemize}

    Tramite il grafico del segno abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{images/es23.png}
    \end{figure}
    dunque $f(x) \geq 0$ quando $x \leq \frac{1}{2} - \frac{\sqrt{5}}{2} \lor 0 \leq x \leq 1 \lor x \geq \frac{1}{2} + \frac{\sqrt{5}}{2}$.
    
    Calcoliamo quindi la sua derivata prima:
    \[f'(x) = 4x^3-6x^2+1 = \rbk{x-\frac{1}{2}}\rbk{x-\frac{1}{2}-\frac{\sqrt{3}}{2}}\rbk{x-\frac{1}{2}+\frac{\sqrt{3}}{2}}\]
    per poi studiare il segno delle sottofunzioni che la compongono:
    \begin{itemize}
        \item Per $x-\frac{1}{2} \geq 0$, ciò risulta essere vero quando $x \geq\frac{1}{2}$
        \item Per $x-\frac{1}{2}-\frac{\sqrt{3}}{2} \geq 0$, ciò risulta essere vero quando $x \geq \frac{1}{2}+\frac{\sqrt{3}}{2}$
        \item Per $x-\frac{1}{2}+\frac{\sqrt{3}}{2} \geq 0$, ciò risulta essere vero quando $x \geq \frac{1}{2}-\frac{\sqrt{3}}{2}$
    \end{itemize}

    \newpage

    Tramite il grafico del segno abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{images/es24.png}
    \end{figure}
    dunque $f'(x) \geq 0$ quando $\frac{1}{2}-\frac{\sqrt{3}}{2} \leq x \leq \frac{1}{2} \lor x \geq \frac{1}{2}+\frac{\sqrt{3}}{2}$.
    
    Calcoliamo quindi la sua derivata prima:
    \[f'(x) = 12x^2-12x = 12x(x-1)\]
    per poi studiare il segno delle sottofunzioni che la compongono:
    \begin{itemize}
        \item Per $12x \geq 0$, ciò risulta essere vero quando $x \geq 0$
        \item Per $x-1 \geq 0$, ciò risulta essere vero quando $x \geq 1$
    \end{itemize}
    
    Tramite il grafico del segno abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{images/es25.png}
    \end{figure}
    dunque $f''(x) \geq 0$ quando $x \leq 0 \lor x \geq 1$.

    Ricapitolando, abbiamo trovato che:
    \begin{itemize}
        \item Il campo di esistenza della funzione è $\R$
        \item La funzione è positiva quando $x \leq \frac{1}{2} - \frac{\sqrt{5}}{2} \lor 0 \leq x \leq 1 \lor x \geq \frac{1}{2} + \frac{\sqrt{5}}{2}$
        \item La funzione è crescente quando $\frac{1}{2}-\frac{\sqrt{3}}{2} \leq x \leq \frac{1}{2} \lor x \geq \frac{1}{2}+\frac{\sqrt{3}}{2}$
        \item La funzione è convessa quando $x \leq 0 \lor x \geq 1$
        \item I punti $x_1 = \frac{1}{2} - \frac{\sqrt{3}}{2}$ e $x_2 = \frac{1}{2}+\frac{\sqrt{3}}{2}$ sono due punti di minimo relativi
        \item Il punto $x_3 = \frac{1}{2}$ è un punto di massimo relativo
        \item I punti $x_4 = 0$ e $x_5 = 1$ sono due punti di flesso
    \end{itemize}

    \newpage

    Tramite le informazioni ricavate, possiamo abbozzare il grafico della funzione:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.65]{images/es26.png}
    \end{figure}

    \quad

    \section{Studio di funzione}

    Giunti a questo punto, siamo in grado di analizzare ogni caratteristica di una funzione. Gli \textbf{studi di funzione} sono alla base dell'analisi matematica e permettono a strumenti informatici come\textit{WolframAlpha}, \textit{Desmos} e \textit{Geogebra} di produrre il grafico di un'intera funzione in pochi secondi.

    Nel nostro caso, siamo interessati a studiare le seguenti caratteristiche:
    \begin{enumerate}
        \item \textbf{Campo di esistenza}, ossia il dominio massimale della funzione
        \item \textbf{Parità della funzione}, ossia determinare se essa sia pari, dispari o nessuno dei due
        \item \textbf{Asintoti della funzione}, ossia determinare se vi siano degli asintoti verticali, orizzontali o obliqui
        \item \textbf{Zeri della funzione}, ossia i punti punti in cui si ha che $x = 0$ oppure che $y = 0$
        \item \textbf{Segno della funzione}, ossia determinare gli intervalli in cui essa sia non-negativa
        \item \textbf{Monotonia della funzione}, ossia determinare gli intervalli in cui essa sia monotona crescente
        \item \textbf{Convessità della funzione}, ossia determinare gli intervalli in cui essa sia convessa
        \item \textbf{Punti di massimo e minimo relativo}, ossia i punti in cui varia la monotonia della funzione
        \item \textbf{Punti di flesso}, ossia i punti in cui varia la concavità della funzione
    \end{enumerate}

    \newpage

    I passaggi da svolgere sono senza dubbio tanti, ma la maggior parte di essi si riducono a risolvere sempre le stesse equazioni, dunque possiamo riutilizzare molti risultati. Consideriamo la seguente funzione:
    \[f(x) = \frac{e^x}{x^2-1}\]

    La frazione all'esponente impone la condizione di esistenza $x^2 -1 \neq 0$, dunque il \textit{campo di esistenza} risulta essere $\R-\{-1, 1\}$.
    
    Vediamo ora che:
    \[f(-x) = \frac{e^{-x}}{(-x)^2-1} = \frac{1}{e^x(x^2-1)}\]
    dunque $f(-x) \neq f(x)$ e $f(-x) \neq -f(x)$, quindi la funzione non è \textit{né pari né dispari} (fattore che potevamo già determinare per via del buco presente nel dominio).

    Analizziamo quindi gli asintoti della funzione:
    \begin{itemize}
        \item Per $x \to 1^+$ abbiamo che:
        \[\lim_{x \to 1^+} \frac{e^x}{x^2-1} = \lim_{x \to 1^+} \frac{e^0}{(1^+)^2-1} = \lim_{x \to 1^+} \frac{1}{0^+} = +\infty\]
        mentre per $x \to 1^-$ abbiamo che:
        \[\lim_{x \to 1^-} \frac{e^x}{x^2-1} = \lim_{x \to 1^-} \frac{e^0}{(1^-)^2-1} = \lim_{x \to 1^-} \frac{1}{0^-} = -\infty\]
        dunque $x = 1$ è un \textit{asintoto verticale} in entrambe le direzioni

        \item Per $x \to (-1)^+$ abbiamo che:
        \[\lim_{x \to (-1)^+} \frac{e^x}{x^2-1} = \lim_{x \to (-1)^+} \frac{e^0}{((-1)^+)^2-1} = \lim_{x \to (-1)^+} \frac{1}{0^-} = -\infty\]
        mentre per $x \to(-1)^-$ abbiamo che:
        \[\lim_{x \to(-1)^-} \frac{e^x}{x^2-1} = \lim_{x \to(-1)^-} \frac{e^0}{((-1)^-)^2-1} = \lim_{x \to(-1)^-} \frac{1}{0^+} = +\infty\]
        dunque $x = -1$ è un \textit{asintoto verticale} in entrambe le direzioni

        \item Per $x \to +\infty$ abbiamo che:
        \[\lim_{x \to +\infty} \frac{e^x}{x^2-1} = \lim_{x \to +\infty} \frac{e^x}{x^2 \rbk{1-\frac{1}{x^2}}} = \lim_{x \to +\infty} \frac{e^x}{x^2} = +\infty\]
        dunque non vi è asintoto orizzontale per $x \to +\infty$. Vediamo quindi se vi sia un asintoto obliquo:
        \[\lim_{x \to +\infty} \frac{e^x}{x(x^2-1)} = \lim_{x \to +\infty} \frac{e^x}{x^3 \rbk{1-\frac{1}{x^3}}} = \lim_{x \to +\infty} \frac{e^x}{x^3} = +\infty\]

        dunque non vi è neanche un asintoto obliquo.

        \item Per $x \to -\infty$ abbiamo che:
        \[\lim_{x \to -\infty} \frac{e^x}{x^2-1} = \lim_{x \to -\infty} \frac{e^x}{x^2 \rbk{1-\frac{1}{x^2}}} = \lim_{x \to -\infty} \frac{e^x}{x^2} = 0\]
        dunque $y = 0$ è un \textit{asintoto orizzontale}.
    \end{itemize}

    Calcoliamo quindi gli zeri della funzione:
    \begin{itemize}
        \item Affinché $f(x) = 0$ è necessario che:
        \[\frac{e^x}{x^2-1} = 0 \implies e^x = 0 \]
        il che è impossibile, dunque $\nexists x \in \mathrm{Dom}(f)$ tale che $f(x) = 0$.
        \item Quando $x = 0$ abbiamo che:
        \[f(0) =  \frac{e^0}{0^2-1} = \frac{1}{1} = 1\]
        dunque $y = 0$ è uno zero della funzione.
    \end{itemize}
    
    Procediamo quindi con studiare la \textit{positività} della funzione:
    \begin{itemize}
        \item Per $e^x \geq 0$, ciò risulta essere vero $\forall x \in \R$
        \item Per $x^2-1 \geq 0$, ciò risulta essere vero quando $x \leq -1 \lor x \geq -1$
        \item La funzione $f(x)$ non è definita per $x = \pm 1$.
    \end{itemize}
    dunque $f(x) \geq 0$ quando $x < -1 \lor x > -1$. 

    Calcoliamo quindi la derivata prima:
    \[f'(x) =  \frac{e^x(x^2-1) - 2xe^x}{(x^2-1)^2} = \frac{e^x(x^2-2x-1)}{(x^2-1)^2}\]

    e studiamo la \textit{monotonia} tramite il segno di tale derivata:
    \begin{itemize}
        \item Per $e^{x} \geq 0$, ciò risulta essere vero $\forall x \in \R$
        \item Per $x^2-2x-1 \geq 0$, ciò risulta essere vero per $x \leq 1-\sqrt{2} \lor x \geq 1 + \sqrt{2}$
        \item Per $(x^2-1)^2 \geq 0$, ciò risulta essere vero $\forall x \in \R$
        \item La funzione $f(x)$ non è definita per $x = \pm 1$.
    \end{itemize}

    concludendo che $f'(x) \geq 0$, dunque che $f(x)$ è crescente, quando $(x \leq 1-\sqrt{2} \lor x \geq 1 + \sqrt{2}) \land (x \neq \pm 1)$. Inoltre, ciò ci dice che $x = 1-\sqrt{2}$ è un punto di massimo relativo, mentre $x = 1+\sqrt{2}$ è un punto di minimo relativo.

    Continuando, calcoliamo la derivata seconda:
    \[\begin{split}
        f''(x) &= \frac{\sbk{e^x(x^2-2x-1)}' \cdot (x^2-1)^2 - e^x(x^2-2x-1) \cdot \sbk{(x^2-1)^2}}{(x^2-1)^4} \\
        &= \frac{(e^x(x^2-2x-1)+e^x(2x^2)) \cdot (x^2-1)^2 - e^x(x^2-2x-1) \cdot 4x(x^2-1)}{(x^2-1)^4} \\
        &= \frac{e^x(x^4 -4x^3 + 4x^2 + 4x + 3)}{(x^2-1)^3}
    \end{split}\]

    e studiamo la \textit{convessità} tramite il segno di tale derivata:
    \begin{itemize}
        \item Per $e^{x} \geq 0$, ciò risulta essere vero $\forall x \in \R$
        \item Per $x^4 -4x^3 + 4x^2 + 4x + 3 \geq 0$, ciò risulta essere vero per $\forall x \in \R$
        \item Per $(x^2-1)^3 \geq 0$, ciò risulta essere quando $x \leq 1 \lor x \geq 1$
        \item La funzione $f(x)$ non è definita per $x = \pm 1$.
    \end{itemize}

    concludendo che $f''(x) \geq 0$, dunque che $f(x)$ è convessa, quando $x < -1 \lor x > 1$.
    
    Tramite le informazioni ricavate, possiamo abbozzare il grafico della funzione:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.575]{images/es27.png}
    \end{figure}

    \newpage

    \section{Polinomio di Taylor}

    Abbiamo visto come lo studio di funzione ci permetta di abbozzare il grafico di una funzione analizzandone varie caratteristiche. Tuttavia, lo studio di funzione risulta non del tutto sufficiente per poter conoscere dettagliatamente il grafico di una funzione e i valori che essa assume.

    All'inizio del capitolo, abbiamo visto come la derivata di una funzione in un punto $x_0$ corrisponda al coefficiente angolare dell'unica sua \textit{miglior approssimazione lineare} possibile nel punto $x_0$ stesso. Il matematico Taylor pensò di estendere tale concetto di miglior funzione approssimante: invece di considerare una semplice funzione lineare, corrispondente ad un polinomio di primo grado, potremmo provare ad approssimare la funzione nel punto $x_0$ con un polinomio di $n$-esimo grado. 

    \begin{frameddefn}{Polinomio di Taylor}
        Siano $[a,b] \subseteq \R$, $\func{f}{[a,b]}{\R}$ e $x_0 \in (a,b)$. Definiamo il \textbf{polinomio di Taylor di ordine $n$ di $f$ centrato in $x_0$}, indicato come $T_n(f, x_0)$, come il polinomio:
        \[T_n(x;x_0) = f(x_0) + f'(x_0) (x-x_0) + \frac{f''(x_0)}{k!}(x-x_0)^2 + \ldots + \frac{f^{(n)}(x_0)}{n!} (x-x_0)^{n}\]
        dove $f^{(k)}$ indica la derivata di ordine $k$ della funzione $f$
    \end{frameddefn}

    Volendo esprimere il polinomio di Taylor in forma contratta, possiamo descriverlo tramite la seguente sommatoria:
    \[T_n(x;x_0) = \sum_{k = 0}^n \frac{f^{(k)}(x_0)}{k!} (x-x_0)^{k} \]
    
    Il \textbf{teorema di Taylor} afferma che, al crescere dell'ordine del polinomio di Taylor utilizzato, l'approssimazione tra la funzione $f(x)$ e il polinomio $T_n(x;x_0)$ tenda ad essere trascurabile per valori di $x$ molto vicini al centro $x_0$ (in particolare, $f(x_0) = T_n(x; x_0)(x_0)$ in quanto ogni termine ogni termine del polinomio si annullerà eccetto il primo). In altre parole, possiamo approssimare una funzione tramite un polinomio di Taylor di ordine sufficientemente alto, ma solo per valori vicini al centro.

    \begin{framedthm}{Teorema di Taylor}
        Siano $[a,b] \subseteq \R$, $\func{f}{[a,b]}{\R}$ e $x_0 \in (a,b)$. Esiste sempre una funzione $R_n(x)$ detta \textbf{resto infinitesimale} per cui si abbia che:
        \[f(x) = T_n(x;x_0) + R_n(x; x_0)\]
        dove $R_n(x; x_0) = o((x-x_0)^n)$ per $x \to x_0$

        \textit{(dimostrazione omessa)}
    \end{framedthm}

    Esistono vari modi per rappresentare il resto infinitesimale dato dal teorema di Taylor. Nel nostro caso, considereremo il \textbf{resto di Lagrange}, definito come:
    \[R_n(x; x_0) = \frac{f^{(n+1)}(\xi)}{(n+1)!} (x-x_0)^{n+1}\]
    dove $\xi \in (x, x_0)$.

    Consideriamo ad esempio la seguente funzione $f(x) = e^{\sin x}$ e supponiamo di volerla approssimare intorno al centro $\pi$. Cerchiamo quindi di trovare una risposta tramite il polinomio di Taylor di ordine $1$ centrato in $\pi$:
    \[\begin{split}
        T_1(x; \pi) &= f(\pi) + f'(\pi) (x - \pi) \\
        &= e^{\sin \pi} + \cos(\pi) e^{\sin \pi} (x-\pi) \\
        &= 1-(x-\pi)
    \end{split} \]

    Dando una veloce occhiata al grafico del polinomio ottenuto e comparandolo con quello di $f(x)$, notiamo che l'approssimazione risulta corretta esclusivamente per il centro $\pi$.

    \begin{center}
        \includegraphics[scale=0.6]{images/taylor_1.png}
    \end{center}

    \quad

    Calcolando il polinomio di ordine 2 notiamo come l'intorno di approssimazione sia aumentato notevolmente:
    \[\begin{split}
        T_2(x; \pi) &= f(\pi) + f'(\pi) (x - \pi) + \frac{f''(\pi)}{2!}(x-\pi)^2\\
        &= e^{\sin \pi} + \cos(\pi) e^{\sin \pi} (x-\pi) + \frac{(\cos^2 \pi - \sin \pi) e^{\sin \pi}}{2}(x-\pi)^2\\
        &= 1-(x-\pi) + \frac{1}{2}(x-\pi)^2
    \end{split} \]

    \begin{center}
        \includegraphics[scale=0.6]{images/taylor_2.png}
    \end{center}

    Lo sviluppo di Taylor può essere utilizzato anche per valutare limiti che danno origine ad una forma indeterminata ma che sono anche troppo complessi per essere risolti con i limiti notevoli. Ad esempio, consideriamo il seguente limite:
    \[\lim_{x \to 0} \frac{\sqrt{1-\sin^2(2x)} - e^x}{\sqrt[4]{\cos^3 x}-1}\]

    Per semplificarci la vita, approssimiamo la funzione $f(x) = \sin 2x$ tramite il suo polinomio di Taylor di terzo ordine centrato in $0$:
    \[\begin{split}
        T_3(x, 0) &= f(0) + f'(0)(x-0) + \frac{f''(0)}{2!}(x-0)^2 + \frac{f^{(3)}(0)}{3!}(x-0)^3\\
        &= \sin(2 \cdot 0) + 2\cos(2 \cdot 0)x + \frac{-4 \sin(2 \cdot 0)}{2!}x^2 + frac{-8 \cos(2 \cdot 0)}{3!}x^3 \\
        &= 2x - \frac{4}{3}x^3
    \end{split}\]

    Sappiamo che per $x \to 0$ tale sviluppo risulta essere perfettamente uguale alla funzione $f(x)$, dunque abbiamo che:
    \[\lim_{x \to 0} \frac{\sqrt{1-\sin^2(2x)} - e^x}{\sqrt[4]{\cos^3 x}-1} = \lim_{x \to 0} \frac{\sqrt{1-\rbk{2x - \frac{4}{3}x^3}^2} - e^x}{\sqrt[4]{\cos^3 x}-1}\]

    Analogamente, sostituiamo $g(x) = \cos x$ con il suo sviluppo di Taylor di terzo ordine centrato in $0$, ottenendo che:
    \[\lim_{x \to 0} \frac{\sqrt{1-\sin^2(2x)} - e^x}{\sqrt[4]{\cos^3 x}-1} = \lim_{x \to 0} \frac{\sqrt{1-\rbk{2x - \frac{4}{3}x^3}^2} - e^x}{\sqrt[4]{\rbk{1-\frac{x^2}{2}}^3}-1}\]

    Una volta rimosse le funzioni trigonometriche dal limite, possiamo procedere con le tecniche conosciute, semplificando qualche calcolo.

    \newpage

    \section{Esercizi svolti}

    \begin{framedprob}{}
        Calcolare le derivate delle seguenti funzioni:
        \begin{enumerate}
            \item $f(x) = x^4+3x^2+\sqrt[3]{x} +\ln x$
            \item $f(x) = x^4 e^{x^2}$
            \item $f(x) = (\cos x)(1+\sin^2 x)$
            \item $f(x) = x \sin x \cos x$
            \item $f(x) = \sqrt{\dfrac{x+1}{x-1}}$
            \item $f(x) = x^x$
        \end{enumerate}
    \end{framedprob}

    \textit{Soluzioni:}

    \begin{enumerate}
        \item Prima di tutto, riscriviamo la funzione come $f(x) = x^4+3x^2+{x}^{\frac{1}{3}} +\ln x$. Abbiamo quindi che:
        \[f'(x) = [x^4]'+[3x^2]'+\sbk{{x}^{\frac{1}{3}}}' +[\ln x]' =4x^3+6x+\frac{1}{3}x^{-\frac{2}{3}}+ \frac{1}{x} \]
        \[= 4x^3+6x+\frac{1}{3\sqrt[3]{x^2}}+\frac{1}{x}\]

        \item Abbiamo che:
        \[f'(x) = [x^4]' \cdot e^{x^2} + x^4 \cdot [e^{x^2}]' = 4x^3e^{x^2} + 2x^4e^{x^2}2x = e^{x^2}(2x^5+4x^3)\]

        \item Abbiamo che:
        \[\begin{split}
            f'(x) &= [\cos x]' \cdot (1+\sin^2 x) + (\cos x) \cdot [1+\sin^2 x]'\\
            &= (-\sin x)(1+\sin^2 x) + (\cos x)(2(\sin x)(\cos x))\\
            & -\sin x(1+\sin^2 x + 2 \cos^2 x)
        \end{split}\]

        \item Abbiamo che:
        \[\begin{split}
            f'(x) &= [x \sin x]' \cdot \cos x + (x \sin x) \cdot [\cos x]' \\
            &= ([x'] \cdot \sin x + x \cdot [\sin x]') \cos x - x \sin^2 x \\
            &= \sin x \cos x + x \cos^2 x - x \sin^2 x \\
        \end{split}\]

        \item Abbiamo che:
        \[\begin{split}
            f'(x) &= \sbk{\rbk{\frac{x+1}{x-1}}^{\frac{1}{2}}}'\\
            &= \frac{1}{2}\rbk{\frac{x+1}{x-1}}^{-\frac{1}{2}} \cdot \sbk{\frac{x+1}{x-1}}' \\
            &= \frac{\sqrt{x-1}}{2\sqrt{x+1}} \cdot \rbk{\frac{[x+1]' \cdot (x-1) - (x+1) \cdot [x-1]'}{(x-1)^2}} \\
            &= \frac{\sqrt{x-1}}{2\sqrt{x+1}} \cdot \frac{-2}{(x-1)^2} \\
            &= -\frac{\sqrt{x-1}}{(x-1)^2 \sqrt{x+1}} \\
        \end{split}\]


        \item Prima di tutto, riscriviamo la funzione come $f(x) = e^{x \ln x}$. Abbiamo quindi che:
        \[\begin{split}
            f'(x) &= [e^{x \ln x}]' \\
            &= e^{x \ln x} \cdot [x \ln x]'\\
            &= x^x \cdot ([x]' \cdot \ln x + x \cdot [\ln x]')\\
            &= x^x \cdot \rbk{\ln x + x \cdot \frac{1}{x}}\\
            &= x^x (\ln x + 1)\\
        \end{split}\]
    \end{enumerate}

    \begin{framedprob}{}
        Determinare massimi e minimi relativi o assoluti della funzione $f(x) = \dfrac{2x^2-1}{x^2+1}$
    \end{framedprob}

    \textit{Soluzione:}

    Il denominatore impone la condizione di esistenza $x^2 + 1 \neq 0$, la quale tuttavia risulta vera $\forall x \in \R$. Per tanto, il campo di esistenza è $\R$. Calcoliamo quindi la derivata della funzione:
    \[\begin{split}
        f'(x) &= \frac{[2x^2-1]' \cdot (x^2+1)^2-(2x^2-1) \cdot [(x^2+1)^2]'}{(x^2+1)^2} \\
        &= \frac{4x \cdot (x^2+1)^2-(2x^2-1) \cdot 2x}{(x^2+1)^2} \\
        &= \frac{6x}{(x^2+1)^2} \\
    \end{split}\]

    Studiamo quindi il segno delle due sottofunzione della derivata:
    \begin{itemize}
        \item Per $6x \geq 0$, ciò risulta essere vero quando $x \geq 0$.
        \item Per $(x^2+1)^2 \geq 0$, ciò risulta essere vero $\forall x \in \R$
    \end{itemize}

    Per tanto, abbiamo che $f'(x) \geq 0$ quando $x \geq 0$. Inoltre, $x_0 = 0$ risulta essere un punto di minimo assoluto poiché la funzione è strettamente decrescente fino a $x_0$ per poi diventare strettamente crescente.


    \begin{framedprob}{}
        Data la funzione $f(x) = \dfrac{\ln(x^2)}{x^2}$, svolgere uno studio di funzione completo e approssimare il grafico della funzione
    \end{framedprob}

    \textit{Soluzione:}

    Il logaritmo presente al numeratore impone la condizione di esistenza $x^2 > 0$, la quale risulta essere vera per $x \neq 0$. Il numeratore, invece, impone la condizione di esistenza $x \neq 0$. Il campo di esistenza della funzione risulta quindi essere $\{x \in \R \mid x \neq 0\}$.

    Notiamo quindi che:
    \[f(-x) = \frac{\ln((-x)^2)}{(-x)^2} = \dfrac{\ln(x^2)}{x^2}\]
    dunque la funzione è pari in quanto $f(-x) = f(x)$

    Calcoliamo quindi gli asintoti della funzione:
    \begin{itemize}
        \item Per $x \to 0^-$ abbiamo che:
        \[\lim_{x \to 0^-} \dfrac{\ln(x^2-1)}{x^2} = \lim_{x \to 0^-} \dfrac{\ln((0^-)^2)}{(0^-)^2} = \lim_{x \to 0^-} \dfrac{\ln(0^+)}{0^+} = -\infty\]
        dunque $x = 0$ è un asintoto verticale

        \item Per $x \to 0^+$ abbiamo che:
        \[\lim_{x \to 0^+} \dfrac{\ln(x^2-1)}{x^2} = \lim_{x \to 0^+} \dfrac{\ln((0^+)^2)}{(0^+)^2} = \lim_{x \to 0^+} \dfrac{\ln(0^+)}{0^+} = -\infty\]
        dunque $x = 0$ è un asintoto verticale anche in tale direzione

        \item Per $x \to +\infty$ abbiamo che:
        \[\lim_{x \to +\infty} \dfrac{\ln(x^2)}{x^2} = \lim_{y \to +\infty} \dfrac{\ln y}{y} = 0\]
        dunque $y = 0$ è un asintoto orizzontale

        \item Per $x \to -\infty$ abbiamo che:
        \[\lim_{x \to -\infty} \dfrac{\ln(x^2)}{x^2} = \lim_{y \to +\infty} \dfrac{\ln y}{y} = 0\]

        dunque $y = 0$ è un asintoto orizzontale anche in tale direzione
    \end{itemize}

    \newpage

    Calcoliamo gli zeri della funzione:
    \begin{itemize}
        \item Affinché $f(x) = 0$ è necessario che:
        \[\dfrac{\ln(x^2)}{x^2} = 0 \implies \ln(x^2) = 0 \implies x^2 = 1 \implies x = \pm 1\]
        dunque $x = \pm 1$ sono due zeri della funzione
        \item Per $x = 0$ la funzione non è definita, dunque non può esserci un'intersezione con l'asse delle ordinate
    \end{itemize}

    Procediamo con lo studiare la positività della funzione:
    \begin{itemize}
        \item Per $\ln(x^2) \geq 0$, ciò risulta essere vero quando $x \leq -1 \lor x \geq 1$
        \item Per $x^2 \geq 0$, ciò risulta essere vero $\forall x \in \R$
    \end{itemize}
    dunque $f(x) \geq 0$ quando $x \leq -1 \lor x \geq 1$

    Calcoliamo quindi la derivata prima:
    \[\begin{split}
        f'(x) &= \frac{[\ln(x^2)]' \cdot x^2 - \ln(x^2) \cdot \sbk{x^2}'}{x^4}\\
        &= \frac{\frac{2x}{x^2} \cdot x^2 - 2x\ln(x^2)}{x^4} \\
        &= \frac{2-2\ln(x^2)}{x^3} \\
    \end{split}\]

    e studiamo la monotonia tramite il segno di tale derivata:
    \begin{itemize}
        \item Per $2-2\ln(x^2) \geq 0$, ciò risulta essere vero quando:
        \[2-2\ln(x^2) \geq 0 \implies 1 \geq \ln(x^2) \implies e \geq x^2 \implies -\sqrt{e} \leq x \leq \sqrt{e}\]
        \item Per $x^3 \geq 0$, ciò risulta essere vero quando $x \geq 0$
        \item La funzione non è definita per $x = 0$
    \end{itemize}

    Dal grafico del segno abbiamo che:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.55]{images/es28.png}
    \end{figure}

    concludendo che $f'(x) \geq 0$, dunque che $f(x)$ è crescente, quando $x \leq -\sqrt{e} \lor 0 < x \leq \sqrt{e}$. Inoltre, ciò ci dice che $x = -\sqrt{e}$ e $x = \sqrt{e}$ sono due punti di massimo relativo. 

    Calcoliamo quindi la derivata seconda:
    \[\begin{split}
        f''(x) &= \frac{[2-2\ln(x^2)]' \cdot x^3 - (2-2\ln(x^2)) \cdot \sbk{x^3}'}{x^6} \\
        &= \frac{\frac{-4x}{x^2} \cdot x^3 - 3x^2(2-2\ln(x^2))}{x^6} \\
        &= \frac{-10 + 6\ln(x^2)}{x^4} \\
    \end{split}\]
    e studiamo la convessità tramite il segno di tale derivata:
    \begin{itemize}
        \item Per $-10 + 6\ln(x^2) \geq 0$, ciò risulta essere vero quando:
        \[-10 + 6\ln(x^2) \geq 0 \implies \ln(x^2) \geq \frac{5}{3} \implies x^2 \geq e^{\frac{5}{3}} \implies x \leq -e^{\frac{5}{6}} \lor x \geq e^{\frac{5}{6}}\]
        \item Per $x^4 \geq 0$, ciò risulta essere vero $\forall x \in \R$
        \item La funzione non è definita per $x = 0$
    \end{itemize}
    concludendo che $f''(x) \geq 0$, dunque che $f(x)$ è convessa, quando $x \leq -e^{\frac{5}{6}} \lor x \geq e^{\frac{5}{6}}$. Inoltre, ciò ci dice che $x = -e^{\frac{5}{6}}$ e $x = e^{\frac{5}{6}}$ sono due punti di flesso. 

    Tramite le informazioni ricavate, possiamo abbozzare il grafico della funzione:
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.6]{images/es29.png}
    \end{figure}
\end{document}
