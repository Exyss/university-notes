\documentclass[a4paper, 12pt]{report}

\usepackage[dvipsnames]{xcolor}

%%%%%%%%%%%%%%%%
% Set Variables %
%%%%%%%%%%%%%%%%

\def\useItalian{1}  % 1 = Italian, 0 = English

\def\courseName{Reti di Elaboratori}

\def\coursePrerequisites{Apprendimento del materiale relativo al corso \textit{Sistemi Operativi I} e conoscenze discrete di programmazione.}

\def\book{\curlyquotes{Computer Networking: A Top-Down Approach}, J. F. Kurose, K. W. Ross}

\def\authorName{Simone Bianco}
\def\email{bianco.simone@outlook.it}
\def\github{https://github.com/Exyss/university-notes}
\def\linkedin{https://www.linkedin.com/in/simone-bianco}


%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage{../../../packages/Nyx/nyx-packages}
\usepackage{../../../packages/Nyx/nyx-styles}
\usepackage{../../../packages/Nyx/nyx-frames}
\usepackage{../../../packages/Nyx/nyx-macros}
\usepackage{../../../packages/Nyx/nyx-title}
\usepackage{../../../packages/Nyx/nyx-intro}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{../../../packages/Nyx/logo.png}

\if\useItalian1
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} Università di Roma}
    \faculty{Ingegneria dell'Informazione,\\Informatica e Statistica}
    \department{Dipartimento di Informatica}
    \ifdefined\book
        \subtitle{Appunti integrati con il libro \book}
    \fi
    \author{\textit{Autore}\\\authorName}
\else
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} University of Rome}
    \faculty{Faculty of Information Engineering,\\Informatics and Statistics}
    \department{Department of Computer Science}
    \ifdefined\book
        \subtitle{Lecture notes integrated with the book \book}
    \fi
    \author{\textit{Author}\\\authorName}
\fi


\title{\courseName}
\date{\today}

% \supervisor{Linus \textsc{Torvalds}}
% \context{Well, I was bored\ldots}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
    \maketitle

    % The following style changes are valid only inside this scope 
    {
        \hypersetup{allcolors=black}
        \fancypagestyle{plain}{%
        \fancyhead{}        % clear all header fields
        \fancyfoot{}        % clear all header fields
        \fancyfoot[C]{\thepage}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}}

        \romantableofcontents
    }

    \introduction

    %%%%%%%%%%%%%%%%%%%%%

    \chapter{Introduzione alle reti}

    \section{Rete, Host e Collegamenti}

    \quad

    \begin{frameddefn}{Rete e Link}
        Una \textbf{rete} è un'infrastruttura composta da dispositivi detti \textbf{nodi della rete} in grado di scambiarsi informazioni tramite dei mezzi di comunicazione, wireless o cablati, detti \textbf{link (o collegamenti)}
    \end{frameddefn}

    \begin{frameddefn}{Nodi di una rete}
        I \textbf{nodi} costituenti una rete vengono differenziati in \textbf{due macro-categorie}:
        \begin{itemize}
            \item \textbf{Sistemi terminali}, differenziati a loro volta in
            \begin{itemize}
                \item \textbf{Host}, ossia un dispositivo di proprietà dell'utente dedicato ad eseguire applicazioni utente
                \item \textbf{Server}, ossia un dispositivo di elevate prestazioni destinato ad eseguire programmi che forniscono un servizio a diverse applicazioni utente
            \end{itemize}
            \item \textbf{Dispositivi di interconnessione}, ossia dei dispositivi atti a modificare o prolungare il segnale ricevuto, differenziati a loro volta in:
            \begin{itemize}
                \item \textbf{Router}, ossia dispositivi che collegano una rete ad una o più reti
                \item \textbf{Switch}, ossia dispositivi che collegano più sistemi terminali all'interno di una rete
                \item \textbf{Modem}, ossia dispositivi in grado di trasformare la codifica dei dati in segnale e viceversa
            \end{itemize}
        \end{itemize}
    \end{frameddefn}

    \newpage

    In particolare, classifichiamo le varie tipologie di rete in:
    \begin{itemize}
        \item \textbf{Personal Area Network (PAN)}, avente scala ridotta, solitamente equivalente a pochi metri (es: una rete Bluetooth)
        \item \textbf{Local Area Network (LAN)}, solitamente corrispondente ad una rete privata che collega i sistemi terminali di un appartamento (es: una rete Wi-Fi o Ethernet). Ogni sistema terminale possiede un indirizzo che lo identifica univocamente all'interno della LAN. Si differenziano in \textbf{LAN con cavo condiviso}, ossia dove tutti i dispositivi sono connessi al router tramite un cavo comune, e \textbf{LAN con switch}, ossia dove tutti i dispositivi sono connessi ad uno o più switch, i quali a loro volta sono connessi al router
        \item \textbf{Metropolitan Area Network (MAN)}, avente scala pari ad una città
        \item \textbf{Wide Area Network (WAN)}, avente scala pari ad un paese o una nazione, solitamente gestita da un \textbf{Internet Service Provider (ISP)}.
        
        Si differenziano in \textbf{WAN point-to-point}, ossia collegante due reti tramite un singolo mezzo di trasmissione, e \textbf{WAN a commutazione}, ossia collegante più reti tramite più mezzi e dispositivi di collegamento
        \item L'\textbf{Internet}, avente scala globale
    \end{itemize}

    \quad

    \textbf{Esempi:}

    \begin{itemize}
        \item \textbf{LAN a cavo condiviso}
        \begin{center}
            \includegraphics[scale=0.6]{images/network1.png}
        \end{center}

        \item \textbf{LAN con switch}
        \begin{center}
            \includegraphics[scale=0.5]{images/network2.png}
        \end{center}
        
        \newpage

        \item \textbf{Rete composta}
        \begin{center}
            \includegraphics[scale=0.5]{images/network3.png}
        \end{center}
        
    \end{itemize}

    I supporti fisici utilizzabili per una trasmissione si differenziano in:
    \begin{itemize}
        \item \textbf{Doppino intrecciato} (ad esempio un cavo Ethernet), composto da due fili di rame isolati, uno utilizzato per inviare i dati ed uno per riceverli
        \item \textbf{Cavo coassiale}, composto da due conduttori di rame concentrici, entrambi bidirezionali, avente una larghezza di banda maggiore
        \item \textbf{Cavo in fibra ottica}, composto da una fibra di vetro che trasporta impulsi luminosi (dunque alla velocità della luce) al suo interno, ognuno rappresentante un singolo bit
        \item \textbf{Trasmissione wireless}, realizzata tramite l'invio di un segnale radio propagato nell'aria (es: rete cellulare, satellitare o Wi-Fi)
    \end{itemize}


    \quad

    \section{Struttura di Internet}

    \quad

    \begin{frameddefn}{Rete internet}
        Definiamo come \textbf{internet} (abbreviativo di internetwork) una \textbf{rete di reti}, ossia una rete che mette in comunicazione due o più reti tra di loro.

        \textit{\textbf{Attenzione:}} nonostante ciò che viene comunemente chiamato l'\textbf{Internet} sia una internet, è necessario puntualizzare che con tale termine comune viene indicata \textbf{la rete di tutte le reti}.
    \end{frameddefn}

    \newpage

    Al suo interno, la struttura di Internet risulta essere composta da:
    \begin{itemize}
        \item \textbf{Periferia della rete (network edge)}, corrispondente all'insieme di tutti i sistemi terminali connessi.
        \begin{center}
            \includegraphics[scale=0.55]{images/internet1.png}
        \end{center}

        \item \textbf{Reti di accesso (access network)}, corrispondente ai collegamenti fisici che connettono un sistema terminale al primo \textbf{edge router}, ossia il primo router presente nel percorso dal sistema terminale di origine ad un qualsiasi altro sistema terminale di destinazione. 
        \begin{center}
            \includegraphics[scale=0.55]{images/internet2.png}
        \end{center}
        
        In particolare, l'accesso all'Internet può essere effettuato in più modi:
        \begin{itemize}
            \item \textbf{Accesso via cavo}, tramite supporti fisici connessi direttamente ad una rete di distribuzione, detta \textbf{cable headend} (es: il centralino di un ISP).
            \item \textbf{Accesso via Digital Subscriber Line (DSL)}, dove viene utilizzata la linea telefonica esistente per collegarsi alla rete dell'ISP
            \item \textbf{Accesso via Wireless LAN (WLAN)}, tramite un collegamento wireless ad una stazione base detta \textbf{access point} connessa con il router, a sua volta connesso con un cable headend
            \item \textbf{Accesso via rete cellulare}, dove viene utilizzata la rete cellulare esistente per collegarsi alla rete dell'ISP
            \item \textbf{Accesso via rete aziendale}, tramite una rete aziendale (o universitaria, privata, ...) direttamente connessa ad Internet
        \end{itemize}
        \item \textbf{Nucleo di rete (core o backbone)}, ossia un sistema di router interconnessi tra di loro, corrispondente all'insieme di nodi tramite cui viene realizzata la vera interconnessione tra tutte le reti.
        \begin{center}
            \includegraphics[scale=0.55]{images/internet3.png}
        \end{center}

        In particolare, all'interno del backbone di Internet sono presenti \textbf{più livelli di reti ISP} (es: regionali, nazionali, aziendali, ...), le quali devono essere interconnesse tra di loro tramite degli \textbf{Internet Exchange Point (IXP)}.

        Inoltre, nel recente periodo, nel backbone di Internet sono state integrate anche delle grandi reti private aziendali, ossia le \textbf{reti dei content provider} (es: Google, Netflix, ...), le quali, ormai, funzionano come vere e proprie ISP.
        \begin{center}
            \includegraphics[scale=0.45]{images/internet4.png}
        \end{center}
    \end{itemize}

    \quad

    \section{Pacchetti, Forwarding e Routing}

    \quad

    \begin{frameddefn}{Pacchetto e Velocità di trasmissione}
        Dato un messaggio $m$ da trasferire tra due terminali, definiamo come \textbf{pacchetti} l'insieme di blocchi di $L$ bit tali che $m = \{p_1, \ldots, p_k\}$.

        Ogni pacchetto viene trasmesso nella rete ad una \textbf{velocità di trasmissione} $R$ (anche detta larghezza di banda o capacità del collegamento).
    \end{frameddefn}

    \begin{frameddefn}{Forwarding e Routing}
        Le funzioni fondamentali di una rete si dividono in:
        \begin{itemize}
            \item \textbf{Forwarding o Switching (commutazione)}, ossia un'azione locale tramite cui vengono spostati i pacchetti in arrivo dal collegamento di ingresso del router al collegamento appropriato di uscita. Viene effettuato attraverso una \textbf{local forwarding table}, contenente gli indirizzi dei nodi locali
            \item \textbf{Routing (instradamento)}, ossia un'azione globale tramite cui vengono determinati i percorsi origine-destinazione seguiti dai pacchetti. Viene effettuato tramite \textbf{algoritmi di instradamento}
        \end{itemize}
    \end{frameddefn}

    In particolare, la commutazione può avvenire in due modi:
    \begin{itemize}
        \item \textbf{Commutazione di pacchetto}:
        
        \begin{itemize}
            \item La rete inoltra i pacchetti da un router all'altro attraverso i collegamenti presenti nell'instradamento dall'origine alla destinazione.
            \item Una volta inviato, un pacchetto deve completamente raggiungere il nodo a cui sta attualmente venendo inviato prima di poter essere trasmesso al collegamento successivo (\textbf{store \& forward})
            \item Se la velocità di trasmissione sul link di entrata supera la velocità di trasmissione di quello in uscita, i pacchetti verranno messi all'interno di una coda, in attesa di essere trasmessi sul link di uscita
            \item Se il buffer della coda raggiunge capienza massima, i pacchetti verranno scartati (\textbf{perdita di pacchetti}), per poi, se necessario, essere rinviati 
        \end{itemize}

        \begin{center}
            \includegraphics[scale=0.45]{images/packet.png}
        \end{center}

        \item \textbf{Commutazione di circuito}:
        
        \begin{itemize}
            \item La banda dei mezzi di trasmissione viene \textbf{suddivisa} in parti, riservando ognuna di essere ad una comunicazione tra un'origine ed una destinazione.
            \item Per via di tale suddivisione, il numero di utenti massimo della rete risulta essere \textbf{limitato dal numero di suddivisioni}
            
            \item La suddivisione può essere effettuata in due modalità:
            \begin{itemize}
                \item \textbf{Frequency Division Multiplexing (FDM)}, dove le frequenze del mezzo di trasmissione vengono suddivise in bande di frequenza, ognuna di esse riservata ad una singola comunicazione, la quale può utilizzare al massimo la banda ad essa riservata
                \begin{center}
                    \includegraphics[scale=0.375]{images/circuit1.png}
                \end{center}

                \item \textbf{Time Division Multiplexing (TDM)}, dove il tempo viene suddiviso in slot, ognuno di essi riservato ad una singola comunicazione, la quale può utilizzare l'intera banda del mezzo per il breve lasso di tempo dedicato.
                
                \begin{center}
                    \includegraphics[scale=0.375]{images/circuit2.png}
                \end{center}
            \end{itemize}
        \end{itemize}
    \end{itemize}
    
    Nonostante la \textbf{commutazione di pacchetto} permetta l'accesso di un numero maggiore di utenti e non necessiti di stabilire una configurazione del collegamento, la presenza di una possibile perdita di pacchetti rende tale tipo di commutazione prettamente ottimo per \textbf{trasmissioni "bursty"}, ossia intermittenti e con lunghi periodi di inattività.

    \section{Misura delle prestazioni}

    \quad

    \begin{frameddefn}{Larghezza di banda e Transmission rate}
        Con il termine \textbf{larghezza di banda (bandwidth)} indichiamo due concetti strettamente legati tra loro:
        \begin{itemize}
            \item La quantità (espressa in $Hz$) rappresentante la \textbf{larghezza dell'intervallo di frequenze} utilizzato dal sistema trasmissivo, ossia l'intervallo di frequenze utilizzato dal sistema trasmissivo. Maggiore è tale quantità, maggiore è la quantità di informazioni veicolabili tramite il mezzo di trasmissione.
            \item La quantità (espressa in $b/s$) detta anche \textbf{transmission rate (o bit rate)} rappresentante la \textbf{quantità di bit al secondo} che un link \textbf{garantisce di trasmettere}. Tale quantità è proporzionale alla larghezza di banda (in $Hz$)
        \end{itemize}
    \end{frameddefn}

    \begin{frameddefn}{Throughput}
        Con il termine \textbf{throughput} indichiamo la \textbf{quantità di bit} al secondo che \textbf{passano attraverso un nodo} della rete.
    \end{frameddefn}

    \begin{framedobs}{}
        A differenza del \textbf{transmission rate}, il quale fornisce una misura della \textbf{potenziale velocità di un link}, il \textbf{throughput} fornisce una misura dell'\textbf{effettiva velocità di un link}. In generale, dunque, si ha che $T < R$ dove $T$ è il throughput e $R$ è il transmission rate
    \end{framedobs}

    \begin{frameddefn}{Collo di bottiglia}
        Dato un percorso end-to-end, ossia tra un dispositivo e un altro, definiamo come \textbf{collo di bottiglia} il link limitante il throughput dei link presenti su tale percorso
    \end{frameddefn}

    \textbf{Esempio:}
    \begin{itemize}
        \item Consideriamo il seguente percorso
        \begin{center}
            \includegraphics[scale=0.45]{images/ex1.png}
        \end{center}
        \item Il link $L2$ risulta essere il collo di bottiglia di tale percorso, limitando il throughput del percorso a $100$ kb/s
    \end{itemize}

    \begin{frameddefn}{Delay di trasmissione}
        Definiamo come \textbf{delay (o latenza) di trasmissione} il tempo necessario ad un nodo per immettere un pacchetto su un link, corrispondente a:
        \[D_t = \frac{L}{R}\]
        dove $L$ è la dimensione del pacchetto e $R$ è il transmission rate del link
    \end{frameddefn}

    \begin{frameddefn}{Delay di propagazione}
        Definiamo come \textbf{delay (o latenza) di propagazione} il tempo impiegato dall'\textbf{ultimo bit di blocco di dati} posto su un link ad essere propagato fino al nodo di destinazione, corrispondente a:
        \[D_p = \frac{k}{v}\]
        dove $k$ è la lunghezza del link e $v$ è la velocità di propagazione del link
    \end{frameddefn}

    \begin{frameddefn}{Delay di un pacchetto}
        Definiamo come \textbf{delay (o latenza) di un pacchetto} il tempo totale necessario ad un pacchetto per essere inviato completamente da un nodo origine ad un nodo destinatario
        \[D_n = D_e + D_q + D_t + D_p\]
        dove:
        \begin{itemize}
            \item $D_e$ è il \textbf{delay di elaborazione del nodo}, dipendente dalle operazioni di controllo svolte dal nodo
            \item $D_q$ è il \textbf{delay di queueing}, ossia l'attesa del pacchetto all'interno della coda del nodo prima di essere trasmesso, dipendente dalla quantità di pacchetti presenti nella coda
            \item $D_t$ è il delay di trasmissione del link
            \item $D_p$ è il delay di propagazione del link
        \end{itemize}
    \end{frameddefn}

    \begin{framedprop}{Prodotto rate per delay di propagazione}
        Dato un link con transmission rate $R$ e delay di propagazione $D_p$, il prodotto
        \[B_{max} = R \cdot D_p = \frac{L \cdot k}{D_t \cdot v}\]
        rappresenta il \textbf{massimo numero di bit distribuiti tutto sul cavo}
    \end{framedprop}

    \textbf{Esempi:}

    \begin{enumerate}
        \item Si consideri un router A che trasmette pacchetti, ognuno di lunghezza $L=4000$ bit, su un canale di trasmissione con rate $R=10$ Mb/s verso un router B all'altro estremo del link. Si supponga che il delay di propagazione sia pari a $0.2$ ms.
        
        \begin{itemize}
            \item Quanto impiega il router A a trasmettere un pacchetto al router B?
            \[D_t = \frac{L}{R} = \frac{4 \cdot 10^3 \;b}{10^7 \;b/s} = 4 \cdot 10^{-4} \;s = 0.4 \;ms\]
            \item Quanto impiega il router A a trasmettere un bit al router B?
            \[D_{1b} = \frac{1}{R} = \frac{1 \;b}{10^7 \;b/s} = 10^{-7} \;s = 0.1 \; \mu s\]
            \item Qual è il massimo numero di pacchetti al secondo che possono essere trasmessi sul link?
            \[1 \;P = 4000 \;b \implies 1 \; b = \frac{1}{4000} \; P \implies \]
            \[\implies R = 10^7 \;b/s = \frac{10^7}{4000} \;P/s = \frac{1}{4} \cdot 10^4 \; P/s = 2500 \;P/s\]
            \item Supponendo che il router A invii i pacchetti uno dopo l'altro senza introdurre ritardi tra la
            trasmissione di un pacchetto e il successivo, quanto tempo impiega il router B a ricevere
            4 pacchetti?
            
            Poiché i pacchetti vengono inviati senza alcun delay tra di essi, possiamo considerare tali pacchetti come un unico grande pacchetto di dimensione $4 \cdot L$, implicando che
            \[D_{4t} = \frac{4 \cdot L}{R} = \frac{16 \cdot 10^3 \;b}{10^7 \;b/s} = 16 \cdot 10^{-4} \;s = 1.6 \;ms\]
            Inoltre, per lo stesso motivo, il tempo di propagazione rimarrà inalterato, poiché esso non dipende dalla lunghezza del pacchetto, ma solo dalla lunghezza e della velocità di propagazione del link. Di conseguenza, il tempo totale impiegato sarà $1.6 \; ms \,+ 0.2\;ms\,= 1.8 \;ms$
            \item Qual è il massimo numero di bit e il numero di pacchetti che possono essere presenti sul canale?
            \[P_{max} = R \cdot D_p = 10^7 \;b/s \cdot 0.2 \; ms \, = 2000 \; b = \frac{1}{2} \;P\]
        \end{itemize}
        
        \item Si consideri un host A che vuole inviare un file molto grande, 4 milioni di byte, a un host B. Il percorso tra A e B ha 3 link $L_1, L_2, L_3$, ognuno di lunghezza $300$ km, ciascuno con rate rispettivo $R_1=500$ kb/s, $R_2=2$ Mb/s e $R_3=1$ Mb/s.
        \begin{itemize}
            \item Assumendo l'assenza di ulteriore traffico nella rete, qual è il throughput per il file
            transfer?

            Poiché il link $L_1$ risulta essere il collo di bottiglia del percorso, il throughput risulta essere $R_1=500$ kb/s

            \item Qual è il tempo totale impiegato per trasferire il file al'host B assumendo che i link siano cavi in fibra ottica?
            
            Poiché non vi è specificata la lunghezza di ogni pacchetto, assumiamo che il file venga inviato come un unico grande pacchetto, implicando che $L = 4 \cdot 10^6 \;B = 32 \cdot 10^6 \; b$.

            Di conseguenza, si ha che:
            \[D_{t}(L_1) = \frac{32 \cdot 10^6 \; b}{5 \cdot 10^5\; b/s} = 64 \; s\]
            \[D_{t}(L_2) = \frac{32 \cdot 10^6 \; b}{2 \cdot 10^6\; b/s} = 16 \; s\]
            \[D_{t}(L_3) = \frac{32 \cdot 10^6 \; b}{1 \cdot  10^6\; b/s} = 32 \; s\]

            Poiché $L_1, L_2, L_3$ sono cavi in fibra ottica, la velocità di propagazione su di essi corrisponde alla velocità della luce, pari a $\sim 3 \cdot 10^8 \; m/s$. Dunque, il delay di propagazione di ogni link corrisponderà a:
            \[D_p = \frac{3 \cdot 10^5 \;m}{3 \cdot 10^8 \; m/s} = 1 \; ms\]

            Infine, concludiamo che il tempo totale impiegato corrisponda a:
            \[D_{tot} = D_t(L_1)+D_t(L_2)+D_t(L_3)+3 \cdot D_p = 64 \; s + 16 \; s + 32 \; s + 3 \cdot 1 \; ms = 112,003 \; s\]
        \end{itemize}

        \item Si consideri la rete nella seguente figura, dove $C_1, C_2, C_3$ e $\tau_1, \tau_2, \tau_3$ sono rispettivamente i transmission rate e i delay di propagazione dei tre link.
        
        Al tempo $t=0$, la coda di uscita di $R_1$ contiene 2 pacchetti diretti ad $A$. Assumendo che la lunghezza dei pacchetti sia $L=512$ b, si indichi per ciascun pacchetto l'istante in cui esso viene completamente ricevuto da $A$. 

        \begin{center}
            \includegraphics[scale=0.55]{images/ex2.png}
        \end{center}

        Per aiutarci durante il calcolo, tracciamo il contenuto di ogni coda al passare del tempo:

        \begin{center}
            \includegraphics[scale=0.55]{images/ex3.png}
        \end{center}
        
        Dunque, il tempo totale impiegato dal primo pacchetto  corrisponderà a:
        \[T_1 = \frac{L}{C_1}+\tau_1+\frac{L}{C_2}+\tau_2+\frac{L}{C_3}+\tau_3 = 4 \; ms + 1 \; ms + 2\;ms+2\;ms+1\;ms+1\;ms=11\;ms\] 

        Analogamente, il tempo totale impiegato dal secondo pacchetto corrisponderà a:
        \[T_2 = 2 \cdot \frac{L}{C_1}+\tau_1+\frac{L}{C_2}+\tau_2+\frac{L}{C_3}+\tau_3 = 8 \; ms + 1 \; ms + 2\;ms+2\;ms+1\;ms+1\;ms=15\;ms\] 

        \item Si consideri la rete nella seguente figura, dove $C_1, C_2, C_3$ e $\tau_1, \tau_2, \tau_3$ sono rispettivamente i transmission rate e i delay di propagazione dei tre link.
        
        Al tempo $t=0$, la coda di uscita di $R_1$ contiene 2 pacchetti diretti ad $A$. Assumendo che la lunghezza dei pacchetti sia $L=512$ b, si indichi per ciascun pacchetto l'istante in cui esso viene completamente ricevuto da $A$.

        Inoltre, supponendo che vi siano $n$ pacchetti, si indichi una formula generica descrivente per ciascun pacchetto l'istante in cui esso viene completamente ricevuto da $A$

        \begin{center}
            \includegraphics[scale=0.55]{images/ex4.png}
        \end{center}

        Come nel caso precedente, tracciamo il contenuto di ogni coda al passare del tempo:

        \begin{center}
            \includegraphics[scale=0.65]{images/ex5.png}
        \end{center}
        
        Il tempo totale impiegato dal primo pacchetto  corrisponderà a:
        \[T_1 = \frac{L}{C_1}+\tau_1+\frac{L}{C_2}+\tau_2+\frac{L}{C_3}+\tau_3 = 1 \; ms + 1 \; ms + 2\;ms+2\;ms+8\;ms+4\;ms=18\;ms\] 

        Notiamo come, a differenza del caso precedente, il secondo pacchetto giunge nelle code successive mentre il primo pacchetto deve essere ancora completamente spedito, implicando che esso debba essere inserito nella coda di attesa.

        Dunque, una volta raggiunta la coda finale, il secondo pacchetto potrà essere inviato solo una volta completato il primo pacchetto.
        
        Di conseguenza, il suo tempo totale di ricezione corrisponde a:

        \[T_2 = T_1 + \frac{L}{C_3} = 18\;ms+8\;ms = 26\;ms\]

        Applicando lo stesso ragionamento nel caso di $n$ pacchetti, la formula generica descrivente l'istante di ricezione dell'$n$-esimo pacchetto corrisponde a:
        \[T_n = T_{n-1} + \frac{L}{C_3} = T_{n-2} + 2 \cdot \frac{L}{C_3} = \ldots = T_1 + (n-1)\frac{L}{C_3} = 18\;ms+8(n-1)\;ms\]
    \end{enumerate}

    \quad

    \section{Stack protocollare TCP/IP}

    \quad

    \begin{frameddefn}{Protocollo}
        Un \textbf{protocollo} definisce l'insieme di \textbf{regole} che il dispositivo mittente e il dispositivo destinatario, così come tutti i sistemi intermedi coinvolti, devono rispettare per essere in grado di comunicare.
    \end{frameddefn}

    In situazioni più complesse, potrebbe essere opportuno suddividere i compiti necessari alla comunicazione fra \textbf{più livelli (layer)}, nel qual caso è richiesto \textbf{un protocollo per ciascun livello}. Tramite un layering dei protocolli, dunque, è possibile suddividere un compito complesso in compiti più semplici, ognuno gestibile da un singolo protocollo.

    In particolare, ogni layer è \textbf{indipendente dagli altri} (modularizzazione), utilizzando i servizi forniti dal layer inferiore e offrendo servizi al layer superiore.
    
    Ogni layer, dunque, può essere considerato come una \textbf{black box} con opportuni ingressi ed uscite, senza necessità di essere a conoscenza delle modalità con cui i dati in ingresso vengano trasformati in quelli di uscita.

    Quando è richiesta una \textbf{comunicazione bidirezionale}, ciascun layer deve essere in grado di effettuare entrambi i compiti richiesti, ossia manipolare i dati in input per inviarli al livello superiore o manipolarli per inviarli al livello inferiore.

    \begin{center}
        \includegraphics[scale=0.5]{images/protocol1.png}
    \end{center}

    In particolare, l'effetto ottenuto tramite una suddivisione in uno stack di layer equivalenti permette l'instaurazione di un \textbf{collegamento logico} tra ogni livello dello stack: il protocollo implementato in ciascun livello specifica una comunicazione diretta tra i pari livelli delle due parti: il layer $N$ di un dispositivo comunica solo ed esclusivamente con il layer $N$ di tutti i dispositivi.

    \begin{center}
        \includegraphics[scale=0.5]{images/protocol2.png}
    \end{center}

    Inoltre, per via dell'estrema modularizzazione ottenuta, viene facilitata la manutenzione e l'aggiornamento del sistema, poiché il cambiando dell'implementazione del servizio di un layer rimane trasparente al resto del sistema.

    \begin{frameddefn}{Stack protocollare TCP/IP}
        La principale forma di stack protocollare utilizzata corrisponde allo \textbf{stack protocollare TCP/IP}, la cui struttura a layer corrisponde a:

        \begin{tabular}{p{0.65 \textwidth} p{0.35 \textwidth}}
            \begin{itemize}
                \item \textbf{Livello di Applicazione}, il quale fornisce supporto alle applicazioni facente uso della rete (protocolli HTTP, SMTP, FTP, DNS, ...). 
                
                \item \textbf{Livello di Trasporto}, il quale gestisce il trasferimento dei pacchetti dal processo del dispositivo mittente a quello del dispositivo destinatario (protocolli TCP, UDP, ...).
                
                \item \textbf{Livello di Rete}, il quale gestisce l'instradamento dei pacchetti dall'origine alla destinazione (protocolli IP, ...).
                
                \item \textbf{Livello di Collegamento (o Link)}, il quale gestisce la trasmissione dei pacchetti da un nodo a quello successivo sul percorso (protocolli Ethernet, Wi-Fi, PPP, ...). Lungo il percorso, un pacchetto può essere gestito da protocolli diversi.
                
                \item \textbf{Livello Fisico}, dove avviene il vero e proprio trasferimento dei singoli bit
            \end{itemize}

            &

            \begin{center}
                \includegraphics[scale=0.7]{images/tcp_ip.png}
            \end{center}
        \end{tabular}
        
        I livelli di Applicazione e di Trasporto sono gestiti tramite \textbf{software}, mentre i livelli di Collegamento e Fisico tramite \textbf{hardware}.
    \end{frameddefn}

    Durante l'invio di un pacchetto, quest'ultimo, partendo dal livello applicazione del dispositivo sorgente, \textbf{percorre tutti i layer dello stack protocollare}, fino a giungere al livello fisico, dove viene effettivamente inviato al nodo successivo.

    Tutti i nodi intermedi presenti sul percorso lavoreranno utilizzando \underline{solo i livelli necessari}. In particolare, ogni dispositivo utilizzerà il livello di collegamento, in modo da poter spedire il pacchetto stesso verso il nodo successivo del percorso.

    Nel caso in cui si raggiunga il \textbf{punto di scambio tra due reti}, solitamente un edge router, verrà utilizzato anche il livello di rete.

    \begin{center}
        \includegraphics[scale=0.385]{images/stack1.png}
    \end{center}

    Prima di essere spedito al livello inferiore, ogni pacchetto viene \textbf{incapsulato}: una volta ricevuto il pacchetto dal layer superiore, il layer attuale applica un proprio \textbf{header (o intestazione)}, aggiungendo informazioni necessarie al layer del dispositivo di destinazione corrispondente a quello attuale.

    In particolare, ad ogni livello un pacchetto assume il nome di:
    \begin{itemize}
        \item \textbf{Messaggio (al livello di applicazione)}, corrispondente al pacchetto originale, senza alcuna intestazione
        \item \textbf{Segmento (al livello di trasporto)}, corrispondente al messaggio ricevuto dal layer superiore a cui viene aggiunto un header di trasporto
        \item \textbf{Datagramma (al livello di rete)}, corrispondente al segmento ricevuto dal layer superiore a cui viene aggiunto un header di rete
        \item \textbf{Frame (al livello di collegamento)}, corrispondente al datagramma ricevuto dal layer superiore a cui viene aggiunto un header di collegamento
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.385]{images/encap.png}
    \end{center}

    Poiché lo stack protocollare TCP/IP prevede la presenza di \textbf{più protocolli nello stesso livello}, ogni livello deve essere in grado di effettuare operazioni di:
    \begin{itemize}
        \item \textbf{Multiplexing}, dove ogni protocollo deve essere in grado di incapsulare (uno alla volta) i pacchetti ricevuti da più protocolli presenti al livello superiore
        \begin{center}
            \includegraphics[scale=0.425]{images/multiplex.png}
        \end{center}

        \newpage

        \item \textbf{Demultiplexing}, dove ogni protocollo deve essere in grado di decapsulare i pacchetti ricevuti ed inviarli a più protocolli presenti nel livello superiore\begin{center}
            \includegraphics[scale=0.425]{images/demultiplex.png}
        \end{center}
    \end{itemize}

    Per realizzare ciò, nell'header di ogni layer viene inserito un \textbf{campo speciale} in grado di identificare quale sia il protocollo di appartenenza di tale pacchetto.

    Un'evoluzione dello stack protocollare TCP/IP è il \textbf{modello Open Systems Interconnection (OSI)}, dove vengono interposti due livelli tra il livello di applicazione e il livello di trasporto:
    
    \begin{itemize}
        \item \textbf{Livello di Presentazione}, utilizzato per consentire alle applicazioni di interpretare i dati (es: crittografia, compressione, ...)
        \item \textbf{Livello di Sicurezza}, utilizzato per gestire servizi come la sincronizzazione o il ripristino dello scambio di dati
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.425]{images/osi_model.png}
    \end{center}

    \chapter{Livello di Applicazione}

    \section{Principi delle applicazioni di rete}

    \quad

    \begin{frameddefn}{Paradigma di comunicazione}
        Un \textbf{paradigma di comunicazione} è una metodologia di scambio informazioni e gestione delle connessioni all'interno di una rete, principalmente all'interno di Internet.
    \end{frameddefn}

    In particolare, i due principali paradigmi utilizzati sono:

    \begin{itemize}
        \item \textbf{Paradigma Client-Server}, dove i sistemi terminali vengono divisi in due categorie:
        \begin{itemize}
            \item \textbf{Client}, il quale comunica solo ed esclusivamente con un server, \textbf{richiedendo dei servizi} a quest'ultimo, e può rimanere anche inattivo se non necessario, implicando che esso possa avere indirizzi IP dinamici nel tempo. In particolare, per tali caratteristiche, non vi è una comunicazione client-client, ma solo una comunicazione client-server-client
            \item \textbf{Server}, il quale possiede un indirizzo IP permanente, rimanendo sempre attivo in attesa di \textbf{fornire servizi} ai vari client richiedenti
        \end{itemize}

        Ad esempio, i protocolli HTTP, FTP e IMAP sono basati su tale paradigma
        
        \item \textbf{Paradigma Peer-to-Peer (P2P)}, dove i sistemi terminali vengono detti \textbf{peer} (tradotto: \textit{pari, di egual importanza}) ed ognuno di essi è in grado di comunicare direttamente con ogni altro peer (assumendo quindi sia il compito di client che di server).
        
        In particolare, ogni peer \textbf{richiede e fornisce servizi ad altri peer}, rendendo il sistema \textbf{estremamente scalabile}: ogni nuovo peer incrementa le capacità di servizio e le richieste di servizio.

        Inoltre, come nel caso dei client, ogni peer può connettersi alla rete in modo intermittente utilizzando IP dinamici, diminuendo temporaneamente la quantità di servizi fornibili nella rete. Di conseguenza, la loro gestione risulta estremamente più complessa, ma anche più performante nel caso di un numero elevato di peer.

        Un classico esempio di utilizzo del paradigma P2P risultano essere i vari protocolli legati al torrenting e alla condivisione di file di grandi dimensioni.
    \end{itemize}

    \begin{frameddefn}{Processo}
        Un \textbf{processo} è un programma in esecuzione all'interno di un sistema terminale.

        In particolare, un \textbf{processo client} è un processo che avvia una comunicazione, mentre un \textbf{processo server} è un processo che attende di essere contattato da un processo client.
    \end{frameddefn}

    All'interno dello stesso sistema, due processi comunicano tra di loro utilizzando una comunicazione \textbf{inter-process}, definita dal sistema operativo. I processi situati su sistemi diversi, invece, comunicano tra di loro tramite \textbf{scambio di messaggi}

    \begin{frameddefn}{Socket}
        Un \textbf{socket} è un'\textbf{astrazione software} tramite cui un processo può inviare e ricevere messaggi tramite il socket di un altro processo. Per poter comunicare, dunque, due processi devono connettersi tramite due socket (uno ciascuno), identificati da una coppia \texttt{<Indirizzo\_IP, Numero\_Porta>}
    \end{frameddefn}

    Ogni protocollo a livello di applicazione definisce:
    \begin{itemize}
        \item Le tipologie di messaggi scambiati (es: richiesta e risposta)
        \item La sintassi del messaggio
        \item La semantica del messaggio
        \item Le regole per come e quando i processi inviano e rispondono ai messaggi
    \end{itemize}

    In particolare, i protocolli a tale livello si differenziano in \textbf{protocolli aperti}, ossia definiti secondo uno standard pubblico ed adottato comunemente da ogni applicazione (es: HTTP, FTP, ...), e \textbf{protocolli proprietari}, ossia non pubblici e fini all'applicazione stessa (es: Skype, ...).

    Per poter funzionare correttamente, ogni applicazione di rete necessita di alcuni \textbf{servizi di trasporto}. In particolare, esse possono necessitare di:
    \begin{itemize}
        \item \textbf{Integrità dei dati}, ossia un trasferimento dei dati affidabile al 100\%, senza alcuna perdita di pacchetto o corruzione dei dati
        \item \textbf{Garanzie temporali}, ossia un basso ritardo per la ricezione dei dati
        \item \textbf{Garanzie di throughput}, ossia una quantità minima di throughput dati
        \item \textbf{Sicurezza}, ad esempio crittografia o integrità dei dati a seguito di manomissioni 
    \end{itemize}

    \begin{frameddefn}{Transmission Control Protocol (TCP)}
        Il \textbf{Transmission Control Protocol (TCP)} è un protocollo risiedente sul \textbf{layer di trasporto} in grado di fornire \textbf{trasporto affidabile}, ossia senza perdita di alcun pacchetto, e controllo del flusso e della congestione, in cambio di un'assenza di garanzie temporali, di throughput e di sicurezza.

        Inoltre, il protocollo TCP è \textbf{orientato alla connessione}, ossia richiedente una configurazione \textbf{(handshaking)} tra il processo client e il processo server
    \end{frameddefn}

    \begin{frameddefn}{User Datagram Protocol (UDP)}
        L'\textbf{User Datagram Protocol (UDP)} è un protocollo risiedente sul \textbf{layer di trasporto} in grado di fornire \textbf{trasporto veloce} poiché \textbf{non orientato alla connessione} ed \textbf{estremamente scarno}, ossia sprovvisto di: trasporto affidabile, controllo del flusso e della congestione e garanzie temporali, di throughput e di sicurezza
    \end{frameddefn}

    Poiché per loro natura i protocolli TCP ed UDP sono privi di garanzie di sicurezza, i messaggi scambiati tra socket TCP e UDP risultano sprovvisti di crittografia, attraversando il percorso instradato completamente in chiaro ed essendo quindi leggibili e manipolabili da qualsiasi dispositivo intermedio.

    Per ovviare tale problema, viene implementato a livello di applicazione il protocollo \textbf{Transport Layer Security (TLS)} tramite socket realizzati con librerie software specifiche, fornendo connessioni crittografate, integrità dei dati ed autenticazione dell'end-point.

    \quad

    \section{Web e Protocollo HTTP}

    Una pagina web è composta da \textbf{oggetti}, ognuno dei quali può essere archiviato su un diverso web server. In particolare, una pagina web consiste in un \textbf{file HTML} il quale include diversi oggetti referenziati tramite vari URL
    \[\underbrace{\text{www.someschool.edu}}_{\text{host name}}/\underbrace{\text{someDept/image.gif}}_{\text{path name}}\]

    \begin{frameddefn}{Protocollo HTTP}
        Il \textbf{protocollo HTTP (Hypertext Transfer Protocol)} è un protocollo a livello di applicazione utilizzato per la realizzazione di servizi web. La sua porta di riferimento comune all'interno dei socket è la \textbf{porta 80}.

        Il protocollo HTTP è \textbf{stateless}, ossia non conservante alcuna informazione sulle richieste passate, e basato sul \textbf{paradigma client-server}, dove il client invia messaggi detti \textbf{richieste} e il server invia messaggi detti \textbf{risposte}.
        
        Inoltre, il protocollo HTTP fa uso del \textbf{protocollo TCP}:
        \begin{enumerate}
            \item Il client avvia una connessione TCP con il server utilizzando la porta 80, rimanendo in attesa che il server accetti la connessione (TCP handshaking)
            \item Vengono scambiati messaggi HTTP tra client e server
            \item La connessione TCP viene chiusa
        \end{enumerate}
    \end{frameddefn}

    Le \textbf{connessioni HTTP} si differenziano in due tipologie:
    \begin{itemize}
        \item \textbf{Connessione non persistente}, dove viene aperta la connessione TCP e viene inviato massimo un oggetto prima di chiudere la connessione TCP
        \item \textbf{Connessione persistente (HTTP/1.1)}, dove viene aperta la connessione TCP e vengono inviati multipli oggetti in successione prima di chiudere la connessione TCP
    \end{itemize}

    \textbf{Esempio:}

    \begin{enumerate}
        \item Supponiamo che un utente inserisca l'URL dell'oggetto "www.someSchool.edu/ someDepartment/home.index", contenente del testo e 10 riferimenti ad immagini.
        \item Il client HTTP dell'utente (browser, cURL, ...) avvia la connessione TCP con il server HTTP tramite la porta 80
        \item Il server HTTP sull'host "www.someSchool.edu" riceve la richiesta di connessione, accettandola e notificando il client
        \item Il client HTTP invia un messaggio di richiesta HTTP, contenente il path dell'oggetto desiderato, ossia "/someDept/index.html"
        \item Il server HTTP riceve il messaggio di richiesta e invia il messaggio di risposta contenente l'oggetto desiderato, il quale a sua volta contiene i riferimenti alle 10 immagini. 
        \item A questo punto, si creano due scenari:
        \begin{itemize}
            \item Se la connessione non è persistente, il server chiude immediatamente la connessione TCP, implicando che l'intero processo debba essere ripetuto per tutti e 10 i riferimenti necessari
            \item Se la connessione è persistente, il client invierà in successione altre 10 richieste al server, richiedendo quindi solo la ripetizione dei passaggi 4 e 5 (per 10 volte), per poi chiudere la connessione TCP
        \end{itemize}
    \end{enumerate}

    \begin{frameddefn}{Round Trip Time (RTT)}
        Definiamo come \textbf{Round Trip Time (RTT)} il tempo impiegato da un pacchetto di piccole dimensioni per compiere il percorso client-server-client
    \end{frameddefn}
    
    \begin{framedobs}{Tempo di risposta HTTP}
        Se la \textbf{connessione non è persistente}, per \underline{ogni oggetto} sono necessari due RTT, uno per avviare la connessione TCP ed uno per l'invio di richiesta e risposta, seguiti dal tempo necessario ad inviare l'oggetto
        \[T_{tot} = (2 \text{ RTT} + \text{ Tempo invio  ogg.}) \cdot \text{Num. Oggetti}\]
        
        Se la \textbf{connessione è persistente}, invece, saranno necessari un RTT per poter stabilire la connessione TCP, seguiti da un solo RTT per oggetto (con annesso tempo di invio)
        \[T_{tot} = 1 \text{ RTT} + (1 \text{ RTT} + \text{ Tempo invio  ogg.}) \cdot \text{Num. Oggetti}\]
    \end{framedobs}

    \begin{center}
        \includegraphics[scale=0.45]{images/rtt.png}
    \end{center}

    \subsection{Messaggi di richiesta e risposta}

    I messaggi HTTP di \textbf{richiesta} e \textbf{risposta} vengono formattati un formato leggibile dall'uomo (in particolare, in codice ASCII). 
    
    Ogni messaggio di \textbf{richiesta HTTP} viene strutturato nel seguente modo:
    \begin{itemize}
        \item Una \textbf{riga di richiesta}, composta dal \textbf{metodo} utilizzato, il path richiesto e la versione di HTTP utilizzata, seguiti da un carattere di ritorno a capo, ossia \texttt{\textbackslash r}, ed un carattere di avanzamento di riga, ossia \texttt{\textbackslash n}
        
        I \textbf{metodi} principali inseribili all'interno della riga di richiesta sono:
        \begin{itemize}
            \item \textbf{Metodo GET}, utilizzato per l'invio di dati al server, i quali vengono inseriti all'interno dell'URL a seguito di un carattere '?'
            
            (es: \texttt{www.mysite.com/search?user=myuser})

            \item \textbf{Metodo POST}, utilizzato per l'invio di dati al server, i quali vengono aggiunti all'interno del body del messaggio (rimanendo quindi parzialmente offuscati all'utente)
            
            \item \textbf{Metodo HEAD}, utilizzato per richiedere solo l'header di risposta che verrebbe restituito dalla destinazione a seguito di una richiesta GET
            
            \item \textbf{Metodo PUT}, utilizzato per caricare un nuovo file o sostituirne uno esistente all'interno della destinazione (non più utilizzato poiché estremamente insicuro)
        \end{itemize}
        \item Un \textbf{header (o intestazione)}, composto da varie linee contenenti informazioni utili alla connessione. Alcuni esempi di campi inseribili all'interno di un header di richiesta sono:
    \end{itemize}

    \begin{center}
        \begin{tabular}{c|c}
            \textbf{Campo Header} & \textbf{Descrizione}\\
            \hline
            \texttt{User-agent} & Indica il programma client utilizzato\\
            \texttt{Accept} & Indica il formato dei contenuti che il client è in grado di accettare\\
            \texttt{Accept-charset} & Famiglia di caratteri che il client è in grado di gestire\\
            \texttt{Accept-encoding} & Schema di codifica supportato dal client\\
            \texttt{Accept-language} & Linguaggio preferito dal client\\
            \texttt{Authorization} & Indica le credenziali possedute dal client\\
            \texttt{Host} & Host e numero di porta del client\\
            \texttt{Date} & Data e ora del messaggio\\
            \texttt{Upgrade} & Specifica il protocollo di comunicazione preferito\\
            \texttt{Cookie} & Comunica un cookie al server\\
            \texttt{If-Modified-Since} & Invia il documento solo se è più recedente della data specificata \\
        \end{tabular}
    \end{center}

    \quad

    \begin{itemize}
        \item Un \textbf{body (o contenuto)}, ossia il vero contenuto del messaggio da inviare (solitamente vuoto a meno dell'uso del metodo POST)
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/req_http.png}
    \end{center}

    \textbf{Esempio:}

    \begin{verbatim}
    GET /index.html HTTP/1.1\r\n
    Host: www-net.cs.umass.edu\r\n
    User-Agent: Firefox/3.6.10\r\n
    Accept: text/html,application/xhtml+xml\r\n
    Accept-Language: en-us,en;q=0.5\r\n
    Accept-Encoding: gzip,deflate\r\n
    Accept-Charset: ISO-8859-1,utf-8;q=0.7\r\n
    Keep-Alive: 115\r\n
    Connection: keep-alive\r\n
    \r\n
    \end{verbatim}

    
    Analogamente, ogni messaggio di \textbf{risposta HTTP} viene strutturato in modo simile, ma con alcune differenze:
    \begin{itemize}
        \item Una \textbf{riga di stato}, composta dalla versione di HTTP utilizzata, un \textbf{codice di status} e una \textbf{frase di status} descrivente in breve il codice di status
        
        I \textbf{codici di status} si dividono in 5 categorie:
        \begin{itemize}
            \item \textbf{Codici 1xx}, indicanti che la risposta ricevuta contiene solamente informazioni
            
            (es: \texttt{100 Continue} indica che il server è pronto a ricevere la richiesta del client) 
            \item \textbf{Codici 2xx}, indicanti che la richiesta effettuata è andata a buon fine 
            
            (es: \texttt{200 OK} indica che la richiesta ha avuto successo e l'oggetto richiesto è stato trovato, \texttt{204 No Content} indica che la richiesta ha avuto successo ma l'oggetto richiesto non contiene nulla al suo interno)
            \item \textbf{Codici 3xx}, indicanti che è stato effettuato un reindirizzamento a seguito della richiesta effettuata
            
            (es: \texttt{301 Moved Permanently} indica che l'oggetto richiesto possiede un path diverso da quello richiesto, reindirizzando automaticamente tutte le richieste successive del client)

            \item \textbf{Codici 4xx}, indicanti un errore nella richiesta del client
            
            (es: \texttt{403 Forbidden} indica che il client non possiede i requisiti per accedere all'oggetto richiesto, \texttt{404 Not Found} indica che l'oggetto richiesto non esiste )

            \item \textbf{Codici 5xx}, indicanti un errore per cui il server non è riuscito a completare la richiesta
            
            (es: \texttt{500 Internal Server Error} indica un errore sconosciuto all'interno del server, \texttt{503 Service Unavailable} indica che il server è attualmente non disponibile)
            
        \end{itemize}

        \item Un \textbf{header (o intestazione)}, composto da varie linee contenenti informazioni utili alla risposta. Alcuni esempi di campi inseribili all'interno di un header di risposta sono:
    \end{itemize}

    \begin{center}
        \begin{tabular}{c|c}
            \textbf{Campo Header} & \textbf{Descrizione}\\
            \hline
            \texttt{Date} & Data e ora attuale\\
            \texttt{Upgrade} & Specifica il protocollo di comunicazione preferito\\
            \texttt{Server} & Indica il programma server utilizzato\\
            \texttt{Set-Cookie} & Il server richiede al client di memorizzare un cookie\\
            \texttt{Content-Encoding} & Specifica lo schema di codifica\\
            \texttt{Content-Language} & Specifica la lingua utilizzata nel documento\\
            \texttt{Content-Length} & Indica la lunghezza del documento\\
            \texttt{Content-Type} & Specifica la tipologia del documento\\
            \texttt{Location} & Chiede al client di inviare la richiesta ad un altro sito\\
            \texttt{Last-modified} & Fornisce data e ora dell'ultima modifica del documento\\
        \end{tabular}
    \end{center}

    \quad
    \begin{itemize}
        \item Un \textbf{body (o contenuto)}, ossia il vero contenuto del messaggio da restituire (in particolare, l'oggetto richiesto)
    \end{itemize}

    \textbf{Esempio:}

    \begin{verbatim}
    HTTP/1.1 200 OK\r\n
    Date: Sun, 26 Sep 2010 20:09:20 GMT\r\n
    Server: Apache/2.0.52 (CentOS)\r\n
    Last-Modified: Tue, 30 Oct 2007 17:00:02 GMT\r\n
    Accept-Ranges: bytes\r\n
    Content-Length: 2652\r\n
    Keep-Alive: timeout=10, max=100\r\n
    Connection: Keep-Alive\r\n
    Content-Type: text/html; charset=ISO-8859-1\r\n
    \r\n
    [document content...]
    [...]\end{verbatim}

    \subsection{Versioni di HTTP}

    Come già discusso, il \textbf{protocollo HTTP/1.1} ha introdotto la possibilità di poter effettuare più richieste GET in successione tramite una singola connessione TCP. Tuttavia, tale modifica ha introdotto ulteriori problematiche:
    \begin{itemize}
        \item Il server risponde alle richieste GET nell'ordine in cui vengono effettuate \textbf{(First Come First Served (FCFS))}
        \item Un oggetto di piccole dimensioni potrebbe dover attendere la trasmissione di oggetti di grandi dimensioni richiesti prima di esso \textbf{(blocco head-of-line (HOL))}
        \item La perdita di un segmento TCP causa lo stallo del trasferimento di un oggetto
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/hol1.png}
    \end{center}

    Per risolvere tali problematiche, il \textbf{protocollo HTTP/2} introduce una maggiore flessibilità al server nell'invio di oggetti al client:
    \begin{itemize}
        \item L'ordine di trasmissione degli oggetti richiesti viene stabilito in base alla priorità dell'oggetto specificata dal client
        \item Gli oggetti vengono  \textbf{divisi in frame}, schedulati in modo da mitigare il blocco HOL
        \item Possono essere inviati più oggetti contemporaneamente (\textbf{multiplexing})
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/hol2.png}
    \end{center}

    Il \textbf{protocollo HTTP/3}, invece, risolve le ultime problematiche rimanenti all'interno del protocollo HTTP/2, tramite l'aggiunta di controlli sulla sicurezza, sugli errori e sulla congestione per oggetto, utilizzando il \textbf{protocollo QUIC} (basato su UDP) al posto del protocollo TCP.

    \subsection{Cookies e Web Caching}

    \quad

    \begin{frameddefn}{Cookie}
        Un \textbf{cookie} è un \textbf{piccolo file di testo} contenente brevi informazioni (preferenze sull'utilizzo, parametri preferiti, token di autorizzazione, ...) salvato all'interno di un client da parte di un server web 
    \end{frameddefn}

    Poiché il protocollo HTTP è un protocollo \textbf{stateless}, i cookie vengono utilizzati all'interno delle applicazioni web per conservare indirettamente alcune informazioni sulle varie comunicazioni client-server effettuate, rendendo ogni richiesta HTTP indipendente dall'altra.

    A seguito di un messaggio di riposta da un web server contenente il campo header \texttt{Set-Cookie}, il client salva il contenuto del cookie all'interno di un file. Durante le \textbf{successive richieste} effettuate dallo stesso client allo stesso server, tutti i cookie impostati da tale server vengono \textbf{allegati ad ogni richiesta HTTP}.

    Solitamente, il cookie fornito dal server contiene un ID univoco, in modo da legare una voce nel suo database interno a quel client specifico.

    \begin{center}
        \includegraphics[scale=0.45]{images/cookie_ex.png}
    \end{center}

    La \textbf{durata di un cookie} inviato viene specificata tramite un campo header \texttt{Max-Age}, tramite il quale viene specificato il tempo di vita di tale cookie in \textbf{secondi}. Allo scadere di tali secondi, il client eliminerà automaticamente tale cookie. Inoltre, non c'è limite alla quantità di secondi specificabili, implicando che sia possibile specificare anche una quantità di secondi pari a mesi o anni

    \newpage

    \begin{frameddefn}{Proxy Server}
        Un \textbf{proxy server} è un server utilizzato come \textbf{intermediario} tra un client e il vero server destinatario.

    \end{frameddefn}

    Solitamente, tale tipologia server viene utilizzato per il \textbf{web caching}:
    
    \begin{itemize}
        \item Se il documento richiesto \textbf{è presente} nella cache del proxy server, esso viene restituito al client senza dover raggiungere il server originale
        \item Se il documento richiesto \textbf{non è presente} nella cache, il proxy server inoltra la richiesta del client al server di origine, memorizzando nella sua cache il documento ricevuto nella risposta, restituendolo al client
    \end{itemize}

    Tramite il web caching è possibile ridurre notevolmente i tempi di risposta e il traffico nei link di accesso alla rete del server di origine, consentendo ai fornitori di contenuti di essere più efficienti.

    \begin{center}
        \includegraphics[scale=0.45]{images/proxy.png}
    \end{center}

    \quad

    \section{Posta elettronica}

    Il servizio di \textbf{posta elettronica} è costituito da tre entità fondamentali:
    \begin{itemize}
        \item Uno \textbf{User agent (UA)}, detto anche \textit{mail reader}, è un processo attivo sul client utente attivato dall'utente stesso o da un timer. Si occupa di informare l'utente nel caso in cui sia disponibile una nuova email da leggere nella sua casella di posta.
        
        Inoltre, lo user agent permette la composizione, l'editing, l'invio e la lettura di messaggi di posta elettronica. Ogni messaggio di posta inviato da un UA viene passato ad un MTA
        \item \textbf{Mail Transfer Agent (MTA)}, è un processo attivo su un mail server utilizzato per il trasferimento tramite Internet di un messaggio ricevuto da un UA o da un altro MTA
        \item \textbf{Mail Access Agent (MAA)}, è un processo attivo su un mail server utilizzato per leggere i messaggi di posta in arrivo
    \end{itemize}

    Ogni \textbf{mail server} è dotato di una \textbf{casella di posta (mailbox)}, contenente i messaggi in arrivo per l'utente, ed una \textbf{coda di messaggi}, contenente i messaggi dell'utente ancora da inviare.

    \begin{center}
        \includegraphics[scale=0.825]{images/mta_maa.png}
    \end{center}

    \quad

    \subsection{Protocolli SMTP e MIME}

    \quad

    \begin{frameddefn}{Protocollo SMTP}
        Il \textbf{protocollo SMTP (Simple Mail Transfer Protocol)} è un protocollo a livello di applicazione utilizzato per l'invio di messaggi di posta elettronica in formato ASCII. La sua porta di riferimento comune all'interno dei socket è la \textbf{porta 25}.

        Il protocollo SMTP effettua un \textbf{trasferimento diretto}, ossia dal mail server mittente a quello destinatario (dunque senza mail server intermedi), basato su un'\textbf{interazione comando/risposta}: viene inviato un comando in testo ASCII e viene ricevuta una risposta equivalente ad un codice di stato.

        Inoltre, il protocollo SMTP fa uso del \textbf{protocollo TCP}:
        \begin{enumerate}
            \item Il client avvia una connessione TCP con il server utilizzando la porta 25, rimanendo in attesa che il server accetti la connessione (TCP handshaking)
            \item Vengono scambiati messaggi di posta tra client e server \textbf{(connessione persistente)}
            \item La connessione TCP viene chiusa
        \end{enumerate}
    \end{frameddefn}

    \textbf{Esempio:}

    \begin{enumerate}
        \item Alice usa il suo UA per comporre il
        messaggio da inviare all'indirizzo di posta elettronica \texttt{bob@someschool.edu}
        \item  L'UA di Alice invia il messaggio al mail server di Alice, il quale porrà tale messaggio nella sua coda di messaggi. Successivamente, il client SMTP presente sul mail server di Alice apre una connessione TCP con il mail server di Bob
        \item Il client SMTP invia il messaggio di Alice sulla
        connessione TCP tramite il suo MTA
        \item Il mail server di Bob riceve il messaggio e lo pone nella casella di posta di Bob
        \item Bob invoca il suo UA per leggere il messaggio, il quale preleverà il messaggio tramite l'MAA presente sul suo mail server
        
        (NB: tale operazione \textit{non} è svolta dal protocollo SMTP, bensì dal protocollo POP3 o dal protocollo IMAP che vedremo in seguito)
    \end{enumerate}

    \begin{center}
        \includegraphics[scale=0.4]{images/smtp_ex.png}
    \end{center}

    In particolare, lo scambio di messaggi viene gestito dal protocollo SMTP nel seguente modo:
    \begin{enumerate}
        \item Il client SMTP \textbf{tenta di stabilire} una connessione TCP sulla porta 25 con il server STMP. Se il server è attivo, la connessione TCP viene stabilita. Altrimenti, il client riproverà dopo un determinato lasso di tempo.

        \item Una volta stabilita la connessione, il client e il server effettuano una \textbf{forma aggiuntiva di handshaking}, dove il client indica al server l'indirizzo email del mittente e del destinatario
        \item Il client invia il messaggio sulla connessione TCP. Una volta ricevuto il messaggio, se ci sono altri messaggi da inviare viene utilizzata la stessa connessione TCP (\textbf{connessione persistente}). Altrimenti, il client invia al server una richiesta di chiusura della connessione.
    \end{enumerate}

    \textbf{Esempio:}

    \begin{itemize}
        \item Di seguito, vediamo un esempio di interazione tra un server SMTP, indicato con S, e un client SMTP, indicato con C.
    \end{itemize}

    \begin{verbatim}
        S: 220 hamburger.edu
        C: HELO crepes.fr
        S: 250 Hello crepes.fr, pleased to meet you
        C: MAIL FROM: <alice@crepes.fr>
        S: 250 alice@crepes.fr... Sender ok
        C: RCPT TO: <bob@hamburger.edu>
        S: 250 bob@hamburger.edu ... Recipient ok
        C: DATA
        S: 354 Enter mail, end with "." on a line by itself
        C: Do you like ketchup?
        C: How about pickles?
        C: .
        S: 250 Message accepted for delivery
        C: QUIT
        S: 221 hamburger.edu closing connection\end{verbatim}

    Lo \textbf{standard RFC 822} definisce la struttura che ogni messaggio di posta elettronica deve assumere:
    \begin{itemize}
        \item Un \textbf{header} composto dai seguenti campi:
        \begin{center}
            \begin{tabular}{c|p{0.5 \textwidth}}
                \textbf{Campo Header} & \textbf{Descrizione}\\
                \hline
                \texttt{To} & L'indirizzo del destinatario\\
                \texttt{From} & L'indirizzo del mittente\\
                \texttt{CC} & Indirizzi aggiuntivi di mittenti a cui far sapere dell'invio e il contenuto di tale email (abbreviativo di Carbon Copy)\\
                \texttt{BCC} & Analogo al \texttt{CC}, ma non vengono mostrati al destinatario (abbreviativo di Blind CC)\\
                \texttt{Subject} & L'argomento del messaggio\\
                \texttt{Sender} & Il nome del mittente
            \end{tabular}
        \end{center}
        \item Un \textbf{body}, contenente il messaggio da inviare (\textbf{solo caratteri ASCII})
    \end{itemize}

    Per poter inviare contenuti diversi dal semplice test ASCII, gli standard RFC 2045 e 2046 definiscono il \textbf{protocollo MIME (Multipurpose Internet Mail Extension)}, in grado di estendere i normali messaggi di posta elettronica in messaggi multimediali.

    Vengono aggiunte alcune righe all'interno dell'header del messaggio inviato, in particolare una riga \texttt{Version}, indicante la \textbf{versione del protocollo} MIME utilizzata, e una riga \texttt{Type}, indicante il \textbf{tipo di dati multimediali} inviati, i quali, prima di essere spediti, vengono convertiti in una \textbf{codifica testuale} (solitamente base64), specificata da un campo aggiuntivo \texttt{Content-Transfer-Encoding}, in modo da poter essere trasmesso sottoforma di testo ASCII, per poi venir decodificati una volta che il messaggio è giunto al destinatario.

    \quad

    \subsection{Protocolli POP3 e IMAP}

    \quad

    \begin{frameddefn}{Protocollo POP3}
        Il \textbf{protocollo POP3 (Post Office Protocol vers. 3)} è un protocollo \textbf{stateless} a livello di applicazione utilizzato per il download di messaggi di posta elettronica ricevuti. La sua porta di riferimento comune all'interno dei socket è la \textbf{porta 110}.

        Per stabilire una connessione, il protocollo POP3 fa uso del \textbf{protocollo TCP}, effettuando quindi l'handshake TCP, per poi procedere nelle seguenti tre fasi:
        \begin{enumerate}
            \item \textbf{Autorizzazione}, dove lo UA invia nome utente e password per essere identificato dal mail server
            \item \textbf{Transazione}, dove lo UA recupera i messaggi nella casella di posta dell'utente
            \item \textbf{Aggiornamento}, dove, successivamente all'invio di un messaggio \texttt{QUIT} da parte dello UA, viene terminata la connessione e vengono rimossi dal mail server i messaggi contrassegnati durante la fase precedente
        \end{enumerate}

    \end{frameddefn}

    \textbf{Esempio:}
    \begin{itemize}
        \item Se la richiesta effettuata viene eseguita correttamente, il server risponderà con \texttt{+OK}, altrimenti con \texttt{-ERR}. Il comando \texttt{retr} permette di scaricare il messaggio, mentre il comando \texttt{dele} permette di marcare i messaggi da eliminare
        
    \begin{verbatim}
    S: +OK POP3 server ready
    C: user rob
    S: +OK
    C: pass hungry
    S: +OK user successfully logged on
    C: list
    S: 1 498
    S: 2 912
    S: .
    C: retr 1
    S: <message 1 contents>
    S: .
    C: dele 1
    C: retr 2
    S: <message 2 contents>
    S: .
    C: dele 2
    C: quit
    S: +OK POP3 server signing off
    \end{verbatim}

        \item Successivamente, viene attivata la fase di aggiornamento, cancellando dal mail server i messaggi marcati tramite \texttt{dele}
    \end{itemize}

    Oltre ad essere un protocollo stateless, il protocollo POP3 non fornisce all'utente la possibilità di creare \textbf{cartelle remote} tra cui poter suddividere i messaggi, costringendo la creazione di tali cartelle solo a livello locale, implicando che esse non siano condivise tra i vari dispositivi dell'utente.

    \begin{frameddefn}{Protocollo IMAP}
        Il \textbf{protocollo IMAP (Internet Message Access Protocol)} è un protocollo a livello di applicazione utilizzato per l'accesso ai messaggi di posta elettronica ricevuti. La sua porta di riferimento comune all'interno dei socket è la \textbf{porta 143}.

        A differenza del protocollo POP3, tutti i messaggi vengono \textbf{conservati nel mail server}, permettendo all'utente di avere solo copie locali. Per via di ciò, il protocollo IMAP permette di:
        \begin{itemize}
            \item Associare ogni messaggio ricevuto ad una cartella, detta \textbf{inbox}
            \item Creare cartelle remote e spostare messaggi tra di esse
            \item Effettuare ricerche nelle cartelle remote
            \item Conservare lo stato tra le varie sessioni dell'utente (protocollo \textbf{stateful})
        \end{itemize} 
    \end{frameddefn}

    \section{Domain Name System (DNS)}

    \quad

    \begin{frameddefn}{Domain Name System (DNS)}
        Il \textbf{Domain Name System (DNS)} è un sistema  utilizzato per mappare singoli nodi di una rete ad un \textbf{nome} che li identifichi. Viene realizzato tramite un database distribuito, implementato come una gerarchia di \textbf{name server}.
    \end{frameddefn}

    Tra le funzioni fornite dal servizio DNS troviamo:
    \begin{itemize}
        \item \textbf{Traduzione} da nome host all'indirizzo IP relativo
        \item \textbf{Distribuzione del carico}, permettendo a più indirizzi IP, ognuno legato ad un server copia di quello originale, di corrispondere ad un unico nome. Quando un client effettua una richiesta, il servizio restituisce l'insieme di indirizzi legati a tale nome in un ordine casuale (rotazione DNS)
        \item \textbf{Host Aliasing}, ossia l'associazione di più sinonimi (alias) allo stesso indirizzo IP, permettendo l'associazione di un nome più semplice rispetto ad uno complesso
        
        (es: al nome \texttt{relay1.west-coast.enterprise.com} associamo l'alias \texttt{enterprise.com} e l'alias \texttt{www.enterprise.com})
    \end{itemize}

    Per via delle sue funzioni, il servizio DNS risulta essere \textbf{fondamentale} per Internet.

    In particolare, la \textbf{decentralizzazione} del servizio DNS risulta essere critica: se il servizio fosse centralizzato (ossia effettuato da un singolo nodo o rete) sarebbe sufficiente un singolo punto di fallimento affinché il servizio diventi inutilizzabili. Inoltre, se il servizio fosse centralizzato si avrebbe un volume di traffico troppo elevato dovuto alle miliardi di richieste effettuate giornalmente (es: il server DNS Comcast riceve 600 miliardi di richieste al giorno)

    \quad

    \subsection{Gerarchia server DNS}

    Poiché il mapping DNS è \textbf{distribuito} su svariati server, dove in particolare nessuno di essi mantiene il mapping di tutti gli IP possibili (un IP corrisponde a 32 bit, dunque $2^{32}$ IP possibili), il database tramite cui viene realizzato il servizio DNS è \textbf{gerarchico}, seguendo la struttura di un albero:

    \begin{itemize}
        \item \textbf{Root Server}:
        
        \begin{itemize}
            \item Radice dell'albero
            \item Viene interrogato da qualsiasi server DNS che non sia in grado di risolvere il nome di un server TLD (ossia restituire l'IP legato ad esso)
        \end{itemize}

        \item \textbf{Server Top-Level Domain (TLD)}:
        
        \begin{itemize}
            \item Viene interrogato per risolvere il nome di un server DNS autoritativo
            \item Responsabili di domini come \texttt{.com, .org, .net, ...} e tutti i domini nazionali di primo livello, ossia \texttt{.it, .uk, .fr, ...}
        \end{itemize}

        \item \textbf{Server autoritativi (o di competenza)}:
        
        \begin{itemize}
            \item Viene interrogato per risolvere il nome di un host pubblicamente accessibile, solitamente all'interno di un organizzazione
            \item Ogni organizzazione con host pubblicamente accessibili deve fornire i record DNS di pubblico dominio che mappano i nomi di tali host ai loro indirizzi IP
        \end{itemize}

        \item \textbf{Server DNS locali (o default name server)}:
        \begin{itemize}
            \item Non appartengono alla gerarchia. Ogni ISP ne è dotato
            \item Possiedono una cache locale delle recenti coppie di mappatura nome-indirizzo (potrebbero non essere aggiornate)
            \item Funge da proxy iniziale tra il client e il root server: se il nome non è nella cache del server locale, la richiesta viene inoltrata al root server
        \end{itemize}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/dns_gerarchia.png}
    \end{center}

    \textbf{Esempio:}

    \begin{enumerate}
        \item Il client vuole ottenere l'indirizzo IP dell'host \texttt{www.amazon.com}
        \item Viene contattato il server DNS locale dell'ISP di riferimento. Se il nome non viene risolto, si procede col passo successivo.
        \item Viene contattato il root server per trovare l'indirizzo IP del server TLD \texttt{.com}
        \item Viene contattato il server TLD \texttt{.com} per trovare l'indirizzo IP del server autoritativo \texttt{amazon.com}
        \item Viene contattato il server autoritativo \texttt{amazon.com} per trovare l'indirizzo IP dell'host \texttt{www.amazon.com}
    \end{enumerate}

    Ogni volta che un server DNS viene a conoscenza di una mappatura, essa viene \textbf{memorizzata} all'interno della cache, utilizzando tali record per rispondere a query future. I record presenti nella cache vengono cancellati allo scadere di un \textbf{TTL (Time-to-live)} o a seguito di un comando manuale.

    Solitamente, all'interno della cache dei server DNS locali sono presenti i server TLD più comuni, implicando che il root server venga interrogato raramente.

    Tuttavia, è necessario notare che i record nella cache \textbf{potrebbero non essere aggiornati}: se viene cambiato l'indirizzo IP associato ad un nome presente nella cache, esso potrebbe non essere noto all'interno di Internet fino alla scadenza di tutti i TTL di tutti i server, poiché quest'ultimi risolverebbero la richiesta restituendo l'indirizzo IP precedente.

    \newpage

    La \textbf{risoluzione dei nomi}, ossia la restituzione dell'indirizzo IP ad esso legato, può avvenire in due modalità:
    \begin{itemize}
        \item \textbf{Risoluzione a query iterativa}, dove il server contattato dal client risponde con il nome del prossimo server da contattare, il quale (probabilmente) sarà in grado di risolvere il nome
        
        \begin{center}
            \includegraphics[scale=0.435]{images/iterative_dns.png}
        \end{center}

        \item \textbf{Risoluzione a query ricorsiva}, dove l'onere della risoluzione del nome viene affidato al server contattato, ricorsivamente
        
        \begin{center}
            \includegraphics[scale=0.435]{images/recursive_dns.png}
        \end{center}

    \end{itemize}

    Ogni mappatura \texttt{nome-indirizzo} viene inserita all'interno di un \textbf{resource record (RR)}, il quale assume la struttura \texttt{(name, value, type, ttl)}, dove a seconda del valore del campo \textbf{\texttt{type}} si ha che:
    \begin{itemize}
        \item \texttt{\textbf{type = A}}, indica che il campo \texttt{name} contiene il nome di un host interno ad un dominio (hostname) e il campo \texttt{value} contiene l'indirizzo IP di tale host
        
        (es: \texttt{name = relay1.bar.foo.com, value = 45.37.93.126})
        \item \texttt{\textbf{type = NS}}, indica che il campo \texttt{name} contiene il nome di un dominio e il campo \texttt{value} contiene l'hostname del server autoritativo associato a tale dominio
        
        (es: \texttt{name = foo.com, value = dns.foo.com})
        
        \item \texttt{\textbf{type = CNAME}}, indica che il campo \texttt{name} contiene un alias del nome canonico e il campo \texttt{value} contiene il nome canonico stesso
        
        (es: \texttt{name = www.ibm.com, value = servereast.backup2.ibm.com})

        \item \texttt{\textbf{type = MX}}, indica che il campo \texttt{name} contiene il nome di un mail server interno ad un dominio e il campo \texttt{value} contiene l'hostname di tale mail server
    \end{itemize}


    \textbf{Esempio:}

    \begin{itemize}
        \item Un server autoritativo per un hostname contiene un record di tipo A per l'hostname stesso, ad esempio 
        \[\texttt{(corsi.di.uniroma1.it, 131.111.45.68, A)}\]

        \item Un server non autoritativo per un dato hostname contiene un record di tipo NS per il dominio che include l'hostname e un record di tipo A che fornisce l'indirizzo IP del server DNS nel campo value del record NS.
        
        Ad esempio, un server TLD .it che non è autoritativo per l'host \texttt{corsi.di.uniroma1.it}, contiene i due record
        \[\texttt{(uniroma1.it, dns.uniroma1.it, NS)}\]
        \[\texttt{(dns.uniroma1.it, 128.119.40.111, A)}\]
        
    \end{itemize}
    
    \quad

    \subsection{Protocollo DNS}

    \quad

    \begin{frameddefn}{Protocollo DNS}
        Il \textbf{protocollo DNS} è un protocollo a livello di applicazione utilizzato per la risoluzione di hostname e nomi di dominio. La sua porta di riferimento comune all'interno dei socket è la \textbf{porta 53}.

        Al fine di rendere il trasferimento il più rapido possibile, il protocollo DNS utilizza il \textbf{protocollo UDP}, richiedendo l'invio di un singolo messaggio, evitando necessità della creazione del collegamento. Se un messaggio non giunge a destinazione dopo un determinato timeout, esso viene semplicemente rinviato.

        Inoltre, il protocollo DNS è un protocollo \textbf{stateless},
        (semplicemente poiché non è necessario salvare alcuno stato)
    \end{frameddefn}

    \newpage
    
    La \textbf{richieste} e le \textbf{risposte} DNS assumono la stessa struttura:
    
    \begin{itemize}
        \item Un \textbf{header} lungo 32 bit, composto da due campi da 16 bit:
        \begin{itemize}
            \item \textbf{Identification}, contenente informazioni del richiedente
            \item \textbf{Flags}, contenente flag di stato indicanti se il messaggio sia di richiesta o risposta, se la risoluzione ricorsiva sia preferita o disponibile e se la risposta sia di un server autoritativo
        \end{itemize}
        \item Un campo \textbf{questions} di dimensione variabile contenente le informazioni per una richiesta
        \item Un campo \textbf{answers} di dimensione variabile contenente i RR da inviare come risposta
        \item Un campo \textbf{authority} di dimensione variabile contenente i RR autoritativi da inviare come risposta
        \item Un campo per le \textbf{informazioni aggiuntive}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/dns_query.png}
    \end{center}
    
    \quad

    \section{Trasferimento di file}

    \subsection{Protocollo FTP}

    \quad

    \begin{frameddefn}{Protocollo FTP}
        Il \textbf{protocollo FTP (File Transfer Protocol)} è un protocollo a livello di applicazione utilizzato per il trasferimento di file basato sul \textbf{paradigma client-server}. 

        Per gestire il trasferimento dei file, il protocollo FTP utilizza \textbf{due connessioni TCP}:
        \begin{itemize}
            \item Una \textbf{connessione di controllo} (porta 21), utilizzata per trasferire le informazioni per il controllo del trasferimento (es: nome utente, password, comandi per cambiare directory e per il trasferimento)
            \item Una \textbf{connessione dati} (porta 20), la quale viene aperta ogni qualvolta sia necessario trasferire un file, per poi chiuderla successivamente
        \end{itemize}
        
    Inoltre, il protocollo FTP è un protocollo \textbf{stateful}, conservando la directory corrente e l'autenticazione della sessione precedente
    \end{frameddefn}

    Nel protocollo FTP, il \textbf{client} corrisponde al dispositivo avviante il trasferimento verso un dispositivo remoto, mentre il \textbf{server} corrisponde al dispositivo remoto stesso.

    Quando l'utente fornisce al proprio client il nome del server a cui connettersi tramite il comando \texttt{ftp <<nome host>>}, il processo client FTP stabilisce la \textbf{connessione di controllo} sulla porta 21.
    
    Successivamente, il client trasferisce nome utente e password sulla porta 21, autenticandosi. Una volta ottenuta l'autorizzazione dal server, il client può \textbf{trasferire uno o più file} memorizzati nel file system locale verso quello remoto (o viceversa), aprendo e chiudendo la connessione dati sulla porta 20 ad ogni trasferimento.

    \begin{center}
        \includegraphics[scale=0.39]{images/ftp.png}
    \end{center}

    \quad

    I principali comandi del protocollo FTP sono:

    \begin{center}
        \begin{tabular}{l|l}
            \textbf{Comando e Argomenti} & \textbf{Descrizione}\\
            \hline
            \texttt{ABOR} & Interrompe il comando precedente\\
            \texttt{CDUP} & Torna alla directory del livello precedente\\
            \texttt{CWD} <<nome directory>> & Cambia directory corrente\\
            \texttt{DELE} <<nome file>>& Elimina il file\\
            \texttt{LIST} <<nome directory>> & Elenca i file nella directory\\
            \texttt{MKD} <<nome directory>>& Crea una directory\\
            \texttt{PASS} <<password>>& Invia la password dell'utente\\
            \texttt{PASV} & Il server sceglie la porta della connessione\\
            \texttt{PORT} <<porta>>& Il client sceglie la porta della connessione\\
            \texttt{PWD} & Mostra nome directory corrente\\
            \texttt{QUIT} & Termina la comunicazione\\
            \texttt{RETR} <<nomi dei file>>& Trasferisce uno o più file dal server al client\\
            \texttt{RMD} <<nome directory>>& Elimina la directory\\
            \texttt{RNTO} <<vecchio nome>> <<nuovo nome>>& Rinomina il file specificato dal vecchio nome\\
            \texttt{STOR} <<nomi dei file>>& Trasferisce uno o più file dal client al server\\
            \texttt{USER} <<nome utente>>& Invia il nome dell'utente\\
        \end{tabular}
    \end{center}

    \quad

    \subsection{Protocollo BitTorrent}

    \quad

    \begin{frameddefn}{Protocollo BitTorrent}
        Il \textbf{protocollo BitTorrent} è un protocollo a livello di applicazione utilizzato per il trasferimento di file basato sul \textbf{paradigma peer-to-peer (P2P)}. Nonostante non abbia una porta standard, solitamente vengono utilizzate le \textbf{porte nel range 6881-6889} assieme al \textbf{protocollo TCP}.

        Ogni peer entra a far parte di un \textbf{torrent}, ossia un gruppo di peer scambianti frammenti di file tra loro, registrandosi su un \textbf{tracker}, ossia un dispositivo che tiene traccia dei peer partecipanti al torrent, per poi connettersi ad un sottoinsieme di peer "vicini".
        
        Durante il download di file, il peer svolge anche la funzione di uploader (\textbf{seeder}) di blocchi verso altri peer. Una volta ricevuto il file, il peer può scegliere se uscire dal torrent o rimanerne all'interno, continuando a svolgere la funzione di seeder.
    \end{frameddefn}

    In un dato momento, peer diversi possiedono diversi sottoinsiemi di blocchi componenti un file. Per richiedere tali blocchi, un peer chiede periodicamente agli altri l'\textbf{elenco dei blocchi} attualmente posseduti. Successivamente, il peer richiede i blocchi mancanti, dando precedenza ai più rari.

    \newpage

    Per favorire l'altruismo tra i peer e sfavorire la presenza di \textbf{leecher}, ossia dispositivi che egoisticamente escono dal torrent una volta scaricato un file, il protocollo BitTorrent usa un approccio \textbf{tit-for-tat} (traduzione più vicina: \textit{do ut des}, "io ti do e tu mi dai" ):

    \begin{itemize}
        \item Ogni peer seeder invia blocchi agli ulteriori quattro peer seeder che attualmente stanno uploadando i blocchi richiesti alla velocità maggiore
        \item Gli altri peer non appartenenti alla top 4 vengono "strozzati" (\textbf{chocked}) dal peer seeder, bloccando l'invio dei blocchi ad essi.
        \item Ogni 10 secondi, tale top 4 viene rivalutata. Inoltre, ogni 30 secondi viene sbloccato casualmente un peer strozzato (\textbf{optimistic un-chocking}), il quale può entrare o meno a far parte della top 4
    \end{itemize}

    Per via di tale approccio, il trasferimento di un file ad $N$ dispositivi risulta più ottimale nel caso dell'applicazione del paradigma P2P
    
    \begin{center}
        \includegraphics[scale=0.4]{images/p2p_vs_cs.png}
    \end{center}

    \chapter{Livello di Trasporto}

    I servizi forniti nel \textbf{livello di trasporto} forniscono \textbf{comunicazione logica} tra processi applicativi in esecuzione su dispositivi, a differenza del \textbf{livello di rete}, il quale si occupa della comunicazione logica direttamente tra i dispositivi stessi.
    In particolare, il dispositivo mittente suddivide i messaggi dell'applicazione in segmenti, passandoli al livello di rete, mentre il dispositivo destinatario riassembla i segmenti in messaggi.

    \section{Multiplexing e Demultiplexing}

    Per implementare le funzionalità di \textbf{multiplexing} e \textbf{demultiplexing} al livello di trasporto, ogni host utilizza \textbf{indirizzi IP} e \textbf{numeri di porta} per indirizzare correttamente un segmento al socket appropriato del destinatario:
    \begin{itemize}
        \item L'header di ogni segmento possiede un numero di porta per l'origine e la destinazione
        \item Ogni datagramma del livello di rete trasporta un segmento del livello di trasporto
        \item L'header di ogni datagramma possiede l'IP dell'origine e l'IP della destinazione
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.55]{images/segment.png}
    \end{center}

    \newpage

    Nel caso di un \textbf{demultiplexing senza connessione} (es: protocollo UDP), durante la creazione di un socket all'interno di un processo è necessario specificare la porta locale dell'\textbf{host} con cui identificare tale socket.

    (es: \texttt{DatagramSocket d\_soc = new DatagramSocket(12534);})

    Successivamente, qualsiasi dispositivo che voglia comunicare con tale host invierà un datagramma al cui interno sia specificata la coppia \textbf{indirizzo IP di destinazione} e la \textbf{porta di destinazione}. Una volta giunto alla destinazione, verrà letto il numero di porta di destinazione presente nell'header del segmento contenuto all'interno del datagramma ricevuto, indirizzando il segmento al \textbf{socket con tale numero di porta}.

    In particolare, è necessario sottolineare che, in tal modo, il socket su tale host per la comunicazione con più mittenti sia \textbf{unico}. Di conseguenza, qualsiasi datagramma inviato su tale porta apparterrà allo \textbf{stesso stream dati}. Tuttavia, essi saranno comunque distinti univocamente dal numero di porta e l'indirizzo IP del mittente presenti nel datagramma.  

    \begin{center}
        \includegraphics[scale=0.4]{images/udp_socket.png}
    \end{center}


    Nel caso del \textbf{demultiplexing con connessione} (es: protocollo TCP), invece, \textbf{ogni socket viene identificato univocamente} come una quadrupla
    \[\texttt{(IP\_Orig., Porta\_Orig., IP\_Dest., Porta\_Dest.)}\]

    Una volta ricevuto il datagramma, vengono utilizzati tutti e quattro i valori per indirizzare il segmento al socket appropriato. In tal modo, ogni \textbf{connessione} è identificata in modo univoco da una \textbf{coppia di socket} (una sul primo host ed una sul secondo host), permettendo di implementare le garanzie previste dai protocolli.
    
    Inoltre, per via dell'identificazione univoca dei socket, un host può avere \textbf{più socket legati alla stessa porta} con una comunicazione diversa: se due host A e C avviano una connessione avente come destinazione la porta 80 dell'host B, su quest'ultimo verranno creati \textbf{due socket diversi}.
    
    \begin{center}
        \includegraphics[scale=0.39]{images/tcp_socket.png}
    \end{center}

    \quad

    \section{Protocollo UDP}

    Come già accennato, il \textbf{protocollo UDP} è un protocollo di trasporto "senza fronzoli" (\textbf{bare bone}) e \textbf{senza connessione}. Pertanto, non avviene alcun handshake tra mittente e destinatario, implicando che ogni segmento UDP venga gestito indipendentemente dagli altri. Inoltre, il protocollo UDP svolge un servizio \textbf{best-effort}, dunque i segmenti UDP possono essere persi o consegnati in modo non ordinato.

    Tuttavia, tali caratteristiche rendono UDP \textbf{vantaggioso} in alcune casistiche:
    \begin{itemize}
        \item Poiché non vi è alcuna connessione, il protocollo risulta semplice, oltre all'\textbf{assenza del ritardo RTT} necessario per l'handshake richiesto
        \item La dimensione dell'header è minima, rendendo il \textbf{pacchetto più leggero}
        \item L'\textbf{assenza di controllo della congestione} permette al protocollo UDP di tentare la trasmissione senza alcun limite di velocità e il funzionamento anche in casi di congestione dovuti ad un carico elevato sui nodi della rete
        \item Se si vuole rendere il trasferimento affidabile anche utilizzando UDP, basta implementare l'affidabilità necessaria al livello di applicazione (es: HTTP/3 tramite il protocollo QUIC), piuttosto che al livello di trasporto
    \end{itemize}

    In particolare, l'header utilizzato dal protocollo UDP, oltre a contenere le porte di origine e di destinazione, contiene solamente due campi aggiuntivi:
    
    \begin{itemize}
        \item Un campo \textbf{length} (16 bit), indicante la lunghezza del contenuto
        \item Un campo \textbf{checksum} (16 bit), utilizzato per rilevare errori nel segmento trasmesso
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.625]{images/udp_segment.png}
    \end{center}

    Il valore di \textbf{checksum} viene calcolato tramite una \textbf{somma in complemento ad uno con wrap-around}:
    \begin{enumerate}
        \item Il mittente considera il contenuto del segmento (compresi gli altri campi dell'header e gli indirizzi IP) come una sequenza di numeri interi a 16 bit
        
        \item Il mittente calcola il checksum sommando in \textbf{complemento ad 1} (ossia sommando e poi invertendo tutti i bit) i numeri interi della sequenza.
        
        In particolare, se è presente un riporto finale generato dalla somma del bit più significativo, viene sommato anche tale riporto (\textbf{wrap-around})

        \item Il valore del checksum viene inserito nel campo dell'header e il pacchetto continua il processo di trasmissione
        
        \item Una volta giunto a destinazione, l'host ricevente \textbf{calcola nuovamente il checksum}, verificando che sia uguale a quello inserito nell'header del segmento.
        
        Se il checksum è differente, viene rilevato un \textbf{errore} nella trasmissione
    \end{enumerate}

    Tuttavia, è necessario notare che se il \textbf{checksum è uguale} \underline{non è detto} che la trasmissione non abbia generato alcun errore:
    \begin{itemize}
        \item Consideriamo il calcolo del checksum tra i seguenti numeri interi a 16 bit:
        
        \begin{center}
            \begin{tabular}{cccccccccccccccccc}
                  & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & +\\
                  & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & =\\
                \hline
                1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1
            \end{tabular}
        \end{center}

        \newpage

        \item Poiché è presente un riporto, viene effettuato il \textbf{wrap-around} sommando tale riporto ai restanti 16 bit:
        \begin{center}
            \begin{tabular}{cccccccccccccccccc}
                  & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & +\\
                  & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & =\\
                \hline
                1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & \\
    
                \multicolumn{18}{c}{$\downarrow \quad \downarrow \quad \downarrow$}\\

                & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & \\
            \end{tabular}
        \end{center}

        \quad

        \item Infine, vengono \textbf{invertiti i bit} del risultato per ottenere la somma in complemento ad 1
        
        \begin{center}
            \begin{tabular}{cccccccccccccccccc}
                & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & \\
                \multicolumn{18}{c}{$\downarrow \quad \downarrow \quad \downarrow$}\\
                & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & \\
            \end{tabular}
        \end{center}

        \quad

        \item Tuttavia, nel caso in cui i due bit meno significativi di entrambi i numeri fossero stati invertiti (per qualche motivo sconosciuto) durante la trasmissione, il \textbf{checksum calcolato sarebbe identico}
        
        \begin{center}
            \begin{tabular}{cccccccccccccccccc}
                  & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & +\\
                  & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & =\\
                \hline
                1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & \\
    
                \multicolumn{18}{c}{$\downarrow \quad \downarrow \quad \downarrow$}\\

                & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 0 & \\

                \multicolumn{18}{c}{$\downarrow \quad \downarrow \quad \downarrow$}\\
                & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & \\
            \end{tabular}
        \end{center}
    \end{itemize}

    \quad

    \section{Trasferimento affidabile dei dati}

    Per realizzare un trasferimento affidabile dei dati, è necessario implementare un \textbf{canale sicuro} al cui interno non vengano perse o corrotte informazioni.

    \begin{center}
        \includegraphics[scale=0.45]{images/rdt_1.png}
    \end{center}
    Tuttavia, un canale fisico che possa svolgere tale funzione risulta essere irrealizzabile. Per tale motivo, la complessità del \textbf{protocollo di trasferimento dati affidabile (RDT - Reliable Data Transfer)} dipende fortemente dalle caratteristiche del canale inaffidabile utilizzato.
    \begin{center}
        \includegraphics[scale=0.45]{images/rdt_2.png}
    \end{center}

    Inoltre, è necessario puntualizzare che il mittente e il destinatario \textbf{non conoscono lo stato l'uno dell'altro} (es: se la ricezione sia andata a buon fine), a meno che non gli venga comunicato tramite un ulteriore messaggio.

    Il protocollo RDT presenta delle \textbf{interfacce} per il suo utilizzo:
    \begin{itemize}
        \item \textbf{\texttt{rdt\_sent(data)}}, il quale viene chiamato dal livello di applicazione e il cui argomento corrisponde ai dati da inoltrare al destinatario
        \item \textbf{\texttt{udt\_send()}}, dove UDT è acronimo di Unreliable Data Transfer, il quale viene chiamato dal protocollo RDT sul mittente per trasferire il pacchetto sul canale inaffidabile
        \item \textbf{\texttt{rdt\_rcv()}}, il quale viene chiamato alla ricezione del pacchetto dal destinatario
        \item \textbf{\texttt{deliver\_data()}}, il quale viene chiamato dal protocollo RDT sul destinatario per inoltrare al livello di applicazione i dati ricevuti 
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/rdt_3.png}
    \end{center}

    Poiché i dispositivi comunicanti non sono a conoscenza dello stato altrui, il protocollo RDT si basa su un \textbf{trasferimento dei dati unidirezionale}, dunque come se uno solo dei due sia il mittente ed uno solo sia il destinatario (sebbene in realtà sia bidirezionale).

    Per rappresentare le operazioni e le decisioni effettuate dal protocollo, utilizzeremo le \textbf{macchine a stati finiti} (FSM - Finite State Machine) e in particolare la seguente notazione:

    \begin{center}
        \includegraphics[scale=0.5]{images/rdt_4.png}
    \end{center}

    \quad

    \subsection{Protocollo RDT 1.0 e 2.0}

    All'interno del \textbf{protocollo RDT 1.0}, viene assunto che il canale sottostante utilizzato per il trasferimento sia \textbf{perfettamente affidabile}, implicando che il mittente invii i dati nel canale e il ricevitore li legga direttamente, senza alcuna operazione aggiuntiva

    \begin{center}
        \begin{tabular}{cc}
            \includegraphics[scale=0.43]{images/rdt_1_1.png}
            
            \includegraphics[scale=0.43]{images/rdt_1_2.png}
            \end{tabular}
    \end{center}

    Nel \textbf{protocollo RDT 2.0}, invece, viene assunto che il canale sottostante possa invertire alcuni bit nel pacchetto inviato. Analogamente al protocollo UDP, viene utilizzato un \textbf{checksum} per rilevare la presenza di errori. Nel caso in cui venga rilevato uno di quest'ultimi, il destinatario comunicherà al mittente l'esito dell'operazione:

    \begin{itemize}
        \item \textbf{Acknowledgements (ACK)}, dove il destinatario dice esplicitamente al mittente che il pacchetto è stato ricevuto senza problemi
        \item \textbf{Negative acknowledgements (NAK)}, dove il destinatario dice esplicitamente al mittente che il pacchetto ricevuto presenta degli errori
    \end{itemize}

    Successivamente all'invio di un pacchetto, il mittente rimane in attesa della risposta del destinatario (meccanismo \textbf{stop and wait})

    \begin{center}
        \includegraphics[scale=0.3]{images/rdt_2_3.png}
    \end{center}

    Se la risposta ricevuta è un \textbf{ACK}, il mittente torna il stato di attesa del prossimo pacchetto da parte del livello applicativo.

    \begin{center}
        \includegraphics[scale=0.3]{images/rdt_2_4.png}
    \end{center}

    Se invece la risposta è un \textbf{NAK}, il mittente rinvia il pacchetto generante l'errore e rimane in attesa della risposta del destinatario, ripetendo nuovamente tale processo nel caso in cui si riceva nuovamente un NAK.

    \begin{center}
        \includegraphics[scale=0.3]{images/rdt_2_5.png}
    \end{center}

    Tuttavia, la versione 2.0 del protocollo RDT presenta un \textbf{difetto fatale}: se la risposta ACK/NAK è corrotta, il mittente non è più a conoscenza di cosa sia accaduto al destinatario. Inoltre, non è sufficiente ritrasmettere il pacchetto per risolvere tale difetto, poiché il destinatario potrebbe ricevere due pacchetti duplicati ed inoltrarli al livello di applicazione.

    \subsection{Protocollo RDT 2.1 e 2.2}

    Per risolvere il difetto fatale della versione 2.0, il \textbf{protocollo RDT 2.1}:

    \begin{itemize}
        \item Viene controllato se la risposta ACK/NAK sia \textbf{corrotta}. Nel caso in cui lo sia, il pacchetto viene rinviato.
        \item Il destinatario non è a conoscenza della possibile corruzione del pacchetto ACK/NAK
        \item Viene aggiunto un \textbf{numero di sequenza} al pacchetto inviato. In particolare, sono necessari i numeri di sequenza 0 ed 1 affinché il protocollo stop and wait possa funzionare correttamente:
        \begin{itemize}
            \item Assieme alla risposta di ACK, il destinatario invia un \textbf{numero di riscontro}, il quale, per convenzione, indica sempre il numero di sequenza del prossimo pacchetto atteso dal destinatario
            \item Se il destinatario ha ricevuto correttamente il pacchetto 0, invia un riscontro con valore 1 (dunque il prossimo pacchetto atteso è il pacchetto 1)
            \item Analogamente, se il destinatario ha ricevuto correttamente il pacchetto 1, invia un riscontro con valore 0 (dunque il prossimo pacchetto atteso è il pacchetto 0)
        \end{itemize}
        \item Se il pacchetto ricevuto dal destinatario è un duplicato, esso viene automaticamente scartato senza essere inviato al livello di applicazione
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.475]{images/rdt_21_1.png}

        \includegraphics[scale=0.475]{images/rdt_21_2.png}
    \end{center}

    In aggiunta alle modifiche della versione 2.1, il protocollo RDT 2.2 \textbf{elimina} la necessità di una risposta \textbf{NAK}: il ricevitore invia come numero di riscontro il numero di sequenza dell'\textbf{ultimo pacchetto correttamente}. In tal modo, un ACK duplicato al mittente comporta la stessa azione di un NAK, ossia la ritrasmissione del pacchetto corrente.

    \begin{center}
        \includegraphics[scale=0.475]{images/rdt_22.png}
    \end{center}

    \newpage

    \subsection{Protocollo RDT 3.0}

    Oltre all'assunzione di possibili bit invertiti, il \textbf{protocollo RDT 3.0} assume la possibilità di una \textbf{perdita di pacchetti}, sia dati che ACK. Per risolvere tale problematica, il mittente \textbf{attende un lasso di tempo}:
    
    \begin{itemize}
        \item Il destinatario deve specificare il \textbf{numero di sequenza del pacchetto} per il quale sta inviando un ACK
        \item Se non viene ricevuto alcun ACK allo scadere del lasso di tempo, il pacchetto dati (che indicheremo con pkt) viene ritrasmesso
        \item Se pkt o ACK arrivano successivamente allo scadere del tempo, il pacchetto verrà ritrasmesso, implicando che la trasmissione verrà duplicata (problema già gestito dai numeri di sequenza)
    \end{itemize}

    La FSM associata al mittente corrisponde a:

    \begin{center}
        \includegraphics[scale=0.425]{images/rdt_3_1.png}
    \end{center}


    \begin{center}
        \begin{tabular}{ccc}

            \textbf{Nessuna perdita} & & \textbf{Perdita di pkt}\\

            \begin{tabular}{c}
                \includegraphics[scale=0.425]{images/rdt_3_2.png}
            \end{tabular}
            &\qquad&
            \begin{tabular}{c}
                \includegraphics[scale=0.425]{images/rdt_3_3.png}
            \end{tabular}
        \end{tabular}

        \begin{tabular}{ccc}
            \textbf{Perdita di ACK} & & \textbf{Ritardo di ACK}\\
            \includegraphics[scale=0.425]{images/rdt_3_4.png}
            &\qquad&
            \includegraphics[scale=0.425]{images/rdt_3_5.png}
        \end{tabular}
    \end{center}

    Tuttavia, in cambio dei notevoli benefici del meccanismo stop and wait, le \textbf{prestazioni} del protocollo RDT 3.0 risultano essere \textbf{infime}, limitando le prestazioni dell'infrastruttura sottostante, ossia il canale.

    In particolare, la \textbf{percentuale di utilizzo} $U_{mit}$ della comunicazione da parte del mittente, ossia la frazione di tempo in cui il mittente è impegnato nell'invio corrisponde a:
    \[U_{mit} = \frac{D_{t}}{RTT+D_t}\]

    dove $D_t$ è il delay di trasmissione (dunque $D_t = \frac{L}{R}$ con $L$ la lunghezza del pacchetto e $R$ il transmission rate del link)

    \begin{center}
        \includegraphics[scale=0.475]{images/rdt_3_6.png}
    \end{center}

    \newpage

    \textbf{Esempio:}

    \begin{itemize}
        \item Considerando un link avente un rate pari a $R=1$ Gb/s, una lunghezza di pacchetto pari a $L=8000$ b e un ritardo di propagazione sia pari a $15$ ms, la percentuale di utilizzo del mittente corrisponde a:
        \[D_t = \frac{8 \cdot 10^3 \;b}{10^{9} \;b/s} = 8 \;\mu s\]
        \[U_{mit} = \frac{8 \;\mu s}{30 \;ms + 8 \;\mu s} = 27 \cdot 10^{-5} = 0.027 \%\]
    \end{itemize}

    \quad

    \subsection{Go-back-N e Selective repeat}

    Per migliorare le prestazioni del protocollo RDT 3.0, viene utilizzato il \textbf{pipelining}, dove il mittente consente la presenza di molteplici trasferiti senza aver ricevuto un ACK precedente.

    Per realizzare il pipelining, l'\textbf{intervallo di numeri di sequenza} deve essere \textbf{aumentato}, poiché è necessario tener traccia di più pacchetti simultaneamente, richiedendo inoltra la presenza di un \textbf{buffer} interno al mittente e al destinatario.

    Poiche i pacchetti successivi al primo vengono inviati durante contemporaneamente al RTT del primo pacchetto, è sufficiente considerare un solo RTT, incrementando notevolmente la percentuale di utilizzo del mittente:

    \textbf{Esempio:}

    \begin{itemize}
        \item Riprendendo i dati dell'esempio precedente, effettuando il pipelining con 3 pacchetti si ha che
        \[U_{mit} = \frac{3 \cdot D_{t}}{RTT+D_t} = 3 \cdot \frac{8 \;\mu s}{30 \;ms + 8 \;\mu s} = 81 \cdot 10^{-5} = 0.081 \%\]
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.45]{images/pipelining.png}
    \end{center}
    
    \newpage

    Una delle metodologie con cui viene implementato il pipelining è il \textbf{Go-back-N}:
    \begin{itemize}
        \item Il mittente ha una "finestra" di $N$ pacchetti consecutivi trasmessi senza ACK (\textbf{ACK cumulativo}). La ricezione del pacchetto \textbf{ACK(n)} viene interpretato dal mittente come un ACK per ognuno dei singoli $N$ pacchetti, implicando che alla sua ricezione la finestra venga spostata in avanti in modo che essa abbia il pacchetto $N+1$ come primo pacchetto
        
        \begin{center}
            \includegraphics[scale=0.44]{images/go-back-n_1.png}
        \end{center}

        \item Viene mantenuto attivo un \textbf{timer} per il pacchetto della finestra inviato e senza ACK \textbf{più vecchio}. Una volta scaduto tale timeout, viene ritrasmesso il pacchetto e tutti i pacchetti con numero di sequenza maggiore presenti all'interno della finestra
        
        \item Il destinatario invia sempre l\textbf{'ACK con numero di sequenza maggiore} (in ordine) per i pacchetti attualmente ricevuti \textbf{correttamente}, implicando che non vi siano pacchetti con numero di sequenza minore mancanti.
        
        Tale procedura potrebbe generare ACK duplicati e richiede di ricordare solamente un \textbf{valore \texttt{rcv\_base}} (a differenza della finestra del mittente), corrispondente al numero di sequenza del pacchetto di cui si è in attesa
        
        \item Se il destinatario riceve un pacchetto fuori ordine, può, a seconda dell'implementazione, scartare tale pacchetto (\textbf{politica don't buffer}) o conservarlo (\textbf{politica buffer}), inviando in entrambi i casi un ACK con il più alto numero di sequenza che si trovi nell'ordine corretto, richiedendo quindi la trasmissione di tutti i pacchetti con numero di sequenza maggiore. 
        \begin{center}
            \includegraphics[scale=0.45]{images/go-back-n_4.png}
        \end{center}
    \end{itemize}

    \newpage

    \textbf{Esempio:}

    \begin{itemize}
        \item Consideriamo la seguente finestra di 7 pacchetti
        \begin{center}
            \includegraphics[scale=0.415]{images/go-back-n_2.png}
        \end{center}

        \item Una volta ricevuto ACK(5), i pacchetti 4 e 5 vengono considerati come arrivati a destinazione, scorrendo la finestra in avanti
        
        \begin{center}
            \includegraphics[scale=0.415]{images/go-back-n_3.png}
        \end{center}
    \end{itemize}
        
    \quad

    \begin{center}
        \includegraphics[scale=0.475]{images/go-back-n_5.png}
    \end{center}

    \begin{center}
        \includegraphics[scale=0.47]{images/go-back-n_6.png}
    \end{center}

    \newpage

    \textbf{Esempio (protocollo Go-back-N con politica don't buffer):} 

    \begin{center}
        \includegraphics[scale=0.45]{images/go-back-n_7.png}
    \end{center}

    Poiché nel caso in cui un singolo pacchetto venga perso o corrotto è necessario rinviare tutti i pacchetti successivi già inviati nella pipeline, il protocollo Go-back-N può \textbf{peggiorare la congestione della rete}.

    Contrariamente, il \textbf{protocollo Selective Repeat} è in grado di gestire tale problematica:

    \begin{itemize}
        \item Oltre al mittente, anche il destinatario è dotato di una\textbf{ finestra di $N$ pacchetti}
        \item Il destinatario conferma \textbf{individualmente} tutti i pacchetti ricevuti correttamente, anche nel caso in cui essi siano fuori sequenza, \textbf{bufferizzandoli} per l'eventuale consegna in ordine al livello superiore
        \item Il mittente mantiene un \textbf{timer per ogni pacchetto} inviato senza ACK, rinviando ogni pacchetto individualmente alla scadenza del suo timeout
        \item La finestra del mittente scorre a partire dal \textbf{pacchetto più alto confermato in ordine} (senza pacchetti non confermati prima di esso). Alla ricezione dell'ACK di un pacchetto, dunque, se tale pacchetto era il più piccolo pacchetto non ancora confermato, la finestra avanza fino al prossimo pacchetto non confermato
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.425]{images/s_rep_1.png}
    \end{center}

    \textbf{Esempio:} 

    \begin{center}
        \includegraphics[scale=0.4]{images/s_rep_2.png}
    \end{center}

    Tuttavia, anche il protocollo Selective Repeat non è privo di problematiche. In particolare, se la dimensione della finestra è troppo piccola, si può andare in contro a casi sfavorevoli (\textbf{dilemma della finestra}). Ad esempio, con un range di numeri di sequenza pari a $0,1,2,3$ e una finestra di dimensione $3$, si ha che:

    \begin{center}
        \begin{tabular}{ccc}
            \textbf{Nessun problema} & & \textbf{Accettazione pacchetto sbagliato}\\
            \includegraphics[scale=0.44]{images/s_rep_3.png}
            &&
            \includegraphics[scale=0.44]{images/s_rep_4.png}
        \end{tabular}
    \end{center}

    \textbf{Esempio:}

    \begin{itemize}
        \item In una rete con un valore fisso $m > 1$ (numero di bit della sequenza), è possibile utilizzare entrambi i meccanismi Go-Back-N e Selective Repeat, si indichino i vantaggi e gli svantaggi dell'impiego di ciascuno di essi. Quali altre considerazioni si devono fare per decidere quale
        meccanismo utilizzare?
        
        \item \textbf{Go-back-N}
        \begin{itemize}
            \item Ritrasmette tutti i frame inviati dopo il frame che si sospetta essere danneggiato o perso
            \item Se il tasso di errore è alto, spreca molta larghezza di banda
            \item Meno complicato
            \item Window size $N-1 = 2^m -1$
            \item  Riordinamento non è richiesto né lato mittente né lato destinatario
            \item  Il destinatario non memorizza i frame ricevuti dopo il frame corrotto finché esso non viene ritrasmesso (dipende dall'implementazione)
            \item Non è richiesta alcuna ricerca di frame né lato mittente né destinatario
        \end{itemize}

        \item \textbf{Selective Repeat}
        \begin{itemize}
            \item Ritrasmette solo i frame sospettati di essere persi o danneggiati
            \item  Comparativamente meno larghezza di banda
            viene sprecata nella ritrasmissione
            \item Più complesso in quanto richiede l'applicazione di logica aggiuntiva, ordinamento e archiviazione, lato mittente e destinatario
            \item Window size $\frac{N+1}{2} = 2^{m-1}$
            \item Il destinatario deve essere in grado di ordinare in quanto deve mantenere la sequenza dei frame
            \item Il destinatario memorizza i frame ricevuti dopo il frame danneggiato nel buffer finché il frame danneggiato non viene sostituito
            \item Il mittente deve essere in grado di cercare e selezionare il frame richiesto
        \end{itemize}
    \end{itemize}

    Un'idea aggiuntiva implementata nei \textbf{trasferimenti bidirezionali} (dunque dove entrambi i dispositivi sono sia mittente sia destinatario, coincidenti con la vita reale) è il \textbf{piggybacking}, dove nel momento in cui un pacchetto stia trasportando dati dal dispositivo A al dispositivo B, vengono trasportati anche i riscontri ricevuti da A inerenti ai pacchetti ricevuti da B, in modo che entrambi i dispositivi ne siano a conoscenza, gestendo efficientemente il rinvio dei pacchetti.

    \newpage

    \addtocontents{toc}{\protect\newpage}
    \section{Protocollo TCP}

    \quad

    Il \textbf{protocollo TCP} è un protocollo \textbf{end-to-end}, ossia con un solo mittente ed un solo destinatario, offerente un \textbf{byte stream affidabile e in ordine}, dove i messaggi del livello di applicazione vengono concatenati in un unico stream, a differenza dell'UDP, dove ogni messaggio è un segmento diverso.

    Come già discusso, il protocollo TCP è \textbf{orientato alla connessione}, dove l'\textbf{handshaking} inizializza lo stato del mittente e del destinatario prima dello scambio dei dati.

    Il flusso dati, inoltre è \textbf{full duplex}, ossia bidirezionale all'interno della stessa connessione (dati full duplex), limitati tuttavia da un \textbf{Maximum Segment Size (MSS)}.
    Tuttavia, è necessario sottolineare che si tratta di un paradigma diverso dalla commutazione di circuito, poiché la rete non è a conoscenza dello stabilimento della connessione.

    \begin{center}
        \includegraphics[scale=0.4]{images/tcp_segment.png}
    \end{center}

    Per gestire il trasporto affidabile, il protocollo TCP utilizza:
    \begin{itemize}
        \item \textbf{ACK cumulativi} e \textbf{pipelining}, dove il window size dipende dal \textbf{flow control}, ossia una garanzia sul non sovraccarico del destinatario da parte del mittente, e dal \textbf{congestion control}, ossia una garanzia sol non sovraccarico della rete da parte del mittente
        
        \item Il \textbf{numero di sequenza} dei segmenti del protocollo TCP corrisponde al numero di sequenza del \textbf{primo byte del settore data} del segmento stesso. Per quanto riguarda l'\textbf{ACK}, viene utilizzato il numero di sequenza del \textbf{byte successivo aspettato}.
        
        \item Nel momento in cui il mittente riceve dati dal livello di applicazione, viene creato il segmento e il suo numero di sequenza, avviando il timer a meno che esso non sia già in esecuzione. Inoltre, il \textbf{timer} utilizzato è \textbf{singolo} e collegato al \textbf{segmento non confermato pià vecchio}. Allo scadere del \textbf{\texttt{TimeoutInterval}}, viene ritrasmesso il segmento che ha causato il timeout, riavviando il timer.
        
        \newpage
        
        \item Alla \textbf{ricezione di un ACK}, invece, se quest'ultimo copre segmenti precedentemente non confermati, vengono aggiornate le informazioni di tali pacchetti, avviando il timer se vi sono ancora segmenti non confermati, il quale sarà collegato al nuovo segmento più vecchio (ibrido tra Go-back-N e Selective Repeat)
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.6]{images/tcp_ack.png}
    \end{center}

    Per quanto riguarda il destinatario, invece, si hanno quattro scenari:
    
    \begin{itemize}
        \item All'arrivo di un \textbf{segmento in ordine}, con \textbf{numero di sequenza atteso} e tutti i segmenti \textbf{precedenti già confermati}, viene inviato un \textbf{delayed ACK}: dopo aver atteso 500 ms per il prossimo segmento, se quest'ultimo non è stato ricevuto viene inviato l'ACK
        
        \item All'arrivo di un \textbf{segmento in ordine}, con \textbf{numero di sequenza atteso} e ma con un segmento precedente \textbf{non ancora confermato}, viene immediatamente inviato un ACK cumulativo confermante entrambe i segmenti
        
        \item All'arrivo di un \textbf{segmento fuori ordine} e con numero di sequenza maggiore di quello atteso (dunque vi è un \textbf{gap}), viene inviato immediatamente un ACK duplicato
        
        \item All'arrivo di un segmento che in parte o totalmente \textbf{riempie in ordine un gap}, viene immediatamente inviato l'ACK
    \end{itemize}
    
    \begin{center}
        \begin{tabular}{ccc}
            \textbf{ACK perso} && \textbf{ACK perso e ACK cumulativo risolvente}\\
        \includegraphics[scale=0.5]{images/tcp_ack_lost.png}
        &\qquad&
        \includegraphics[scale=0.5]{images/tcp_ack_lost_2.png}
        \end{tabular}
    \end{center}

    \begin{center}
        \begin{tabular}{c}
            \textbf{Timeout prematuro}\\
        \includegraphics[scale=0.5]{images/tcp_premature_timeout.png}
        \end{tabular}
    \end{center}

    \quad

    \subsection{Gestione del timeout e stima del RTT}

    \quad

    Il valore di timeout impostato deve essere \textbf{più lungo di un RTT}. Tuttavia, poiché il RTT è variabile, è necessario \textbf{stimarlo}.

    Se il timeout scelto è \textbf{troppo corto}, si verificheranno troppi timeout prematuri, creando una serie di ritrasmissioni non necessarie. Se invece è \textbf{troppo lungo}, vi è una reazione troppo lenta a seguito della perdita di un pacchetto.

    Per stimare il RTT, viene campionato un valore \texttt{\textbf{SampleRTT}}, ossia il tempo misurato dalla trasmissione del segmento fino alla ricezione dell'ACK (ignorando le ritrasmissioni). Poiché \texttt{SampleRTT} varia, viene utilizzata una \textbf{media delle misurazioni recenti} e non solo dell'ultimo \texttt{SampleRTT} (EWMA - Exponential Weighted Moving Average):
    \[\texttt{EstimatedRTT} = (1-\alpha) \cdot \texttt{PreviousEstimatedRTT} + \alpha \cdot \texttt{SampleRTT}\]
    dove tipicamente si ha $\alpha = 0.125$ e dove l'influenza del campione passato diminuisce in modo esponenziale

    \begin{center}
        \includegraphics[scale=0.55]{images/expected_rtt.png}
    \end{center}

    Il valore del \texttt{\textbf{TimeoutInterval}}, dunque, corrisponderà al valore attuale dell'\texttt{EstimatedRTT} sommato ad un \textbf{margine di sicurezza}
    \[\texttt{TimeoutInterval} = \texttt{EstimatedRTT}+4 \cdot \texttt{DevRTT}\]
    dove \texttt{DevRTT} è l'EWMA della deviazione di \texttt{SampleRTT} da \texttt{EstimatedRTT}
    \[\texttt{DevRTT} = (1-\beta) \cdot \texttt{PreviousDevRTT}+\beta \abs{\texttt{SampleRTT} - \texttt{EstimatedRTT}} \]
    con un valore tipico $\beta=0.25$

    Un'ottimizzazione ulteriore del protocollo TCP prevede l'implementazione del \textbf{fast retransmit}: se il mittente riceve 3 ACK aggiuntivi per gli stessi dati (dunque \textbf{tre ACK duplicati}), viene nuovamente inviato il segmento non confermato con numero di sequenza pià piccolo poiché probabilmente tale segmento è andato perso, dunque non è necessario aspettare il timeout

    \begin{center}
        \includegraphics[scale=0.45]{images/tcp_fast_ret.png}
    \end{center}

    \quad

    \subsection{Controllo del flusso}

    Per poter funzionare correttamente, il protocollo TCP necessita di un \textbf{controllo del flusso}. Ad esempio, se la velocità con cui il livello di rete del destinatario fornisce i dati è maggiore rispetto a quella con cui il suo livello di applicazione rimuove i dati dal buffer del socket, il buffer andrà in \textbf{overflow}, implicando che i dati in eccesso vengano necessariamente \textbf{scartati}, risultando tuttavia come ricevuti correttamente dal destinatario.

    \begin{center}
        \includegraphics[scale=0.44]{images/tcp_stream.png}
    \end{center}

    Di conseguenza, è necessario che il \textbf{destinatario controlli il mittente}, impedendo che quest'ultimo possa riempire il buffer del destinatario trasmettendo troppi dati velocemente. Per gestire il flusso, quindi, viene utilizzata un campo \texttt{rwnd} (\textbf{receive window}) all'interno del segmento TCP:
    \begin{itemize}
        \item Il destinatario inserisce in \texttt{rwnd} il numero di byte che è disposto ad accettare (dunque lo spazio rimanente nel buffer del socket)
        \item La dimensione del \texttt{RcvBuffer} impostata tramite le opzioni socket (predefinito a 4096 byte) o gestita automaticamente dal sistema operativo
        \item Il mittente limita la quantità di dati inviati senza ACK al valore di \texttt{rwnd}, garantendo che il buffer di ricezione non vada in overflow
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.43]{images/tcp_stream_2.png}
    \end{center}

    \subsection{Gestione della connessione}

    Prima di effettuare lo scambio di dati, il mittente e il destinatario effettuano un \textbf{handshake}, dove viene determinata la disponibilità dell'un e dell'altro ad accettare di stabilire una connessione, concordando i parametri di quest'ultima (es: l'inizio del numero di sequenza)

    \begin{center}
        \includegraphics[scale=0.38]{images/socket_param.png}
    \end{center}

    Una prima implementazione dell'handshake è l'\textbf{handshake a 2 vie}, dove il mittente invia la richiesta di connessione al destinatario, il quale invia successivamente l'accettazione di tale richiesta, assumendo lo stato di connessione \textbf{\texttt{ESTAB}} (established).
    
    Una volta ricevuta l'accettazione, anche il mittente assumerà lo stato \texttt{ESTAB}, per poi procedere con l'invio effettivo dei dati. 

    \begin{center}
        \includegraphics[scale=0.525]{images/handshake_2way.png}
    \end{center}

    Tuttavia, in tale implementazione il destinatario \textbf{non è a conoscenza} della \textbf{ricezione} da parte del mittente del pacchetto di \textbf{accettazione} della connessione, presentando quindi \textbf{due problematiche fondamentali}:

    \begin{itemize}
        \item Nel caso in cui il mittente \textbf{rinvii la richiesta} di connessione allo scadere del timer TCP e e l'accettazione del destinatario inerente alla prima richiesta giunge comunque dopo lo scadere del timer, il mittente suppone che la connessione sia andata a buon fine (nonostante il RTT sia estremamente basso), stabilendo quindi una \textbf{prima connessione}.

        \item Se tale connessione viene \textbf{terminata} prima che la seconda richiesta del mittente sia giunta al destinatario, quest'ultimo interpreterà la richiesta come una richiesta appartenente ad un'\textbf{seconda connessione}.
        
        \item Tuttavia, poiché tale richiesta era solo un rinvio della prima richiesta connessione, il client ignorerà la seconda richiesta di accettazione del server, creando quindi una \textbf{connessione fantasma senza client}

        \begin{center}
            \includegraphics[scale=0.475]{images/handshake_2way_2.png}
        \end{center}

        \item Inoltre, nel caso in cui venga stabilita una connessione fantasma, si potrebbe andare incontro ad accettazioni di pacchetti dati duplicati
        
        \begin{center}
            \includegraphics[scale=0.44]{images/handshake_2way_3.png}
        \end{center}
    \end{itemize}

    Di conseguenza, l'handshake TCP viene implementato attraverso uno scambio di 3 messaggi (\textbf{handshake a 3 vie}):

    \begin{enumerate}
        \item Il mittente sceglie un numero di sequenza iniziale $x$ e invia un pacchetto di tipo \textbf{\texttt{SYN} (synchronize)} al destinatario, richiedendo di stabilire una connessione.
        
        Per inviare un pacchetto di tipo \texttt{SYN}, è sufficiente impostare il campo \texttt{SYN = 1} all'interno dell'header

        \item Una volta ricevuto il pacchetto \texttt{SYN}, il destinatario sceglie un numero di sequenza iniziale $y$ e invia un pacchetto di tipo \textbf{\texttt{SYN/ACK} (synchronize and ACK)} al mittente, impostando i campi \texttt{SYN = 1} e \texttt{ACK = 1} nell'header
        
        \item Una volta ricevuto il pacchetto \texttt{SYN/ACK}, il mittente invia un pacchetto di tipo \texttt{ACK} (dunque con solo \texttt{ACK = 1}), passando in stato \texttt{ESTAB}. Infine, una volta ricevuto il pacchetto \texttt{ACK}, il destinatario passerà in stato \texttt{ESTAB}
    \end{enumerate}

    \begin{center}
        \includegraphics[scale=0.37]{images/handshake_3way.png}
    \end{center}

    In questo modo, il destinatario sarà a conoscenza dello stato finale del mittente, risolvendo le due problematiche.

    Per effettuare la \textbf{chiusura di una connessione}, il primo dispositivo (mittente o destinatario che sia) invia al secondo dispositivo un pacchetto di tipo \textbf{\texttt{FIN} (finished)}. Una volta ricevuto il pacchetto \texttt{FIN}, il secondo dispositivo risponderà con un pacchetto \texttt{FIN/ACK}, per poi inviare, dopo un breve lasso di tempo, un secondo pacchetto \texttt{FIN}. Analogamente, anche il primo dispositivo una volta ricevuto il pacchetto \texttt{FIN} invierà un pacchetto \texttt{FIN/ACK}.
    
    Utilizzando tale \textbf{handshake a 4 vie}, entrambi i dispositivi riescono accertarsi il corretto termine della connessione. Inoltre, in tal modo entrambi i dispositivi possono terminare la connessione simultaneamente (creando una sorta di doppio handshake a 2 vie)

    \section{Controllo della congestione}

    A differenza del \textbf{controllo del flusso}, il quale si occupa di gestire un mittente troppo veloce per un destinatario, il \textbf{controllo della congestione} si occupa di gestire situazioni in cui vi sono troppe fonti che inviano una grande quantità di dati troppo velocemente per poter essere gestiti correttamente dalla rete.

    In presenza di congestione della rete, si manifestano \textbf{lunghi ritardi}, dovuti all'accodamento di troppi pacchetti nel buffer dei router, e \textbf{perdita di pacchetti}, dovuti agli overflow dei buffer dei vari router.

    \subsection{Cause e costi della congestione}

    Consideriamo il seguente scenario:

    \begin{itemize}
        \item Vi sono due connessioni aperte passanti per un router con \textbf{buffer di dimensione infinita} e il transmission rate dei link è $R$
        \item $\lambda_{in}$ è l'\textbf{arrival rate del router}, la quantità di dati inviati da un host della prima rete al router 
        \item $\lambda_{out}$ è il \textbf{throughput del router}, la quantità di dati inviati dal router ad un host della seconda rete
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.45]{images/cong_1.png}
    \end{center}

    In tal caso, poiché il buffer è infinito ci troviamo in una situazione in cui non sono necessarie ritrasmissioni dovute alla perdita del pacchetto. Di conseguenza, l'\textbf{arrival rate} riesce ad essere equivalente al \textbf{throughput}, corrispondente alla quantità di dati in uscita dal router.
    
    Tuttavia, poiché sono aperte due connessioni passanti per il router, il throughput massimo di ognuna di esse corrisponde a $\frac{R}{2}$. Inoltre, anche in tale scenario perfetto, man mano che $\lambda_{in}$ si avvicina a $\frac{R}{2}$, il \textbf{delay cresce notevolmente}, per via carico eccessivo sui link stessi della rete.

    \begin{center}
        \includegraphics[scale=0.5]{images/cong_2.png}
    \end{center}

    Nella vita reale, ovviamente, la dimensione dei buffer è \textbf{finita}, implicando che alcuni pacchetti possano andar persi, venendo ritrasmessi dal mittente a seguito dello scadere del timeout.

    Dato l'arrival rate $\lambda_{in}'$ dei \textbf{dati originali sommati ai dati ritrasmessi}, è necessario sottolineare che:
    \begin{itemize}
        \item Al livello di applicazione, la quantità di dati inviati è equivalente a quella dei dati ricevuti, dunque si ha che $\lambda_{in} = \lambda_{out}$
        \item Al livello di trasporto, tuttavia, l'input contiene anche i dati ritrasmessi, implicando che $\lambda_{in}' \geq \lambda_{in}$
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.525]{images/cong_3.png}
    \end{center}

    \newpage

    A questo punto, procediamo per \textbf{assunzioni} per studiare come la congestione influenzi l'infrastruttura:

    \begin{itemize}
        \item Idealmente, possiamo assumere che il mittente vada ad inviare i dati \textbf{solamente} nel caso in cui esso sappia che i buffer dei router abbiano abbastanza spazio per ricevere il pacchetto (assunzione \textbf{perfect knowledge})
        
        In tal caso, ci troveremmo in una situazione identica allo scenario perfetto, poiché la rete sarebbe in grado di gestire il carico senza problemi, inviando i dati da un router all'altro al loro arrivo.

        \item In uno scenario più realistico, assumiamo che i pacchetti possano essere scartati a seguito di un \textbf{overflow} di un buffer e che il mittente sia a conoscenza perfetta di quali pacchetti siano andati persi, ritrasmettendoli (\textbf{perfect knowledge parziale}).
        
        In tal caso, parte della capacità dei link verrebbe sprecata per via delle ritrasmissioni, \textbf{diminuendo il throughput}
        
        \begin{center}
            \includegraphics[scale=0.525]{images/cong_6.png}
        \end{center}

        \item In uno scenario reale, oltre alla perdita di pacchetti dovuta ad un overflow dei buffer, il \textbf{timer} del mittente può scadere prematuramente, inviando due copie dello stesso pacchetto ritrasmesso (\textbf{duplicati non necessari})
        
        In tal caso, ulteriore parte della capacità dei link verrebbe sprecata per via delle ritrasmissioni non necessarie, \textbf{diminuendo il throughput ulteriormente}

        \begin{center}
            \includegraphics[scale=0.525]{images/cong_8.png}
        \end{center}
    \end{itemize}

    \newpage

    Consideriamo invece ora una rete più realistica in cui tutti e quattro i dispositivi sono mittenti e vi siano più router colleganti le loro reti (rete multi-hop).
    
    \begin{center}
        \includegraphics[scale=0.475]{images/cong_9.png}
    \end{center}

    All'aumentare dei valori $\lambda_{in}^{red}$ e $\lambda_{in}^{red}\,'$ del collegamento rosso mostrato in figura, \textbf{tutti i pacchetti del collegamento blu vengono scartati}, poiché il buffer del router viene riempito dai pacchetti del collegamento rosso rinviati, portando il valore $\lambda_{out}^{blue}$ a tendere a 0, diminuendo il throughput generale della rete

    \begin{center}
        \includegraphics[scale=0.4]{images/cong_10.png}
    \end{center}

    Possiamo quindi riassumere il comportamento della rete nei seguenti punti:

    \begin{itemize}
        \item Il throughput non può mai superare la capacità
        \item Il ritardo aumenta con l'avvicinarsi alla capacità
        \item La perdita e ritrasmissione riduce il throughput effettivo
        \item I duplicati non necessari riducono ulteriormente il throughput effettivo
        \item Viene sprecata capacità di trasmissione e buffering upstream per i pacchetti persi downstream
    \end{itemize}

    Infine, utilizziamo tali punti per definire i \textbf{costi della congestione}:
    \begin{itemize}
        \item È necessario un \textbf{lavoro} (numero di ritrasmissioni) \textbf{maggiore} per un dato throughput durante la congestione
        \item Il collegamento trasporta \textbf{più copie} dello stesso pacchetto \textbf{non necessarie}, riducendo il throughput massimo ottenibile
        \item Quando un pacchetto viene scartato, tutta la capacità di trasmissione upstream e la porzione di buffer utilizzata per esso viene \textbf{sprecata}
    \end{itemize}

    \newpage

    \subsection{Controllo della congestione nel TCP}

    Per tentare di gestire la congestione, vengono principalmente utilizzati due approcci:
    \begin{itemize}
        \item \textbf{Controllo della congestione end-to-end}, dove non viene ricevuto alcun feedback esplicito dalla rete e la congestione viene \textbf{dedotta} dalle perdite e ritardi osservati dal mittente e il destinatario.
        
        Tale approccio è adottato dal protocollo TCP

        \item \textbf{Controllo della congestione assistito dalla rete}, dove i router forniscono un feedback \textbf{diretto} agli host di invio/ricezione con flussi che passano attraverso router congestionati, indicando, in alcuni casi, direttamente il livello di congestione o la velocità di invio impostata
    \end{itemize}

    \begin{frameddefn}{Algoritmo AIMD}
        L'algoritmo \textbf{AIMD (Additive Increase, Multiplicative Decrease)} è un algoritmo utilizzato da alcune versioni del protocollo TCP per \textbf{prevenire la congestione}, dove i mittenti possono \textbf{aumentare la velocità di invio} fino a quando si verifica una \textbf{perdita di pacchetti}, per poi diminuirla:
        \begin{itemize}
            \item \textbf{Additive Increase}: il rate viene aumentato di 1 MSS (Maximum Segment Size) ad ogni RTT fino a quando una perdita non viene osservata
            \item \textbf{Multiplicative Decrease}: ad ogni perdita osservata, il rate di invio viene dimezzato
        \end{itemize}
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.55]{images/aimd.png}
    \end{center}

    \quad

    \begin{frameddefn}{Congestion avoidance e Congestion window}
        Approssimativamente, il protocollo TCP utilizza la seguente procedura di \textbf{prevenzione della congestione (congestion avoidance)}:

        \begin{itemize}
            \item Viene utilizzato un valore \textbf{\texttt{cwnd}} (\textbf{congestion window}), corrispondente alla quantità di byte inviata ad ogni RTT, da cui ne segue che
            \[\texttt{Rate di invio} \approx \frac{\texttt{cwnd}}{\text{RTT}} \; \text{B/s}\]

            \item Il mittente limita la trasmissione a $\texttt{LastByteSent} - \texttt{LastByteAcked} \leq \texttt{cwnd}$

            \item Il valore \texttt{cwnd} varia dinamicamente reagendo alla congestione osservata. In particolare, utilizzando l'\textbf{Additive Increase} ad ogni ACK ricevuto si ha che:
            \[\texttt{cwnd} \approx \texttt{prev\_cwnd} + \left (\text{MSS} \cdot \frac{\text{MSS}}{\texttt{prev\_cwnd}} \right )\]
        \end{itemize}
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.5]{images/tcp_cong.png}
    \end{center}

    \begin{frameddefn}{Fast recovery}
        Il \textbf{fast recovery} è una procedura utilizzata da alcune versioni del protocollo TCP per \textbf{prevenire la congestione}, dove ad ogni perdita rilevata a seguito di un \textbf{triplo ACK duplicato} viene \textbf{dimezzato il rate di invio} (ottenuto circa dimezzando il valore \texttt{cwnd})
    \end{frameddefn}

    \begin{frameddefn}{Slow start}
        Lo \textbf{slow start} è una procedura utilizzata da alcune versioni del protocollo TCP \textbf{prevenire la congestione}, dove:
        \begin{itemize}
            \item Il valore \texttt{cwnd} viene \textbf{impostato ad 1 MSS} all'inizio della connessione o a seguito di un \textbf{timeout}
            \item Successivamente, il valore di \texttt{cwnd} viene \textbf{raddoppiato ad ogni RTT}, fino al rilevamento della prima perdita di pacchetto (\textbf{incremento esponenziale})
        \end{itemize}
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.45]{images/slow_start.png}

        \textit{\textbf{Nota}: l'immagine superiore è un'approssimazione del vero comportamento, poiché raddoppiare \texttt{cwnd} non implica che venga raddoppiata la quantità di segmenti inviati, bensì che raddoppi la quantità di segmenti di \underline{dimensione massima} inviati}
    \end{center}

    \textbf{Versioni del protocollo TCP:}
    \begin{itemize}
        \item \textbf{TCP Tahoe}: composto da un'algoritmo di \textbf{congestion avoidance} (tramite l'Additive Increase), l'algoritmo \textbf{slow start} e il \textbf{fast retransmit}
        \item \textbf{TCP Reno}: analogo al TCP Tahoe, ma con l'utilizzo aggiuntivo del \textbf{fast recovery} (FSM riportata in seguito)
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/tcp_reno.png}
    \end{center}

    In particolare, per effettuare il passaggio tra \textbf{slow start} e \textbf{congestion avoidance}, viene utilizzato un valore \texttt{\textbf{ssthresh}} (\textbf{slow start threshold}).
    
    \begin{itemize}
        \item A seguito del rilevamento di una perdita di pacchetto, il valore \texttt{ssthresh} viene impostato a $\frac{\texttt{cwnd}}{2}$ (con il valore di \texttt{cwnd} precedente alla perdita). Se al prossimo RTT si verificasse che \texttt{cwnd} $\geq$ \texttt{ssthresh}, viene posto \texttt{cwnd} = \texttt{ssthresh} e si passa dallo slow start al congestion avoidance
        \item Nel caso particolare del TCP Reno, se si verifica un triplo ACK duplicato, il valore \texttt{cwnd} viene dimezzato dal fast recovery, dunque si ha direttamente \texttt{cwnd} = \texttt{ssthresh}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.525]{images/tahoe_vs_reno.png}
    \end{center}

    \begin{frameddefn}{TCP CUBIC}
        Il \textbf{TCP CUBIC} è una versione di TCP utilizzante l'algoritmo \textbf{CUBIC} per \textbf{prevenire la congestione}, il quale è definito dalla seguente logica:

        \begin{itemize}
            \item Viene utilizzato un valore $W$, corrispondente alla \textbf{velocità di invio} (o alla quantità di dati inviati dal mittente, ossia \texttt{cwnd}). Ad ogni perdita rilevata, viene \textbf{dimezzato} tale valore.
            
            \item Il limite superiore $W_{max}$ corrisponde alla \textbf{velocità di invio} nel momento in cui è stata rilevata una \textbf{perdita di pacchetto} (viene assunto che a seguito della perdita lo stato di congestione della rete non sia variato di molto)
            
            \item Viene utilizzato un valore $K$ corrispondente al \textbf{momento di tempo stimato} in cui il valore $W$ raggiungerà il limite superiore $W_{max}$ (la modalità di stima viene definita dallo standard RFC 8312)
            
            \item Il valore $W$ viene \textbf{incrementato in funzione del cubo della distanza tra il tempo corrente e $K$}. Di conseguenza, il valore $W$ \textbf{crescerà molto rapidamente} quando il tempo corrente è lontano dal valore $K$, mentre \textbf{crescerà lentamente} al suo avvicinarsi.
        \end{itemize}
    \end{frameddefn}

    Supponendo, ad esempio, che il valore di $W_{max}$ rimanga sempre lo stesso nel tempo, il throughput del TCP CUBIC rispetto a quello standard risulta più elevato:
    \begin{center}
        \includegraphics[scale=0.5]{images/tcp_cubic.png}
    \end{center}

    In particolare, essendo predefinito sul sistema operativo Linux, il TCP CUBIC è la versione del protocollo TCP più diffusa nei web server.

    Una volta aver visto algoritmi e tecniche per prevenire la congestione, possiamo concentrarci sul link di uscita del stesso in cui si verifica la perdita (\textbf{bottleneck link})
    
    \begin{center}
        \includegraphics[scale=0.5]{images/bottleneck_link.png}
    \end{center}

    In presenza di un bottleneck link, \textbf{aumentando il rate di invio} non aumenterà il throughput per via del bottleneck link ma \textbf{aumenterà il RTT misurato}.
    
    \begin{center}
        \includegraphics[scale=0.5]{images/bottleneck_link_2.png}
    \end{center}

    Una soluzione ottimale, dunque, è quella di mantenere il percorso end-to-end \textbf{quasi pieno}, ma senza superare la soglia stabilita, utilizzando un approccio \textbf{delay-based}:
    \begin{itemize}
        \item Il valore RTT$_{min}$ è il RTT minimo osservato dal mittente, corrispondente quindi al RTT osservato quando il percorso \textbf{non è congestionato}
        \item Approssimativamente, il \textbf{throughput misurato} ad ogni RTT corrisponde a:
        \[\text{Throughput}_{\text{misurato}} = \frac{\text{Byte}_{\text{RTT}}}{\text{RTT}_{misurato}}\]
        dove Byte$_{\text{RTT}}$ è il numero di byte inviati nell'ultimo RTT, mentre il \textbf{throughput non congestionato} è pari a: 
        \[\text{Throughput}_{\text{non cong}} = \frac{\texttt{cwnd}}{\text{RTT}_{min}}\]
        \item Se il valore del throughput misurato è \textbf{molto vicino} a quello non congestionato, il valore di \texttt{cwnd} viene \textbf{incrementato} in modo lineare (dunque +1 MSS ad ogni RTT), mentre se è \textbf{molto inferiore} viene \textbf{decrementato} in modo lineare
    \end{itemize}

    Tramite tale approccio, alcune versioni di TCP (es: protocollo BBR) riescono ad indurre un controllo della congestione senza forzare delle perdite di pacchetto, massimizzando il throughput ma mantenendo basso il ritardo.

    Altre versioni di TCP (es: TCP ECN), invece, implementano anche la seconda modalità di controllo della congestione, ossia il \textbf{controllo della congestione assistito dalla rete}, dove:
    \begin{itemize}
        \item Due bit dell'\textbf{header del livello di rete} vengono contrassegnati dal \textbf{router} per indicare lo stato della congestione
        \item Una volta raggiunto il destinatario, quest'ultimo imposterà il bit ECE sul segmento ACK per notificare al mittente lo \textbf{stato della congestione}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.575]{images/congestion_2.png}
    \end{center}
    
    \newpage

    \section{Equità nei protocolli di trasporto}

    \begin{framedprop}{Equità nelle connessioni}
        Affinché un protocollo di trasporto sia definibile \textbf{equo}, se $K$ \textbf{sessioni} di tale protocollo condividono lo stesso \textbf{bottleneck link} con larghezza di banda $R$, ciascuna delle $K$ sessioni deve avere una velocità media pari a $\frac{R}{K}$
    \end{framedprop}
    
    Notiamo con facilità che il \textbf{protocollo UDP} sia un protocollo \textbf{non equo} per via dell'assenza di un controllo della congestione e di limiti sulla banda utilizzabile.
    
    Per tale motivo, spesso applicazioni multimediali utilizzanti il protocollo UDP (es: i servizi streaming) "rubano" velocità di connessione ad altre applicazioni.

    Per quanto riguarda il protocollo TCP, invece, è necessario effettuare uno studio:

    \begin{itemize}
        \item Consideriamo il seguente scenario con due sessioni TCP con algoritmo AIMD concorrenti sullo stesso bottleneck link 
        \begin{center}
            \includegraphics[scale=0.375]{images/fairness.png}
        \end{center}

        \item Tramite l'\textbf{additive increase} viene generata una pendenza pari ad 1
        \item Tramite il \textbf{multiplicative decrease} viene ridotto proporzionalmente il throughput
        
        \begin{center}
            \includegraphics[scale=0.4]{images/fairness_2.png}
        \end{center}

    \end{itemize}

    Sotto \textbf{ipotesi idealizzate}, dunque, il \textbf{protocollo TCP} risulta essere \textbf{equo} (es: stesso RTT, numero fisso di sessioni, ...). Tuttavia, molte applicazioni moderne utilizzano \textbf{più di una connessione TCP parallela} tra due host (es: un web browser). Di conseguenza, anche se la larghezza di banda fosse equamente distribuita tra tutte le connessioni possibili tra i due host, tale applicazione otterrebbe comunque una quantità di banda superiore alle altre applicazioni. 

    \chapter{Livello di Rete}
    
    Come già accennato, a differenza del livello di trasporto, il \textbf{livello di rete} si occupa della comunicazione logica tra i dispositivi stessi tramite il trasporto di segmenti dall'host di invio a quello di ricezione.

    In particolare, ogni \textbf{router} della rete si occupa di esaminare i campi header di tutti i \textbf{datagrammi} IP che lo attraversano, spostandoli dalle porte di ingresso alle porte di uscita per trasferirli lungo il percorso end-to-end

    \begin{frameddefn}{Forwarding e Routing}
        All'interno del livello di rete distinguiamo \textbf{due funzionalità fondamentali}:

        \begin{itemize}
            \item \textbf{Forwarding (inoltro)}, ossia il trasferimento dei pacchetti dal link di ingresso di un router al link appropriato di uscita tramite la \textbf{gestione delle porte}
            \item \textbf{Routing (instradamento)}, ossia la determinazione (solitamente tramite \textbf{algoritmi} di routing) del percorso seguito dai pacchetti dalla sorgente alla destinazione
        \end{itemize}
    \end{frameddefn}

    Per poter realizzare correttamente il servizio di trasferimento dei datagrammi, il livello di rete deve essere in grado di realizzare entrambe tali funzioni fondamentali. Distinguiamo quindi il servizio di rete in \textbf{due strati}:

    \begin{itemize}
        \item \textbf{Data plane}, dove viene determinato come il datagramma in arrivo sulla porta di ingresso di un router venga inoltrato alla porta di uscita del router (\textbf{lavoro in locale})
        \item \textbf{Control plane}, dove viene determinato come il datagramma venga instradato tra i router lungo il percorso end-to-end dall'host di origine all'host di destinazione (\textbf{logica a livello di rete})
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/control_data_plane.png}
    \end{center}

    Oltre agli \textbf{algoritmi di routing} implementati all'interno dei singoli router, per il control plane può essere utilizzato anche il \textbf{Software-Defined Networking (SDN)}, dove un server remoto, detto \textbf{controller remoto}, calcola preventivamente tutte le \textbf{forwarding table} dei router, ossia le tabelle contenenti le regole di inoltro, i quali poi si connetteranno con il controller stesso per ottenere ed installare la propria tabella

    \begin{center}
        \includegraphics[scale=0.5]{images/SDN.png}
    \end{center}
    
    Nella gestione dei "canali" di trasporto dei datagrammi dal mittente al destinatario viene utilizzato un modello \textbf{best effort}:
    \begin{itemize}
        \item \textbf{Non vi è garanzia} sull'effettiva \textbf{consegna} del datagramma a destinazione
        \item \textbf{Non vi è garanzia} sulle \textbf{tempistiche} o sull'\textbf{ordine} di consegna dei datagrammi
        \item \textbf{Non vi è garanzia} sulla \textbf{larghezza di banda} disponibile per il flusso end-to-end
    \end{itemize}

    \newpage

    Nonostante i difetti, il modello best effort ha raggiunto un ottimo \textbf{successo}:
    \begin{itemize}
        \item La sua \textbf{semplicità} ha permesso ad Internet di essere ampiamente adottato ed implementato
        \item Una \textbf{larghezza di banda sufficiente} consente alle prestazioni delle applicazioni in tempo reale di essere per lo più sufficientemente ottime
        \item I \textbf{servizi distribuiti replicati a livello di applicazione} che si connettono vicino alle reti dei clienti (data center,reti di distribuzione di contenuti, ...) consentono di fornire servizi da più posizioni
    \end{itemize}

    \quad

    \section{Architettura e funzionalità dei router}

    L'architettura interna di un router può essere riassunta in:
    \begin{itemize}
        \item Una serie di \textbf{porte di ingresso e di uscita} connesse a dei link
        \item Una \textbf{struttura di commutazione (switching fabric)} interposta tra le porte di entrata ed uscita
        \item Un \textbf{processore di instradamento}, il quale si occupa di effettuare i calcoli necessari per il routing
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/arch_router.png}
    \end{center}

    Le \textbf{porte di ingresso e di uscita} sono dotate di:
    \begin{itemize}
        \item Una propria \textbf{memoria} contenente le \textbf{forwarding table}
        \item Una \textbf{terminazione di linea} (ossia il termine/inizio del link ad esse associate)
        \item Un'interfaccia con il \textbf{livello di collegamento} tramite cui viene gestito il protocollo utilizzato (es: Ethernet)
        \item Una \textbf{coda di ingresso/uscita} in cui vengono inseriti temporaneamente i pacchetti appena vengono ricevuti o prima di essere spediti.
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/in_port.png}
        
        \includegraphics[scale=0.425]{images/out_port.png}
    \end{center}

    In particolare, all'interno della coda della porta di ingresso viene effettuata una \textbf{commutazione decentralizzata}, dove per ogni datagramma al suo interno viene cercata la porta di uscita utilizzando i valori del campo di intestazione e della forwarding table nella memoria della porta di input stessa (\textbf{match plus action}).

    Per realizzare tale commutazione, vengono utilizzati il \textbf{destination-based forwarding}, dove l'inoltro è basato solo sull'indirizzo IP di destinazione presente negli header, e il \textbf{generalized forwarding}, dove l'inoltro è basato su un insieme di valori dell'header dei datagrammi.

    \begin{frameddefn}{Longest prefix matching}
        Il \textbf{longest prefix matching} è un algoritmo di forwarding basato sul destination-based forwarding: durante la ricerca della voce della forwarding table per un indirizzo di destinazione, viene selezionata l'entrata il cui indirizzo ha il \textbf{prefisso più lungo corrispondente} a quello dell'indirizzo di destinazione
    \end{frameddefn}

    \textbf{Esempio:}

    \begin{itemize}
        \item Consideriamo la seguente forwarding table, dove gli asterischi, detti \textbf{wildcard}, indicano che un qualsiasi valore tra 0 o 1 possa occupare tale posizione (\textbf{intervalli di indirizzi IP})
        
        \begin{center}
            \begin{tabular}{l|c}
                \textbf{Intervallo di indirizzi di destinazione} & \textbf{Porta di uscita}\\
                \hline
                \texttt{11001000 00010111 00010*** ********} & 0\\
                \texttt{11001000 00010111 00011000 ********} & 1\\
                \texttt{11001000 00010111 00011*** ********} & 2\\
                altrimenti & 3
            \end{tabular}
        \end{center}

        \item Utilizzando il longest prefix matching, il datagramma contenente l'indirizzo di destinazione \texttt{11001000 00010111 00010110 10100001} verrà inoltrato alla porta di uscita 0, poiché l'intervallo \texttt{11001000 00010111 00010*** ********} possiede il prefisso corrispondente più lungo tra le tutte le entrate
        
        \item Analogamente, il datagramma contenente l'indirizzo di destinazione \texttt{11001000 00010111 00011000 10101010} verrà inoltrato alla porta di uscita 1, poiché l'intervallo \texttt{11001000 00010111 00011000 ********} possiede il prefisso corrispondente più lungo tra le tutte le entrate (24 cifre rispetto alle 21 della porta 2)
    \end{itemize}

    \quad

    Per quanto riguarda gli \textbf{switching fabric}, essi si occupano di effettuare il vero e proprio inoltro, trasferendo ogni pacchetto dai link di input al link di output appropriato.
    
    In particolare, lo \textbf{switching rate} dello switching fabric corrisponde alla velocità con cui i pacchetti possono essere trasferiti dagli ingressi alle porte (idealmente pari a $N \cdot R$, dove $N$ è il numero di porte di ingresso/uscita ed $R$ è il transmission rate dei link connessi alla porta, supponendo che esso sia uguale per tutti i link)

    Le principali tre modalità di implementazione degli switching fabric prevedono:

    \begin{itemize}
        \item \textbf{Commutazione tramite memoria}, dove la commutazione è sotto diretto controllo della CPU, copiando i pacchetti in arrivo nella \textbf{memoria del sistema}, per poi inviarli sulle porte di uscita, implicando che lo switching rate sia limitato dalla larghezza di banda della memoria.
        
        \begin{center}
            \includegraphics[scale=0.4]{images/comm_memory.png}
        \end{center}

        \item \textbf{Commutazione tramite bus}, dove i datagrammi vengono trasferiti dalla memoria della porta di ingresso alla memoria della porta di uscita tramite un \textbf{singolo bus} condiviso, implicando che lo switching rate sia limitato dalla larghezza di banda del bus e che vi sia una contesa tra le porte per l'utilizzo del bus
        
        \begin{center}
            \includegraphics[scale=0.5]{images/comm_bus.png}
        \end{center}

        \item \textbf{Commutazione tramite reti di interconnessione}, dove vengono utilizzate reti di interconnessione (es: Crossbar, reti Clos) inizialmente sviluppate per connettere processori tra di loro. In particolare, vengono utilizzati \textbf{interruttori multistadio}, ossia interruttori $N \times N$ formati da più stadi di interruttori più piccoli, e il \textbf{parallelismo}, frammentando i diagrammi in celle di lunghezza fissa all'ingresso per poi commutarle attraverso la rete di interconnessione e riassemblarle una volta raggiunta la porta di uscita
        
        \begin{center}
            \begin{tabular}{ccc}
                \textbf{Interruttore $3 \times 3$} & & \textbf{Interruttore multistadio $8 \times 8$}\\
                &&\textbf{formato interruttori più piccoli}\\
                \includegraphics[scale=0.5]{images/comm_net_1.png}

                &\qquad\qquad&
                
                \includegraphics[scale=0.5]{images/comm_net_2.png}
            \end{tabular}
        \end{center}

        \quad

        Inoltre, l'uso di reti di interconnessione permette un maggiore \textbf{scaling} utilizzando più "piani" di commutazione in parallelo

        \begin{center}
            \includegraphics[scale=0.525]{images/comm_net_3.png}
        \end{center}
    \end{itemize}

    \quad

    \subsection{Accodamento nelle porte}

    Nel caso in cui lo switch fabric sia più lento delle porte di input combinate, dunque se lo switching rate è minore del transmission rate dei link di entrata, potrebbe verificarsi dell'\textbf{accodamento} nei buffer di coda delle \textbf{porte di input}, generando un \textbf{queueing delay} e una possibile \textbf{perdita} dovuta all'overflow del buffer. 
    
    In particolare, possono verificarsi due situazioni sfavorevoli che possano generare accodamento nella porta di input:
    
    \begin{itemize}
        \item \textbf{Contesa della porta di uscita}: in ogni istante può essere commutato un solo pacchetto verso una determinata porta di uscita, impedendo agli altri pacchetti di proseguire, bloccando di conseguenza la loro coda
        
        \begin{center}
            \includegraphics[scale=0.525]{images/queue_in_2.png}
        \end{center}

        \item \textbf{Blocco HOL (Head-of-Line)}: all'interno di ogni coda il datagramma nella parte anteriore della coda impedisce agli altri datagrammi in coda di poter proseguire
        
        \begin{center}
            \includegraphics[scale=0.525]{images/queue_in_1.png}
        \end{center}
    \end{itemize}
    
    \quad

    Analogamente, può verificarsi dell'\textbf{accodamento} all'interno nei buffer di coda delle \textbf{porte di output} nel caso in cui lo switch rate superi il transmission rate del link di uscita, generando ritardo e perdite di pacchetti.

    \begin{center}
        \includegraphics[scale=0.475]{images/queue_out.png}
    \end{center}

    \quad

    Per gestire tali accodamenti, dunque, è necessario gestire minuziosamente i \textbf{buffer}. In particolare, lo standard più recente prevede un buffer di dimensione pari a:
    \[\text{Buffer } = \frac{\text{RTT} \cdot C}{\sqrt{N}}\]
    dove $N$ è il numero di flussi e $C$ è la capacità dei collegamenti.

    \newpage

    Tuttavia, un buffering eccessivo può \textbf{aumentare i ritardi} (in particolare all'interno dei router domestici):
    \begin{itemize}
        \item Con RTT lunghi si ottengono scarse prestazioni per le app in tempo reale ed una risposta TCP troppo lenta
        \item I buffer dovrebbero solo assorbire le fluttuazioni statistiche di occupazione in mancanza di congestione, senza creare un collo di bottiglia troppo pieno
    \end{itemize}

    Di conseguenza, è necessario utilizzare un \textbf{protocollo di scarto} per scegliere quale pacchetti inserire nella coda e quali scartare quando il buffer è pieno. In particolare, vengono utilizzati principalmente il \textbf{tail drop}, dove viene scartato l'ultimo pacchetto in arrivo, e il \textbf{priority drop}, dove i pacchetti vengono scartati selettivamente in base alla priorità.

    \quad

    \subsection{Scheduling dei pacchetti}

    Per decidere quale sia il prossimo pacchetto da inviare, le porte di uscita vengono gestite tramite \textbf{politiche di scheduling}, cercando di ottenere le \textbf{migliori prestazioni} possibili mantenendo una \textbf{neutralità della rete}, ossia la modalità con cui un ISP dovrebbe allocare le proprie risorse.

    In particolare, vengono principalmente utilizzate quattro politiche:
    \begin{itemize}
        \item \textbf{First come, First served (FCFS)}, dove i pacchetti vengono trasmessi in ordine di arrivo alla porta di uscita
        \item \textbf{Priority scheduling}, dove il traffico in arrivo viene classificato ed inserito in una classe di coda in base alla sua priorità, inviando il pacchetto della coda con la priorità più alta contenente pacchetti nel buffer (FCFS all'interno delle classi di priorità). La priorità viene determinata utilizzando un insieme di campi presenti nell'intestazione del pacchetto.
        
        \begin{center}
            \includegraphics[scale=0.525]{images/prio_sched.png}
        \end{center}

        \item \textbf{Round Robin (RR)}, dove il traffico in arrivo viene sempre classificato in code di classe utilizzando più code e l'invio dei pacchetti viene effettuato ciclicamente: viene ciclicamente eseguita una scansione delle code di classe, inviando a turno un pacchetto completo da ciascuna classe (se disponibile)
        
        \begin{center}
            \includegraphics[scale=0.45]{images/round_robin.png}
        \end{center}

        \item \textbf{Weighted fair queueing (WFQ)}, dove il traffico in arrivo viene sempre classificato in code di classe utilizzando più code e l'invio dei pacchetti viene effettuato in base al peso delle classi: ogni classe $i$ ha un peso $w_i$ e riceve una quantità ponderata di servizio ad ogni ciclo, equivalente a 
        \[\frac{w_i}{\sum\limits_{j = 1}^k w_j}\]
        dove $k$ è il numero di classi.

        In tal modo, si ottiene una gestione pari ad un Round Robin generalizzato e viene garantita una larghezza di banda minima per ogni classe di traffico.
        \begin{center}
            \includegraphics[scale=0.525]{images/wfq_sched.png}
        \end{center}
    \end{itemize} 

    Inoltre, con la terminologia "neutralità della rete" vengono anche contrassegnati i \textbf{principi sociali/economici} e i \textbf{provvedimenti legali} atti a stabilire regole e politiche di gestione. In particolare, tale neutralità viene basata su tre principi:
    \begin{itemize}
        \item \textbf{No blocking}: non devono essere bloccati contenuti, applicazioni, servizi o dispositivi leciti e non dannosi soggetti ad una ragionevole gestione della rete
        \item \textbf{No throttling}: non si deve compromettere o degradare il traffico Internet legittimo sulla base di contenuti, applicazioni o servizi Internet o l'uso di un dispositivo non dannoso, soggetto a una ragionevole gestione della rete
        \item \textbf{No payed priority}: non deve essere prevista la prioritizzazione retribuita
    \end{itemize}
    
    \quad

    \subsection{Frammentazione dei datagrammi}

    Per gestire meglio la \textbf{congestione}, i collegamenti di rete possiedono \textbf{Maximum Transmission Unit (MTU)}, ossia la dimensione massima comunicabile in una singola trasmissione del livello di rete all'interno del link stesso (dunque variabile a seconda del tipo di collegamento).

    Di conseguenza, ogni datagramma di grandi dimensioni viene \textbf{frammentato} lungo la sua trasmissione a seconda dei link attraverso cui avviene il forwarding, venendo \textbf{ri-assemblato} solamente una volta raggiunta la destinazione, richiedendo quindi un campo all'interno dell'header per mantenere  traccia dell'\textbf{ordine}.
    
    \begin{center}
        \includegraphics[scale=0.5]{images/fragment_ip.png}
    \end{center}

    \newpage

    \section{Protocollo IP}

    Principalmente, all'interno del livello di rete viene utilizzato un solo protocollo standard, ossia il \textbf{protocollo IP (Internet Protocol)}.

    \begin{center}
        \includegraphics[scale=0.425]{images/ip_prot.png}
    \end{center}

    Il protocollo IP è basato su tre costrutti fondamentali:
    \begin{itemize}
        \item \textbf{Interfaccia}, ossia una \textbf{connessione} tra host e router associata ad un \textbf{collegamento fisico}. Solitamente, i router possiedono più interfacce, mentre un host possiede una o due interfacce (es: interfaccia Ethernet cablata ed interfaccia wireless Wi-Fi). Vengono gestite e determinate dal livello di collegamento.
        \item \textbf{Sottorete}, ossia un insieme di interfacce di dispositivi che possono raggiungersi fisicamente l'un l'altro senza passare attraverso un router intermedio (dunque tramite uno switch o altri mezzi).
        \item \textbf{Indirizzo IP}, ossia un identificatore a 32 bit associato ad un'interfaccia. Per facilitare la gestione agli umani, viene interpretato con una \textbf{notazione decimale puntata}, dove l'indirizzo viene suddiviso in quattro ottetti ed ogni ottetto viene interpretato come un valore decimale
        
        (es: l'indirizzo \texttt{11011111 00000001 00000001 00000001} viene interpretato come \texttt{223.1.1.1})
        
        La struttura degli indirizzi IP viene definita dal \textbf{Classless Inter Domain Routing (CIDR, letto "cider")}:
        \begin{itemize}
            \item Ogni indirizzo possiede una \textbf{parte di sottorete}, condivisa tra i dispositivi della stessa sottorete e costituita da un determinato numero di bit più significativi (dunque più a sinistra). Gli $n$ bit utilizzati per la parte di sottorete vengono definiti all'interno della \textbf{subnet mask}, i cui primi $n$ bit più significativi sono posti ad 1 e i restanti posti a 0 (formata da 32 bit totali)
            \item Ogni indirizzo possiede una \textbf{parte di host}, identificante l'host stesso all'interno della sottorete e costituita dai bit meno significativi rimanenti
            \item Il formato degli indirizzi "ciderized" segue la struttura \texttt{a.b.c.d/x}, dove \texttt{a.b.c.d} è l'indirizzo IP e \texttt{x} è la quantità di bit posti ad 1 della subset mask
            
            (es: l'indirizzo \texttt{200.23.16.0/23} viene interpretato come \texttt{11001000 00010111 00010000 00000000}, dove i primi 23 bit rappresentano la sottorete)
        \end{itemize}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.35]{images/subnet.png}
    \end{center}
    
    L'utilizzo della \textbf{subnet mask} risulta essere estremamente comodo per ottenere in modo efficiente informazioni sul \textbf{blocco di indirizzi} definito dalla sottorete:
    \begin{itemize}
        \item Il \textbf{numero di indirizzi del blocco} corrisponde al bitwise NOT della maschera sommato ad 1
        \[\text{Num. indirizzi} = \texttt{NOT(\text{mask})+1}\]
        \item Il \textbf{primo indirizzo del blocco} corrisponde al bitwise AND tra un indirizzo qualsiasi del blocco e la maschera
        \[\text{Primo indirizzo} = \texttt{(\text{qualsiasi indirizzo del blocco}) AND (\text{mask})}\]
        (solitamente viene utilizzato per indicare direttamente la sottorete)
        \item L'\textbf{ultimo indirizzo del blocco} corrisponde al bitwise OR tra un indirizzo qualsiasi del blocco e il bitwise NOT della maschera
        \[\text{Ultimo indirizzo} = \texttt{(\text{qualsiasi indirizzo del blocco}) OR (NOT(\text{mask}))}\]
    \end{itemize}

    \begin{framedprop}{Indirizzi IP speciali}
        Alcuni \textbf{indirizzi IP speciali} vengono utilizzati come scorciatoie per ottenere determinati comportamenti:
        \begin{itemize}
            \item L'indirizzo \texttt{0.0.0.0} viene utilizzato per indicare \textbf{qualsiasi indirizzo possibile}
            \item Gli indirizzi IP la cui parte di rete è impostata completamente a 0 si riferiscono alla \textbf{sottorete corrente}
            \item L'indirizzo \texttt{255.255.255.255} permette la \textbf{trasmissione broadcast}, ossia ad ogni dispositivo, sulla rete \textbf{locale}
            \item Gli indirizzi con parte di rete opportuna e la parte di host impostata completamente ad 1 permettono l'invio di pacchetti \textbf{broadcast a reti distanti}
            \item Gli indirizzi in cui il primo ottetto è impostato a 127, dunque gli indirizzi \texttt{127.x.y.z}, vengono riservati al \textbf{loopback}. Tali pacchetti non vengono trasmessi sul mezzo di trasmissione ma vengono elaborati localmente dall'host e trattati come se fossero pacchetti in arrivo.
        \end{itemize}
    \end{framedprop}

    \quad

    \subsection{Protocollo DHCP e indirizzamento gerarchico}

    Ogni \textbf{host} può ottenere il suo indirizzo IP all'interno della sua rete, dunque la sua \textbf{parte host} da associare alla parte di sottorete, in modalità \textbf{statica} tramite una sua configurazione interna (es: il file \texttt{/etc/rc.config} sul sistema operativo Unix) o in modalità \textbf{dinamica} ottenendo tale indirizzo IP da un server addetto, non richiedendo alcuna configurazione.
    
    \begin{frameddefn}{Protocollo DHCP}
        Il \textbf{protocollo Dynamic Host Configuration Protocol (DHCP)} è un protocollo a \textbf{livello di applicazione} in grado di assegnare dinamicamente gli indirizzi IP agli host interni ad una rete:
        \begin{enumerate}
            \item Nel momento in cui si unisce alla rete, l'host effettua una richiesta broadcast interna alla rete, cercando un server DHCP al suo interno (\textbf{DHCP discover})
            \item Il server DHCP (solitamente collocato all'interno del router stesso) risponde alla richiesta offrendo all'host un possibile indirizzo IP (\textbf{DHCP offer})
            \item L'host risponde al server accettando tale indirizzo IP, prendendolo "in prestito" fino a quando esso non si disconnetterà dalla rete (\textbf{DHCP request})
            \item Il server DHCP risponde all'host confermando la presa in prestito di tale indirizzo (\textbf{DHCP ack})
        \end{enumerate}
    \end{frameddefn}

    \begin{framedobs}{Riutilizzo di indirizzi precedenti}
        Se l'host appena unitosi alla rete \textbf{ricorda} e desidera \textbf{riutilizzare} il precedente indirizzo IP, verrà inviato direttamente il messaggio di DHCP request in modalità broadcast, permettendo al server DHCP di rispondere immediatamente con un DHCP ack
    \end{framedobs}

    Oltre all'indirizzo IP, solitamente il protocollo DHCP restituisce anche altre informazioni sulla sottorete, come l'indirizzo del router di \textbf{gateway}, ossia il primo router raggiungibile dal client per comunicare in rete, il nome e l'indirizzo IP del server DNS (se ve ne è uno) e la subnet mask della sottorete.

    Per quanto riguarda le \textbf{reti} invece, ognuna di esse ottiene il suo indirizzo IP, dunque la sua \textbf{parte di sottorete}, effettuando una richiesta al proprio ISP, il quale allocherà una \textbf{porzione} del proprio \textbf{spazio di indirizzi}.

    \textbf{Esempio:}

    \begin{itemize}
        \item Un ISP possiede il blocco di indirizzi \texttt{200.23.16.0/20}
        \item L'ISP decide di suddividere il suo blocco in 8 blocchi, associando ciascuno di essi ad un'organizzazione richiedente un blocco di indirizzi.
        
        \begin{center}
            \begin{tabular}{c|c|c}
                \textbf{Proprietario} & \multicolumn{2}{c}{\textbf{Indirizzo IP}}\\
                \hline
                ISP & \texttt{\underline{11001000 00010111 0001}0000 00000000} & \texttt{200.23.16.0/20}\\
                Organiz. 1 & \texttt{\underline{11001000 00010111 0001000}0 00000000} & \texttt{200.23.16.0/23}\\
                Organiz. 2 & \texttt{\underline{11001000 00010111 0001001}0 00000000} & \texttt{200.23.18.0/23}\\
                ... & ... & ...\\
                Organiz. 7 & \texttt{\underline{11001000 00010111 0001111}0 00000000} & \texttt{200.23.30.0/23}\\
            \end{tabular}
        \end{center}
    \end{itemize}

    \quad

    In tal modo, è possibile creare una struttura di \textbf{indirizzamento gerarchico}, permettendo un'instradamento più efficiente tramite la pubblicizzazione di percorsi più specifici per poter raggiungere le sottoreti.

    \textbf{Esempio:}

    \begin{itemize}
        \item Nell'esempio precedente, l'ISP pubblicizza un percorso più specifico per poter raggiungere le varie organizzazioni tra cui ha diviso il suo blocco di indirizzi, richiedendo all'esterno che gli venga inviato qualsiasi pacchetto avente un'indirizzo ricadente in tali range
    \end{itemize}

    In particolare, l'indirizzamento gerarchico è anche uno dei motivi per cui il \textbf{longest prefix matching} risulti essere cosi efficiente, cercando di inviare il pacchetto seguendo l'orientamento gerarchico.

    Per ottenere un blocco di indirizzi, ogni ISP deve effettuare una richiesta all'\textbf{Internet Corporation for Assigned Names and Numbers (ICANN)}, la quale alloca gli indirizzi IP attraverso \textbf{5 registri regionali} e gestisce la zona radice del DNS, inclusa la delega della gestione dei singoli TLD.

    Tuttavia, nel 2011 l'ICANN ha assegnato l'ultima parte disponibile di \textbf{indirizzi IPv4} (ossia la versione trattata fino ad adesso), \textbf{esaurendo} a tutti gli effetti \textbf{gli indirizzi assegnabili}.

    \quad

    \subsection{Servizio NAT e Protocollo IPv6}

    Per aggirare il problema dell'esaurimento degli indirizzi IPv4, è stato idealizzato un \textbf{escamotage} tramite l'implementazione del \textbf{Network Address Translation (NAT)}:
    \begin{itemize}
        \item Tutti i dispositivi interni ad una sottorete condividono \textbf{un solo IPv4 pubblico}, il quale viene utilizzato per identificare l'intera sottorete al mondo esterno
        \item Tutti i dispositivi interni ad una sottorete possiedono un proprio \textbf{indirizzo IPv4 privato}, il quale può essere utilizzato solo all'interno della sottorete stessa
        \item Tutti i datagrammi che escono dalla rete locale hanno lo \textbf{stesso indirizzo IPv4 pubblico di origine} ma \textbf{diversi numeri di porta di origine}, utilizzando quindi la porta del livello di trasporto come un identificatore univoco per un indirizzo IPv4 privato
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.375]{images/nat.png}
    \end{center}

    Tramite il NAT, dunque, l'ISP può utilizzare un \textbf{singolo indirizzo IPv4} per identificare ogni dispositivo interno ad una sottorete. Inoltre, gli indirizzi della rete locale possono essere gestiti separatamente, permettendo di cambiarli senza dover avvisare il mondo esterno e fornendo una \textbf{maggiore sicurezza}, poiché i dispositivi della rete locale non sono direttamente indirizzabili e visibili dall'esterno.
    
    Per implementare il NAT, dunque, è necessario:
    \begin{enumerate}
        \item \textbf{Sostituire} la coppia \texttt{<IP origine, Porta Origine>} di ogni datagramma in uscita con la coppia \texttt{<IP Router, Porta Random Inutilizzata>}, implicando che i client/server remoti risponderanno utilizzando la nuova coppia come indirizzo di destinazione
        \item \textbf{Memorizzare} all'interno di una \textbf{tabella di traduzione NAT} ogni coppia di conversione
        \item \textbf{Sostituire} nuovamente la coppia di tutti i datagrammi in arrivo con la coppia originale, per poi spedire il datagramma al destinatario interno alla rete
    \end{enumerate}

    \begin{center}
        \includegraphics[scale=0.425]{images/nat_2.png}
    \end{center}

    Per via della sua implementazione, l'utilizzo del NAT ha generato molte controversie:
    \begin{itemize}
        \item Per loro definizione stessa, i router dovrebbero processare i pacchetti solo \textbf{fino al livello di rete}, mentre per attuare il NAT è necessario che essi adoperino anche il livello di trasporto per modificare le porte dei datagrammi
        \item La \textbf{carenza di indirizzi} può essere risolta anche tramite gli \textbf{indirizzi IPv6} (che vedremo in seguito)
        \item Viene \textbf{violata} la modalità di trasmissione \textbf{end-to-end}, poiché è necessario manomettere il pacchetto per effettuare le traduzioni
    \end{itemize}

    Tuttavia, il NAT risulta ormai essere attualmente ampiamente utilizzato in reti domestiche, istituzionali e cellulari, rendendo \textbf{lenta} la sua sostituzione con strumenti più moderni.

    In particolare, il principale strumento che (man mano) sostituirà l'uso dell'IPv4 e il NAT è il \textbf{protocollo IPv6}, dove vengono utilizzati \textbf{128 bit} per gli indirizzi invece di 32 bit e vengono \textbf{rimossi} il \textbf{checksum} per i datagrammi (non per gli altri livelli superiori) per velocizzare l'elaborazione nei router, la \textbf{frammentazione} dei datagrammi e i \textbf{campi opzione} (implementabili tramite protocolli superiori).

    \begin{center}
        \includegraphics[scale=0.4]{images/ipv6.png}
    \end{center}

    \newpage

    Poiché non tutti i router possono essere aggiornati contemporaneamente, attualmente vengono utilizzati un \textbf{indirizzamento misto}, utilizzando sia l'IPv4 che l'IPv6:
    \begin{itemize}
        \item Per le comunicazioni tra due router IPv4 viene utilizzato direttamente il protocollo IPv4. Analogamente, per le comunicazioni tra due router IPv6 viene utilizzato direttamente il protocollo IPv6
        \item Per le comunicazioni tra un router IPv6 e un router IPv4 viene utilizzato il \textbf{tunneling}, dove un datagramma IPv6 viene trasportato come payload all'interno di un datagramma IPv4 tra router IPv4 ("datagramma dentro un datagramma").
    \end{itemize}
    
    \begin{center}
        \includegraphics[scale=0.5]{images/tunneling_ipv6.png}
    \end{center}
    \begin{center}
        \includegraphics[scale=0.475]{images/tunneling_ipv6_2.png}
    \end{center}

    \section{Protocollo ICMP e Traceroute}

    \quad

    \begin{frameddefn}{Protocollo ICMP}
        Il \textbf{protocollo Internet Control Message Protocol (ICMP)} è un protocollo a livello di rete utilizzato da host e router per scambiarsi informazioni a livello di rete (es: report degli errori come un host irraggiungibile).
        
        I \textbf{messaggi ICMP} hanno un campo \textbf{tipo} e un campo \textbf{codice}, contenendo l'header e i primi 8 byte del datagramma IP che ha provocato la generazione del messaggio.
    \end{frameddefn}

    Il protocollo ICMP viene considerato "parte" del protocollo IP, nonostante quest'ultimo venga utilizzato da ICMP per inviare i suoi messaggi. Per tale motivo, esso viene considerato come "superiore" a IP all'interno dello stack TCP/IP.

    \begin{center}
        \begin{tabular}{ccl}
            \textbf{Tipo} & \textbf{Codice} & \textbf{Descrizione}\\
            \hline
            0 & 0 & Risposta echo (a ping)\\
            3 & 0 & Rete destin. irraggiungibile\\
            3 & 1 & Host destin. irraggiungibile\\
            3 & 2 & Protocollo dest. irraggiungibile\\
            3 & 3 & Porta destin. irraggiungibile\\
            3 & 6 & Rete destin. sconosciuta\\
            3 & 7 & Host destin. sconosciuto\\
            4 & 0 & Riduzione (controllo
            di congestione)\\
            8 & 0 & Richiesta echo\\
            9 & 0 & Annuncio del router\\
            10 & 0 & Scoperta del router\\
            11 & 0 & TTL scaduto\\
            12 & 0 & Errata intestazione IP\\
        \end{tabular}
    \end{center}

    Uno dei programmi utilizzante lo scambio di messaggi echo di richiesta e risposta del protocollo ICMP è il \textbf{programma \texttt{ping}}, presente su (quasi) ogni dispositivo, utilizzato per calcolare rapidamente il RTT.
    
    \textbf{Esempio:}

    \begin{verbatim}
    $ping google.it

    PING google.it (142.250.180.163) 56(84) bytes of data.
    64 bytes from mil04s44-in-f3.1e100.net (142.250.180.163):
    icmp_seq=1 ttl=114 time=17.0 ms
    64 bytes from mil04s44-in-f3.1e100.net (142.250.180.163):
    icmp_seq=2 ttl=114 time=16.5 ms
    64 bytes from mil04s44-in-f3.1e100.net (142.250.180.163):
    icmp_seq=3 ttl=114 time=16.9 ms
    --- google.it ping statistics ---
    3 packets transmitted, 3 received, 0% packet loss, time 2003ms
    rtt min/avg/max/mdev = 16.452/16.800/17.026/0.250 ms\end{verbatim}
    
    Un ulteriore programma utilizzato per vedere il percorso effettuato dal traffico per raggiungere un determinato host è il \textbf{programma \texttt{traceroute}}.
    
    Il programma invia una \textbf{serie di datagrammi IP} alla destinazione, ciascuno contenente un segmento UDP con un numero di porta inutilizzato. All'interno di ogni datagramma viene inserito un \textbf{valore incrementale} (partendo da 1) nel campo header \textbf{Time-to-live (TTL)}, corrispondente al numero di router attraversabili prima che il datagramma venga considerato come \textbf{scaduto}:
    \begin{itemize}
        \item Per ogni datagramma inviato, il mittente avvia un \textbf{timer}
        \item Se l'\textbf{$n$-esimo datagramma} arriva all'\textbf{$n$-esimo router}, esso scarterà il datagramma, inviando al mittente un messaggio di allerta ICMP (tipo 11, codice 0), contenente inoltre il nome del router e il suo indirizzo IP. Quando il messaggio ICMP arriverà al mittente, esso calcolerà anche il RTT. Tale processo viene ripetuto per tre volte.
        \item Se invece il segmento UDP arriva all'\textbf{host di destinazione}, esso restituirà un messaggio ICMP segnalando che la porta sia irraggiungibile (tipo 3, codice 3), utilizzato solo come "valore simbolico". Quando l'origine riceverà tale messaggio, verrà arrestato l'invio di dei datagrammi.
        \item Una volta arrestato l'invio, verranno utilizzati tutti i messaggi di risposta ricevuti per ricostruire il \textbf{percorso effettuato}
    \end{itemize}
    
    \begin{center}
        \includegraphics[scale=0.675]{images/traceroute.png}
    \end{center}


    \newpage

    \section{API OpenFlow e forwarding generalizzato}
    
    Come già discusso in precedenza, ogni router è dotato di una propria \textbf{forwarding table} (anche detta \textbf{flow table}). L'uso delle forwarding table può essere astratto tramite il concetto di \textbf{match plus action}:
    \begin{itemize}
        \item Ad ogni \textbf{match} (ad esempio usando il longest prefix matching), viene eseguita un'\textbf{azione}
        \item Le \textbf{azioni} eseguibili consistono in \texttt{forward}, \texttt{drop}, \texttt{modify} e \texttt{send to controller}
        \item Per disambiguare pattern sovrapposti (ossia match multipli), vengono utilizzate \textbf{regole di priorità}
        \item Vengono utilizzati anche dei \textbf{contatori} per il numero di byte e il numero di pacchetti
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.35]{images/flow_table.png}
    \end{center}

    Le \textbf{API OpenFlow} consentono l'\textbf{accesso al data plane} di un host o router attraverso la rete, venendo utilizzato per dettare le \textbf{regole} implementate all'interno delle forwarding table. Ogni regola dettata è composta da un campo \textbf{match}, un campo \textbf{action} ed un campo \textbf{statistics}

    \begin{center}
        \includegraphics[scale=0.425]{images/openflow.png}
    \end{center}

    \newpage

    \textbf{Esempi:}

    \begin{enumerate}
        \item \textbf{Destination-based forwarding}: per inoltrare sulla porta di output 6 tutti i datagrammi IP destinati all'indirizzo IP \texttt{51.6.0.8} verrà utilizzata la seguente regola:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/of_1.png}
        \end{center}

        \item \textbf{Firewall}: per bloccare tutti i datagrammi IP la cui porta di destinazione è la porta \texttt{TCP/22} (corrispondente ad un protocollo non visto, ossia il protocollo SSH) verrà utilizzata la seguente regola:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/of_2.png}
        \end{center}

        \item \textbf{Forwarding a livello di collegamento}: per inoltrare sulla porta di output 3 tutti i datagrammi IP destinati all'indirizzo MAC \texttt{22:A7:23:11:E1:02} (vedremo in seguito il protocollo MAC) verrà utilizzata la seguente regola:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/of_4.png}
        \end{center}

        \item \textbf{Gestione del flusso}
        
        \begin{itemize}
            \item Consideriamo la seguente rete
            
            \begin{center}
                \includegraphics[scale=0.45]{images/of_5.png}
            \end{center}
            
            \item Vogliamo far sì che i datagrammi dagli host \texttt{h5} e \texttt{h6} inviati verso gli host \texttt{h3} e \texttt{h4} passino prima per il router \texttt{s1} e poi per il router \texttt{s2}

            \begin{center}
                \includegraphics[scale=0.45]{images/of_7.png}
            \end{center}

            \item Per ottenere tale flusso, impostiamo le seguenti flow table all'interno dei router
            
            \begin{center}
                \includegraphics[scale=0.42]{images/of_6.png}
            \end{center}
        \end{itemize}
        
    \end{enumerate}

    \quad

    \section{Principi architetturali di Internet}

    \quad

    \begin{frameddefn}{Middleboxes}
        Un \textbf{middlebox} è un qualsiasi dispositivo \textbf{intermediario} tra mittente e destinatario che esegue \textbf{funzioni diverse} dalle normali funzioni standard di un router (es: NAT, Firewall, Cache servers, Load balancers, ...)
    \end{frameddefn}

    \begin{framedprop}{Principi architetturali di Internet}
        Come dettato all'interno del documento \texttt{RFC 1958}, non vi è una vera e propria architettura standard per Internet, bensì solamente delle \textbf{"tradizioni"}. In termini generici, il servizio Internet è basato su tre principi fondamentali:
        \begin{itemize}
            \item \textbf{Connettività semplice}, rendendo il servizio facile da implementare nel maggior numero di dispositivi possibili
            \item Mantenere la \textbf{clessidra TCP/IP} con il \textbf{minor girovita possibile}, cercando di ridurre al minimo il numero di servizi svolti dal livello di rete, aumentando la quantità verso i livelli superiori e inferiori
            \item Complessità ed intelligenza (ossia lo svolgimento delle operazioni, il mantenimento dei dati, ...) deve essere implementata sulla \textbf{periferia della rete} utilizzando il \textbf{principio end-to-end}.
            \end{itemize}
        \end{framedprop}

    \textbf{Clessidra TCP/IP ottimale}

    \begin{center}
        \includegraphics[scale=0.275]{images/clessidra_1.png}
    \end{center}
    \textbf{Clessidra TCP/IP dopo 40 anni}

    \begin{center}
        \includegraphics[scale=0.4]{images/clessidra_2.png}
    \end{center}

    \quad

    \section{Algoritmi di instradamento}

    Gli \textbf{algoritmi di instradamento} vengono utilizzati per determinare il \textbf{percorso migliore}, ossia una sequenza di router che i pacchetti devono attraversare, da una sorgente ad una destinazione.

    Per determinare tali percorsi, la rete viene modellata come un \textbf{grafo} $G=(V,E)$ i cui vertici $V(G) = \{v_1, \ldots, v_n\}$ corrispondono ai singoli router e/o host e gli archi $E(G)$ corrispondono ai collegamenti tra tali dispositivi. Ad ogni arco $(u,v) \in E(G)$ viene attribuito un \textbf{costo (o peso)} il quale può essere dettato da \textbf{più valori} (maggior velocità, minore congestione, ...).

    \begin{center}
        \includegraphics[scale=0.5]{images/routing_1.png}
    \end{center}

    Gli algoritmi di routing vengono classificati in:
    
    \begin{itemize}
        \item \textbf{Statici}, ossia determinanti percorsi poco soggetti al cambiamento, oppure \textbf{dinamici}, ossia determinanti percorsi soggetti ad un aggiornamento periodico in risposta a variazioni dei costi
        \item \textbf{Globali}, dove al termine dell'algoritmo tutti i router conoscono completamente la topologia e il costo dei link della rete, oppure \textbf{decentralizzati}, dove lo scambio di informazioni avviene tra router vicini che non conoscono l'intero stato della rete
    \end{itemize}

    Per le successive sezioni, utilizzeremo la seguente \textbf{notazione}: 
    \begin{itemize}
        \item $c_{x,y}$ è il \textbf{costo del link diretto} tra i nodi $x$ e $y$. Viene posto uguale a $\infty$ se tale link diretto non esiste.
        \item $D(v)$ è la \textbf{stima corrente} del costo del percorso a minor costo dal nodo sorgente al nodo destinazione $v$
        \item $p(v)$ è il \textbf{nodo predecessore} lungo il percorso dal nodo sorgente al nodo $v$ 
    \end{itemize}

    \quad

    \subsection{Algoritmo link-state di Dijkstra}

    L'\textbf{algoritmo link-state} è un algoritmo \textbf{dinamico globale} basato sull'\textbf{algoritmo di Dijkstra}. Dato un \textbf{nodo sorgente} $u \in V(G)$, per ogni nodo $u \neq v \in V(G)$ viene calcolato il percorso a \textbf{distanza minore} (ossia di minor costo) da un \textbf{nodo sorgente} a tutti gli altri nodi della rete, per poi fornire una forwarding table alla sorgente in base ai percorsi calcolati.
    
    \begin{algorithm}[H]
        \caption{Algoritmo Link-State (basato su Dijkstra)}
        \Fn{\upshape{\texttt{linkStateDijkstra(G, u):}}}{
            \texttt{$R$ = $\{u\}$}\;
            \For{$v \in V(G)$}{
                \eIf{$\exists (u,v) \in E(G)$}{
                    \texttt{D($v$) = $c_{u,v}$}\;
                }
                {
                    \texttt{D($v$) = $\infty$}\;
                }
            }

            \While{$R \neq V(G)$}{
                \texttt{$w := \argmin\limits_{w \in V(G)-R}($\,D($w$)$)$}\;
                \texttt{$R$.add($w$)}\;
                \For{$x \in V(G)-R$}{
                    \uIf{$\exists (w,x) \in E(G)$}{
                        \texttt{D($x$) = min(D($x$), D($w$) + $c_{w,x}$)}\;
                        \texttt{p($x$) = $w$}\;
                    }
                }
            }
        }
    \end{algorithm}

    \textbf{Esempio:}

    \begin{itemize}
        \item Consideriamo la seguente rete
        
        \begin{center}
            \includegraphics[scale=0.5]{images/routing_1.png}
        \end{center}

        \item Vogliamo calcolare la forwarding table del nodo sorgente $u$. Inizializziamo quindi la tabella delle distanze dalla sorgente $u$ verso ogni nodo, ponendo la distanza di ogni nodo adiacente a $u$ pari al costo del link diretto e pari a $\infty$ per ogni altro nodo
    \end{itemize}

    \quad
    
    \begin{center}
        \begin{tabular}{r|c|c|c|c|c}
            \textbf{R} & \textbf{D(v), p(v)} & \textbf{D(w), p(w)} & \textbf{D(x), p(x)} & \textbf{D(y), p(y)} & \textbf{D(z), p(z)}\\
            \hline
            \{u\} & 2, u & 5, u & 1, u & $\infty$ & $\infty$\\
        \end{tabular}
    \end{center}

    \newpage

    \begin{itemize}
        \item A questo punto, consideriamo il nodo avente distanza minore dal nodo attualmente analizzato (ossia $u$), corrispondente al nodo $x$. Per ogni nodo $a$ adiacente a $x$ non ancora analizzato (ossia non in $R$), poniamo la nuova distanza calcolata pari al il minimo tra la distanza dalla sorgente ad $x$, ossia $D(x)$, e la somma tra la distanza tra la sorgente ed $a$ e il costo del link tra $a$ ed $x$, ossia $D(a)+c_{a,x}$
    \end{itemize}

    \quad

    \begin{center}
        \begin{tabular}{r|c|c|c|c|c}
            \textbf{R} & \textbf{D(v), p(v)} & \textbf{D(w), p(w)} & \textbf{D(x), p(x)} & \textbf{D(y), p(y)} & \textbf{D(z), p(z)}\\
            \hline
            \{u\} & 2, u & 5, u & 1, u & $\infty$ & $\infty$\\
            \{u, x\} & 2, u & 4, x &  & 2, x & $\infty$\\
        \end{tabular}
    \end{center}

    \quad

    \begin{itemize}
        \item Proseguendo analogamente, le distanze finali calcolate saranno pari a:
    \end{itemize}

    \begin{center}
        \begin{tabular}{r|c|c|c|c|c}
            \textbf{R} & \textbf{D(v), p(v)} & \textbf{D(w), p(w)} & \textbf{D(x), p(x)} & \textbf{D(y), p(y)} & \textbf{D(z), p(z)}\\
            \hline
            \{u\} & 2, u & 5, u & 1, u & $\infty$ & $\infty$\\
            \{u, x\} & 2, u & 4, x &  & 2, x & $\infty$\\
            \{u, x, y\} & 2, u & 3, y &  &  & 4, y\\
            \{u, x, y, v\} &  & 3, y &  &  & 4, y\\
            \{u, x, y, v, w\} &  &  &  &  & 4, y\\
            \{u, x, y, v, w, z\} &  &  &  &  & \\
        \end{tabular}
    \end{center}

    \quad

    \begin{itemize}
        \item Una volta ottenute le distanze finali, verrà costruita la forwarding table di $u$:
        \begin{itemize}
            \item I nodi $v$ e $x$ sono direttamente raggiungibili da $u$ con distanza minima
            \item Il nodo $y$ è raggiungibile tramite $x$ con distanza minima
            \item I nodi $w$ e $z$ sono raggiungibili tramite $y$ con distanza minima, necessitando dunque di passare anche per $x$
        \end{itemize}
    
        \begin{center}
            \includegraphics[scale=0.5]{images/routing_2.png}
        \end{center}
        \begin{center}
            \begin{tabular}{c|c}
                \hline
                \multicolumn{2}{c}{\textbf{Forwading table di $u$}}\\
                \hline
                \textbf{Destinazione} & \textbf{Link di uscita}\\
                \hline
                $v$ & $(u,v)$\\
                $x$ & $(u,x)$\\
                $y$ & $(u,x)$\\
                $w$ & $(u,x)$\\
                $z$ & $(u,x)$\\
            \end{tabular}
        \end{center}
    \end{itemize}

    \quad

    L'algoritmo link-state ha una \textbf{complessità computazionale} pari a $O(n^2)$ (anche se è possibile implementarlo ottimamente in $O(n \log n)$) ed una \textbf{complessità di comunicazione} pari a $O(n^2)$, poiché ogni router deve trasmettere in broadcast il suo stato dei costi a tutti gli altri router (richiedendo $O(n)$ tramite algoritmi efficienti).
    
    Inoltre, poiché i costi dei link dipendono dal volume di traffico, può verificarsi un \textbf{caso patologico} per via delle \textbf{oscillazioni del percorso}, richiedendo di essere costantemente ricalcolati.

    \begin{center}
        \includegraphics[scale=0.4]{images/routing_3.png}
    \end{center}

    \quad

    \subsection{Algoritmo Distance-vector}

    L'\textbf{algoritmo distance-vector} è un algoritmo \textbf{dinamico decentralizzato} basato sulla \textbf{equazione di Bellman-Ford}.

    \begin{framedthm}{Equazione di Bellman-Ford}
        Dati $x,y \in V(G)$, sia $D_x(y)$ la \textbf{distanza minima da $y$ ad $x$}.
        
        In tal caso, si ha che:
        \[D_x(y) = \min_{v \in V(G)}[c_{x,v}+D_v(y)]\]
    \end{framedthm}

    Al verificarsi di un determinato \textbf{evento} (es: lo scadere di un timer), ogni nodo invia ai propri vicini la propria \textbf{stima del distance-vector}, o
    ssia un vettore contenente le distanze verso tutti i nodi della rete. Quando un nodo riceve una stima da parte di un vicino, utilizza tale stima per aggiornare il proprio distance-vector tramite l'\textbf{equazione di Bellman-Ford}. Sotto determinate condizioni ottimali, la distanza stimata \textbf{converge} dopo un determinato numero di interazioni alla \textbf{distanza minima}.

    Solitamente, l'aggiornamento locale del vettore di un nodo viene effettuato \underline{solo} a seguito dell'\textbf{aggiornamento} del costo di un \textbf{link diretto} da tale nodo verso un suo vicino o a seguito della \textbf{ricezione di un vettore aggiornato} inviato da un vicino (\textbf{Iterativo ed asincrono}). Inoltre, ogni nodo invia il proprio distance-vector ai vicini solo quando esso viene aggiornato (\textbf{Distribuito, self-stopping e responsive}).

    Dunque, l'algoritmo è riassumibile nei seguenti passi:
    \begin{enumerate}
        \item \textbf{Inizializzazione}: il DV di ogni nodo contiene il costo diretto verso tutti i suoi vicini e $\infty$ per ogni altro nodo
        \item \textbf{Attesa dell'evento}: ogni nodo attende il cambio di un costo diretto locale o la ricezione del vettore di un vicino
        \item \textbf{Ricalcolo del DV}: se l'evento viene attivato per un nodo, esso ricalcola il proprio DV utilizzando i valori precedenti e quelli ricevuti
        \item \textbf{Invio solo se modificato}: se al termine del calcolo il DV del nodo è stato aggiornato, esso viene inviato ai vicini del nodo
        \item Viene ripetuto il tutto in loop tornando al passo 2
    \end{enumerate}

    \textbf{Esempio:}

    \begin{itemize}
        \item Supponiamo che i router $a,c$ ed $e$ inviino il proprio DV al router $b$
        \begin{center}
            \includegraphics[scale=0.475]{images/dv_1.png}
        \end{center}

        \item Una volta ricevuti i vettori, il router $b$ ricalcola il proprio DV utilizzando l'equazione di Bellman-Ford
    \end{itemize}
    \begin{center}
        \includegraphics[scale=0.45]{images/dv_2.png}
    \end{center}

    \quad

    \begin{itemize}
        \item Successivamente, il nuovo DV  viene inviato ai vicini del router $b$
        
        \begin{center}
            \includegraphics[scale=0.375]{images/dv_3.png}
        \end{center}

        \newpage

        \item Una volta ricevuto il DV di $b$, il router $c$ (e anche i router $a$ ed $e$) procederà a ricalcolare il proprio DV utilizzando le nuove distanze ricevute
        
        \begin{center}
            \includegraphics[scale=0.45]{images/dv_4.png}
        \end{center}

        \quad

        \item Al passare degli istanti di tempo, i cambiamenti effettuati all'istante $t=0$ verranno propagati su tutti gli altri router della rete
        
        \begin{center}
            \includegraphics[scale=0.45]{images/dv_5.png}
        \end{center}
    \end{itemize}
    
    \newpage

    Come l'algoritmo link-state, anche l'algoritmo distance-vector è soggetto a \textbf{comportamenti patologici}, in particolare il \textbf{conteggio all'infinito}:
    
    \begin{enumerate}
        \item Data la seguente rete, supponiamo che il costo del link $(x,y)$ venga modificato da $4$ a $60$
        
        \begin{center}
            \includegraphics[scale=0.45]{images/dv_6.png}
        \end{center}

        \item Di conseguenza, il router $y$ nota il nuovo costo del collegamento diretto verso $x$ sia $60$. Tuttavia, il nodo $y$ ha precedentemente ricevuto il DV del router $z$, venendo a sapere che tramite $z$ sia possibile raggiungere $x$ con un costo pari a $6$, aggiornando quindi il proprio DV ed inviandolo ai suoi vicini
        \[D_y(x) = 4 \quad \xrightarrow{\text{diventa}} \quad D_y(x) = c_{y,z}+D_z(x) = 1+5 = 6\]
        
        (\textbf{Attenzione:} è necessario ricordare che l'algoritmo distance-vector è \underline{decentralizzato} dunque il vertice $y$ non sa che il percorso da $z$ a $x$ passi per $y$ stesso)

        \item Successivamente, il vertice $z$ riceverà il DV di $y$, notando che la distanza del percorso da $y$ a $x$ tramite cui $z$ possa raggiungere $x$ è stato modificato, aggiornando quindi il proprio DV ed inviandolo ai vicini
        \[D_z(x) = 5 \quad \xrightarrow{\text{diventa}} \quad D_z(x) = c_{z,y}+D_z(y) = 1+6 = 7\]

        \item Analogamente, $y$ riceverà il DV di $z$, ricadendo nella stessa casistica
        
        \[D_y(x) = 6 \quad \xrightarrow{\text{diventa}} \quad D_y(x) = c_{y,z}+D_z(x) = 1+7 = 8\]
        
        \item ...
    \end{enumerate}

    \quad
    
    \begin{framedprop}{Soluzioni al conteggio all'infinito}
        Per risolvere il comportamento patologico del \textbf{conteggio all'infinito}, l'algoritmo DV adotta due politiche aggiuntive:
        \begin{itemize}
            \item \textbf{Split horizon}, dove, invece che inviare l'intera tabella attraverso ogni interfaccia, ogni nodo invia solo una porzione della propria tabella a seconda dell'interfaccia (es: se il nodo $x$ riceve il DV del nodo $y$, nel DV di $x$ aggiornato inviato verso $y$ verranno omesse le informazioni ricevute da $y$)

            \item \textbf{Poisoned reverse}, dove, durante l'invio del proprio DV, il nodo mittente pone a $\infty$ la distanza dei percorsi passanti attraverso il vicino a cui sta inviando il nuovo DV (es: se il nodo $x$ deve inviare il suo DV al nodo $y$ e un percorso di $x$ verso un nodo $z$ passa per $y$, nel DV inviato viene posto $D_x(z) = \infty$)
        \end{itemize}
    \end{framedprop}

    A differenza dell'algoritmo link-state, l'algoritmo distance-vector possiede una \textbf{complessità di comunicazione} pari a $O(n)$. Per quanto riguarda la \textbf{velocità di convergenza}, invece, l'algoritmo LS necessita di $O(n^2)$ computazioni (a meno di oscillazioni) mentre l'algoritmo DV richiede condizioni troppo ottimali (l'instradamento potrebbe divenire ciclico).

    Inoltre, per propria natura stessa, l'algoritmo DV risulta essere \textbf{meno robusto}:
    \begin{itemize}
        \item Supponiamo che un router subisca un malfunzionamento o un attacco esterno, peggiorando notevolmente il costo dei propri link diretti
        \item Nell'algoritmo LS, tale router pubblicizzerà un \textbf{costo errato dei link diretti}. Tuttavia, poiché ogni router calcola solamente la propria tabella, gli altri router non verranno influenzati.
        \item Nell'algoritmo DV, invece, tale router pubblicizzerà un \textbf{costo errato dei percorsi} (\textbf{black-holing}). Di conseguenza, poiché ogni altro router userà il DV di tale router per i calcoli, l'errore verrà \textbf{propagato sull'intera rete}
    \end{itemize}

    \quad

    \section{Instradamento intra-AS e inter-AS}

    Gli algoritmi di routing precedentemente visti si basano su una \textit{concezione irrealistica} della rete, poiché viene assunto che tutti i router siano identici e che non vi sia alcuna gerarchia al suo interno, oltre all'evidente problema di scala dovuto alle miliardi di destinazioni che porterebbe ad intasare la rete con messaggi di scambio di forwarding table.

    \begin{framedprop}{Instradamento intra-AS e inter-AS}
        Per risolvere tali problematiche, i router vengono \textbf{aggregati} in regioni note come \textbf{autonomous systems (AS)} o \textbf{domini}. Ogni AS costituisce una rete composta da soli router.
        
        Distinguiamo quindi due tipologie di instradamento:
        \begin{itemize}
            \item \textbf{Instradamento intra-AS} ossia instradamento all'interno di un AS, dove tutti i router all'interno dell'AS devono eseguire lo stesso protocollo di instradamento intra-AS, implicando che router di diversi AS possano scegliere il proprio protocollo.
            \item \textbf{Instradamento inter-AS}, ossia instradamento tra diversi AS, dove ogni AS possiede un gateway router posto sul bordo e connesso ai gateway router degli altri AS (i gateway partecipano comunque all'instradamento intra-AS) 
        \end{itemize}
    \end{framedprop}


    Le \textbf{forwarding table}, dunque, verranno configurate sia da algoritmi di instradamento intra-dominio sia da algoritmi di instradamento inter-dominio.

    Di conseguenza, ogni router deve essere in grado di apprendere quali destinazioni siano raggiungibili tramite gli AS esterni e propagare tali informazioni all'interno del proprio AS.

    \quad

    \subsection{Protocolli RIP e OSPF}

    \quad

    \begin{frameddefn}{Protocollo RIP}
        Il \textbf{protocollo Routing Information Protocol (RIP)} è un protocollo di \textbf{instradamento intra-AS} basato sull'\textbf{algoritmo distance-vector}.        
        
        La metrica di costo utilizzata è la \textbf{distanza misurata in hop}, ossia il numero di router necessari da attraversare per raggiungere la destinazione. Il \textbf{valore massimo} per tale metrica è \textbf{15 hop} (il valore 16 corrisponde a $\infty$)
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.5]{images/rip_1.png}
    \end{center}

    Periodicamente, dunque dopo un \textbf{prefissato lasso di tempo}, ogni router utilizzante l'algoritmo RIP invierà il proprio distance-vector assieme ad alcune informazioni aggiuntive, fornendo agli altri router informazioni sugli host e le altre reti (ossia gli altri AS) raggiungibili.

    Se all'interno del DV di un router $x$ vi è un'entrata indicante la possibilità di raggiungere la rete $A$ con un costo pari a $N$ hop, ogni altro router all'\textbf{interno della rete} di $x$ saprà di poter raggiungere la rete $A$ con un costo pari a $N+1$ passando tramite $x$.

    Ogni messaggio può contenere \textbf{più voci}, ognuna di esse corrispondenti ad un'entrata del distance-vector del router mittente.

    \begin{center}
        \includegraphics[scale=0.5]{images/rip_2}
    \end{center}

    I messaggi di \textbf{RIP request} vengono inviati dai router al momento della loro immissione all'interno di un AS oppure a fini diagnostici (es: per richiedere una voce specifica).
    
    Per quanto riguarda i messaggi di \textbf{RIP response}, invece, essi vengono inviati in risposta ad un messaggio di richiesta (\textbf{solicited response}) o a seguito dello scadere di un timer di 25-35 secondi (\textbf{unsolicited response}). Oltre a tale timer periodico, vengono utilizzati due ulteriori timer:
    \begin{itemize}
        \item Un \textbf{timer di scadenza} (150-210 secondi), dove se allo scadere del tempo non è stato ricevuto alcun aggiornamento per un percorso, esso viene considerato come scaduto, venendo posto a 16 (dunque a $\infty$).
        
        Se un router non riceve messaggi da un suo vicino per circa 180 secondi (media tra 150 e 210), tale vicino viene considerato \textbf{spento o guasto}, impostando il costo di tale percorso a 16 e propagando l'informazione sugli altri nodi della rete. 
        \item Un \textbf{timer per il garbage collection} (120 secondi), dove se allo scadere del tempo il router continua ad annunciare un percorso con costo pari a 16, tale percorso viene completamente rimosso
    \end{itemize}

    Essendo basato sull'algoritmo distance-vector, il protocollo RIP presenta gli stessi comportamenti patologici, i quali vengono mediati utilizzando sia lo \textbf{split horizon} sia il \textbf{poisoned reverse}. Inoltre, quando viene ricevuta un'informazione da una rotta non più valida (dunque posta a 16), viene avviato un timer e tutti i messaggi arrivati prima del timeout e riguardanti tale rotta vengono ignorati (\textbf{hold-down})

    \begin{framedobs}{}
        Il \textbf{protocollo RIP} viene implementato tramite un processo a livello di applicazione chiamato \textbf{routed (route daemon)}, il quale utilizza \textbf{protocollo UDP} sulla \textbf{porta 520} per l'invio dei messaggi.

        Per tale motivo, seppur considerato un protocollo al livello di rete, sarebbe più corretto considerare il protocollo RIP come un protocollo a livello di applicazione.

        Tuttavia, è necessario sottolineare che l'utilizzo del protocollo UDP non sia necessario, bensì solo una comodità a livello di implementazione.
    \end{framedobs}

    \begin{center}
        \includegraphics[scale=0.5]{images/rip_3}
    \end{center}
    

    \begin{frameddefn}{Protocollo OSPF}
        Il \textbf{protocollo Open Shortest Path First (OSPF)} è un protocollo open-source di \textbf{instradamento intra-AS} basato sull'\textbf{algoritmo link-state}.

        Per gestire il costo dei singoli link, vengono utilizzate \textbf{più metriche possibili} (es: larghezza di banda, ritardo, ...). Inoltre, tutti i messaggi OSPF sono \textbf{autenticati} per prevenire intrusioni.
    \end{frameddefn}

    Il protocollo OSPF utilizza una \textbf{gerarchia a due livelli}, composta da una \textbf{backbone} e varie \textbf{local area}:
    \begin{itemize}
        \item Gli annunci link-state vengono propagati solo nella backbone o all'interno di un'area locale, riducendo la quantità di messaggi in base alla gerarchia
        \item Ogni nodo conosce, a seconda di dove si trova, la \textbf{topologia dettagliata} della propria area o del backbone, mentre conosce solo la \textbf{direzione} necessaria per raggiungere le altre destinazioni
        \item I router vengono distinti in quattro tipologie:
        \begin{itemize}
            \item \textbf{Backbone router}, situato all'interno del backbone, esegue la propagazione solo all'interno del backbone
            \item \textbf{Local router}, situato all'interno di un'area locale, esegue la propagazione solo all'interno dell'area stessa
            \item \textbf{Boundary router}, ossia il backbone router tramite cui l'intero AS si connette ad altri AS (gateway router)
            \item \textbf{Area border router}, situato sia nel backbone sia all'interno di un'area locale (punto di scambio), "riepiloga" le distanze verso le altre destinazioni nella propria area e le pubblicizza nel backbone 
        \end{itemize}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.55]{images/ospf.png}
    \end{center}

    \quad

    \subsection{Protocollo BGP}

    \quad

    \begin{frameddefn}{Protocollo BGP}
        Il \textbf{protocollo Border Gateway Protocol (BGP)} è un protocollo di \textbf{istradamento inter-AS} basato sull'algoritmo path-vector (non visto precedentemente).

        Consente ad un'AS di pubblicizzare alle altre AS la propria esistenza e le destinazioni che essa può raggiungere.

        Il protocollo BGP fornisce due tipologie di connettività ad ogni AS:
        \begin{itemize}
            \item \textbf{eBGP (external BGP)}, permettendo di ottenere informazioni sulla raggiungibilità di una sottorete tramite gli AS vicini
            \item \textbf{iBGP (internal BGP)}, permettendo di propagare tali informazioni sulla raggiungibilità a tutti i router interni all'AS
        \end{itemize}
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.45]{images/bgp_1.png}
    \end{center}

    All'interno di una \textbf{sessione BGP}, due router BGP (detti \textit{peer}) si scambiano messaggi BGP su una connessione TCP semipermanente, pubblicizzando i percorsi verso diversi prefissi di rete di destinazione.

    \textbf{Esempio:}

    \begin{itemize}
        \item Quando il gateway 3a di AS3 annuncia il percorso \texttt{AS3, X} al gateway 2c di AS2, l'AS3 \textit{promette} ad AS2 di inoltrare tutti i datagrammi diretti verso X
    \end{itemize}
        
    \begin{center}
        \includegraphics[scale=0.45]{images/bgp_2.png}
    \end{center}

    I messaggi BGP vengono scambiati tramite \textbf{connessioni TCP} e possono essere di quattro tipologie:
    \begin{itemize}
        \item \textbf{OPEN}, dove viene aperta una connessione TCP tra due peer BGP, autenticando prima il peer che apre la connessione
        \item \textbf{UPDATE}, dove viene pubblicizzato un nuovo percorso o ritirato uno precedente
        \item \textbf{KEEPALIVE}, dove viene richiesto di mantenere viva la connessione in assenza di messaggi UPDATE (viene utilizzato anche come ACK per il messaggio OPEN)
        \item \textbf{NOTIFICATION}, dove vengono segnalati errori nei messaggi precedenti (viene utilizzato anche per chiudere la sessione)
    \end{itemize}

    Per quanto riguarda i \textbf{percorsi BGP pubblicizzati}, essi sono composti da un prefisso ed una serie di attributi:
    \begin{itemize}
        \item Il \textbf{path prefix}, ossia la destinatazione che viene pubblicizzata dall'AS mittente (in formato \textit{ciderized})
        \item L'attributo \textbf{AS-PATH}, contenente l'elenco di AS attraverso cui è passato l'annuncio, utilizzato dall'AS destinatario come percorso per raggiungere l'AS mittente
        \item L'attributo \textbf{NEXT-HOP}, contenente l'indirizzo dell'hop successivo dell'AS destinatario per poter raggiungere il gateway, ossia l'\textbf{egress router}, (es: corrispondente al router 2c nell'esempio precedente)
    \end{itemize}

    Alla ricezione di un percorso pubblicizzato, il router destinatario sceglie se \textbf{accettare} o \textbf{rifiutare} il percorso in base ad una propria politica (\textbf{policy-based routing}). Ad esempio, una politica di routing potrebbe essere basata sul rifiutare qualsiasi percorso passante attraverso un determinato AS o un determinato paese (ulteriore utilizzo dell'attributo AS-PATH).
    
    Se un percorso viene accettato, esso viene \textbf{propagato} all'\textbf{interno dell'AS}, affinché i router interni ne siano a conoscenza, e verso le \textbf{altre AS raggiungibili}.

    \quad

    \textbf{Esempi:}
    \begin{enumerate}
        \item Consideriamo la seguente situazione:

        \begin{center}
            \includegraphics[scale=0.425]{images/bgp_3.png}
        \end{center}

        \begin{itemize}
            \item Il router 2c di AS2 riceve (tramite eBGP) l'annuncio del percorso \texttt{AS3, X} dal router 3a di AS3.
            
            \item Basandosi sulla propria politica, il router 2c accetta il percorso e lo propaga (tramite iBGP) all'interno del proprio AS
            
            \item Successivamente, basandosi sempre sulla propria politica, il router 2c annuncia (tramite eBGP) il percorso \texttt{AS2, AS3, X} al router 1c di AS1
        \end{itemize}

        \quad

        \item Consideriamo la seguente situazione:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/bgp_4.png}
        \end{center}

        \begin{itemize}
            \item Il router 1c di AS1 apprende il percorso \texttt{AS2, AS3, X} da parte del router 2a di AS2 e il percorso \texttt{AS3, X} da parte del router 3a di AS3
            \item Basandosi sulla propria politica, il router 1c decide di accettare il percorso \texttt{AS3, X} e rifiutare il percorso \texttt{AS2, AS3, X} (es: poiché necessita meno hop), propagando il percorso all'interno del suo AS
        \end{itemize}
        
        \newpage

        \item Consideriamo la seguente situazione:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/bgp_6.png}
        \end{center}

        \begin{itemize}
            \item Il router 2d di AS2 apprende (tramite iBGP) la possibilità di raggiungere il router X di AS3 sia tramite il router 2a sia tramite il router 2c (utilizzo dell'attributo NEXT-HOP)
            \item In tal caso, il router 2d sceglierà il gateway locale avente il minor costo intra-AS (\textbf{hot potato routing}) nonostante il percorso passante tramite 2c abbia un numero di hop inferiore, favorendo l'utilizzo di minor traffico all'interno di AS1 al prezzo di avere un minor controllo sul traffico esterno
        \end{itemize}
        
        \quad

        \item Consideriamo la seguente situazione:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/bgp_5.png}
        \end{center}

        \begin{itemize}
            \item L'AS dell'ISP A pubblicizza il percorso \texttt{A, w} agli AS degli ISP B e C
            \item Poiché l'ISP B non trae alcun vantaggio per l'instradamento \texttt{C, B, A, w} (poiché nè C, nè A e nè w sono clienti di B), decide di non pubblicizzare tale percorso verso C (policy basata sull'\textit{egoismo})
            \item Di conseguenza, l'ISP C apprenderà solo il percorso \texttt{C, A, w} ricevuto da A stesso
        \end{itemize}

        \item Consideriamo la seguente situazione:
        
        \begin{center}
            \includegraphics[scale=0.425]{images/bgp_7.png}
        \end{center}

        \begin{itemize}
            \item L'AS X è \textbf{dual-homed}, ossia connesso a due ISP
            \item Poiché B e C sono già direttamente connessi, per evitare il transito di traffico tra di essi passando attraverso l'AS x, quest'ultimo non pubblicizzerà il percorso \texttt{C, x, B} e il percorso \texttt{B, x, C} (policy basata sulla rimozione di intermediari tra ISP)
        \end{itemize}
    \end{enumerate}

    \begin{framedprop}{Scelta dei percorsi BGP}
        Se un router apprende più di un percorso verso la stessa destinazione, verrà selezionato il percorso in base a:
        \begin{itemize}
            \item Attributo del valore di preferenza locale
            \item AS-PATH più breve
            \item Percorso verso il NEXT-HOP con peso minore (\textbf{hot-potato routing})
            \item Criteri aggiuntivi dettati dalla policy 
        \end{itemize}
    \end{framedprop}

    \quad

    \section{Tipologie di instradamento}

    \subsection{Unicast e Broadcast}

    \quad

    \begin{frameddefn}{Unicast e Broadcast}
        Nell'ambito delle comunicazioni in rete, definiamo come:
        \begin{itemize}
            \item \textbf{Unicast} la comunicazione tra \textbf{una sorgente ed una destinazione}, solitamente effettuata tramite la coppia \texttt{<IP sorgente, IP destinazione>}
            \item \textbf{Broadcast} la comunicazione tra \textbf{una sorgente e tutti i nodi di una rete}, solitamente effettuata tramite la coppia \texttt{<IP sorgente, IP broadcast \\destinazione>} (es: come già discusso, l'IP speciale \texttt{255.255.255.255} effettua il broadcast sulla rete locale)
        \end{itemize}
    \end{frameddefn}

    Alla ricezione di un pacchetto broadcast da parte di un nodo, esso verrà \textbf{duplicato} ed inviato su tutti i nodi adiacenti al ricevente, fatta eccezione del nodo tramite cui è stato ricevuto il pacchetto. Tale tipologia di invio di messaggi viene detto \textbf{uncontrolled flooding} (tradotto \textit{inondazione incontrollata}).

    L'utilizzo dell'uncontrolled flooding può portare ad un \textbf{grave peggioramento della rete}, soprattutto nel caso in cui vi siano \textbf{cicli nel grafo}, portando il pacchetto broadcast ad essere duplicato ed inviato all'infinito.

    \begin{center}
        \begin{tabular}{ccc}
            \includegraphics[scale=0.44]{images/un_broad_1.png}
            &\qquad\qquad&
            \includegraphics[scale=0.44]{images/un_broad_2.png}
            \\
            \includegraphics[scale=0.44]{images/un_broad_3.png}
            &\qquad\qquad&
            \includegraphics[scale=0.44]{images/un_broad_4.png}
        \end{tabular}

        \includegraphics[scale=0.44]{images/un_broad_5.png}
    \end{center}

    \quad

    Di conseguenza, è necessario utilizzare una strategia di \textbf{controlled flooding} affinché si possa ridurre il traffico sulla rete:
    \begin{itemize}
        \item \textbf{Sequence number controlled flooding}, dove ogni nodo contiene una lista dei pacchetti già ricevuti, duplicati ed inviati, inoltrando il pacchetto broadcast ricevuto solo se non è già stato inviato
        \item \textbf{Reverse path forwarding (RPF)}, dove il pacchetto broadcast ricevuto viene inoltrato solo se è stato inoltrato dal link appartenente al \textbf{percorso più breve verso la sorgente} dell'invio
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.475]{images/rpf.png}
    \end{center}

    Nonostante le due strategie eliminino il problema di inondare la rete di pacchetti all'infinito, esse non eliminano completamente la trasmissione di pacchetti ridondanti, poiché essi verranno comunque inviati/ricevuti più volte prima di essere scartati.

    Per risolvere definitivamente la ridondanza dei pacchetti, viene utilizzato uno \textbf{spanning tree}, ossia un albero in cui ogni nodo può essere raggiunto da un solo link, propagando i pacchetti broadcast \textbf{solamente all'interno dell'albero stesso}.

    \begin{center}
        \begin{tabular}{ccc}
            \includegraphics[scale=0.35]{images/stree_1.png}
            &\qquad\qquad&
            \includegraphics[scale=0.35]{images/stree_2.png}
            \\
            \textit{Broadcast con sorgente A} && \textit{Broadcast con sorgente C}
        \end{tabular}
    \end{center}

    \quad

    Per creare lo spanning tree, viene scelto un \textbf{nodo radice} come centro della rete. Successivamente, ogni altro nodo invierà un messaggio di \textbf{join} in modalità unicast verso la radice. Tale messaggio viene propagato finché esso non arriva ad un nodo che già appartiene all'albero o finché non arriva alla radice. Una volta "toccato" l'albero, il percorso mancante verrà aggiunto allo spanning tree.

    \quad

    \subsection{Multicast}

    \begin{frameddefn}{Multicast}
        Nell'ambito delle comunicazioni in rete, definiamo come \textbf{multicast} la comunicazione tra \textbf{una sorgente e un gruppo di nodi della rete}
    \end{frameddefn}

    Molte applicazioni richiedono il trasferimento di pacchetti da uno o più mittenti verso un gruppo di destinatari (es: aggiornamento di un gruppo di macchine, streaming ad un gruppo di utenti, ...). Effettuare tali trasferimenti utilizzando dei \textbf{pacchetti unicast multipli} risulta essere \textbf{molto inefficiente} per via dell'aggiunta di ritardi nella rete.

    \begin{center}
        \includegraphics[scale=0.46]{images/m_unicast.png}
    \end{center}

    La soluzione più ottimale, dunque, risulta essere quella di trattare l'insieme di destinatari come un \textbf{gruppo multicast}, necessitando di un singolo pacchetto che verrà man mano sdoppiato per poter raggiungere tutte le destinazioni.

    \begin{center}
        \includegraphics[scale=0.47]{images/multicast.png}
    \end{center}
    
    Tuttavia, poiché il protocollo IP è in grado di gestire un singolo indirizzo IP di destinazione, è necessario identificare tutti i membri del gruppo attraverso un \textbf{indirizzo multicast} (aggiuntivo rispetto al normale indirizzo IP).

    In particolare, viene utilizzato un \textbf{blocco di indirizzi riservati} per il multicast. Per l'IPv4, ad esempio, il blocco di indirizzi da \texttt{224.0.0.0} a \texttt{239.255.255.255} ($2^{28}$ gruppi possibili). Dunque, qualsiasi \textbf{indirizzo IP secondario} "appartenente alla rete" \texttt{224.0.0.0/4} viene considerato come un indirizzo multicast valido (dunque qualsiasi indirizzo nel formato \texttt{1110-identificatore gruppo-})

    \begin{center}
        \includegraphics[scale=0.475]{images/multicast_2.png}
    \end{center}

    Dunque, l'appartenenza ad un gruppo multicast non ha alcuna relazione con il prefisso associato alla rete. Inoltre, l'appartenenza ad un gruppo è \textbf{variabile} (ad esempio il gruppo potrebbe avere un periodo di appartenenza limitato).

    Pertanto, un router deve essere in grado di venire a conoscenza di quali gruppi siano raggiungibili su ciascuna delle sue interfacce per poter propagare l'informazione.

    \begin{frameddefn}{Protocollo IGMP}
        Il \textbf{protocollo Internet Group Management Protocol (IGMP)} è un protocollo di comunicazione utilizzato per offrire agli host la possibilità di comunicare al proprio router direttamente connesso la volontà di \textbf{aderire} ad uno specifico \textbf{gruppo multicast}.

        I messaggi del protocollo IGMP (inviati con TTL pari a 1) si suddividono in:
        \begin{itemize}
            \item \textbf{Membership query}, inviato dal router agli host per determinare a quali gruppi multicast hanno aderito gli host (inviati periodicamente)
            \item \textbf{Membership request}, inviato da un host al router per informarlo dell'adesione ad un gruppo multicast
            \item \textbf{Leave group}, inviato da un host al router per informarlo dell'abbandono di un gruppo multicast
        \end{itemize}
    \end{frameddefn}

    Ogni router multicast mantiene una \textbf{lista} per ciascuna sottorete di gruppi multicast (a patto che almeno un elemento del gruppo faccia parte della sottorete) impostando un \textbf{timer} per ogni \textbf{membership}. Se la membership non viene aggiornata (da reqeust o leave) prima dello scadere del tempo, essa viene rimossa dalla lista.

    Fra la popolazione complessiva di router, solo alcuni di essi, in particolare quelli collegati agli host del gruppo multicast, si occuperanno del traffico multicast (\textbf{multicast router}). Di conseguenza, è necessario un protocollo che coordini i vari router multicast per instradare il traffico multicast all'interno di Internet.

    Per realizzare ciò, viene mantenuto un \textbf{albero} che colleghi i vari router multicast, instradando il traffico multicast solamente all'interno dell'albero stesso. Un albero può essere unico per tutto il gruppo o diverso a seconda della sorgente.

    I principali protocolli per l'instradamento multicast sono:
    \begin{itemize}
        \item \textbf{Instradamento multicast intra-AS}:
        
        \begin{itemize}
            \item Distance-vector multicast routing protocol (DVMRP)
            \item Multicast open shortest path first (MOSPF)
            \item Protocol independent multicast (PIM)
        \end{itemize}
        \item \textbf{Instradamento multicast inter-AS}:
        
        \begin{itemize}
            \item Multicast border gateway protocol (MBGP)
        \end{itemize}
    \end{itemize}

    \quad

    \section{Software Defined Networking (SDN)}

    Come precedentemente trattato, il livello di rete è stato storicamente implementato tramite un approccio di controllo distribuito sui router:
    \begin{itemize}
        \item Un \textbf{router monolitico} contiene hardware di commutazione, esegue implementazioni proprietarie dei protocolli standard Internet (es: IP, RIP, OSPF, BGP, ...) su sistemi operativi proprietari (es: Cisco IOS, ...)
        \item Diversi \textbf{middleboxes} per diverse funzionalità aggiuntive del livello di rete: firewall, load balancing, NAT, ...
    \end{itemize}

    A differenza di un piano di controllo basato sull'approccio distribuito tra i vari router, dunque, il \textbf{Software Defined Networking (SDN)} permette l'implementazione di un \textbf{singolo piano di controllo} tramite un controller remoto che calcola e poi installa le tabelle di inoltro tramite le \textbf{API OpenFlow}, permettendo una gestione della rete più semplice,evitando errori di configurazione dei router e permettendo una \textbf{maggiore flessibilità dei flussi di traffico}.

    \begin{center}
        \includegraphics[scale=0.4]{images/sdn_0.png}
    \end{center}

    \textbf{Esempi:}

    \begin{enumerate}
        \item \begin{itemize}
            \item L'ISP vuole far si che il traffico dal router $u$ verso il router $z$ scorra sul percorso $u,v,w,z$ anziché sul percorso $u,x,y,z$.
        
            \begin{center}
                \includegraphics[scale=0.44]{images/sdn_1.png}
            \end{center}
    
            \item Per ottenere ciò, utilizzando il normale approccio distribuito, sarebbe necessario ridefinire i pesi dei collegamenti in modo che l'algoritmo di instradamento del traffico calcoli il percorso desiderato.
            
            \item Alternativamente, sarebbe necessario realizzare un nuovo algoritmo di routing.
        \end{itemize}

        \item \begin{itemize}
            \item L'ISP vuole far si che il traffico dal router $u$ verso il router $z$ venga bilanciato (\textbf{load balancing}) sui percorsi $u,v,w,z$ e $u,x,y,z$.
        
            \begin{center}
                \includegraphics[scale=0.44]{images/sdn_2.png}
            \end{center}
    
            \item Utilizzando il normale approccio distribuito, ciò sarebbe impossibile se non tramite un nuovo algoritmo di routing.
        \end{itemize}
        
        \item \begin{itemize}
            \item Il router $w$ vuole instradare il traffico blu verso il router $z$ e il traffico rosso verso il router $z$ tramite due percorsi diversi
        
            \begin{center}
                \includegraphics[scale=0.44]{images/sdn_3.png}
            \end{center}
    
            \item Utilizzando il normale approccio distribuito, ciò sarebbe impossibile se non tramite una tipologia di forwarding diversa dal destination-based forwarding e un nuovo algoritmo di routing.
        \end{itemize}
    \end{enumerate}
    
    Tramite l'uso di un SDN, inoltre, il forwarding  può essere realizzato tramite \textbf{switch di rete} veloci e semplici (al posto di normali router più complessi), i quali  implementano il \textbf{generalized forwarding} all'interno del data plane, dove la \textbf{forwarding table} degli switch viene calcolata e installata sotto la supervisione del controller SDN tramite le API OpenFlow e un protocollo per la comunicazione con il controller.
    
    Per quanto riguarda le \textbf{applicazioni di controllo della rete} presenti all'interno del control plane, invece, esse implementano funzioni di controllo utilizzando i servizi di livello inferiore (ossia le API fornite dal controller SDN). Possono essere fornite da un fornitore distinto rispetto a quello degli switch e del controller SDN.

    \begin{center}
        \begin{tabular}{m{0.5 \textwidth} m{0.5 \textwidth}}
            Il \textbf{controller SDN} viene gestito da un sistema operativo di rete, mantenendo informazioni sullo stato della rete e interagendo con gli altri livelli attraverso delle API:
    
            \begin{itemize}
                \item \textbf{API Northbound}, utilizzate per  interagire con le applicazioni di controllo della rete presenti nel control plane
                \item \textbf{API Southbound}, utilizzate per interagire con gli switch di rete all'interno del data plane tramite le \textbf{API Southbound}
            \end{itemize}
            
            \quad

            Per evitare la presenza di un \textbf{single point of failure}, ossia un dispositivo il cui malfunzionamento porterebbe al malfunzionamento dell'intera rete, i controller SDN vengono implementati come \textbf{sistema distribuito}
            
            &
            
            \includegraphics[scale=0.34]{images/sdn_4.png}
        \end{tabular}

        \includegraphics[scale=0.5]{images/sdn_5.png}
    \end{center}

    \begin{frameddefn}{Protocollo OpenFlow}
        Il \textbf{protocollo OpenFlow} è un protocollo di comunicazione utilizzato per la comunicazione tra controller SDN e switch di rete attraverso il \textbf{protocollo TCP} (con crittografia opzionale).

        \textit{\textbf{Attenzione:}} il protocollo OpenFlow è \textbf{diverso} dalle API OpenFlow, nonostante quest'ultime vengano utilizzate dal protocollo stesso.
    \end{frameddefn}

    I messaggi del protocollo OpenFlow si suddividono in tre categorie:
    \begin{itemize}
        \item \textbf{Controller-to-switch}:
        \begin{itemize}
            \item Messaggi di \textbf{feature}, ossia una query del controller per conoscere le funzionalità supportate dallo switch
            \item Messaggi di \textbf{configure}, dove il controller modifica parametri di configurazione dello switch
            \item Messaggi di \textbf{modify-state}, dove vengono utilizzate le API OpenFlow per aggiungere, eliminare o modificare campi della forwarding table dello switch
            \item Messaggi di \textbf{packet-out}, dove il controller invia un pacchetto da una specifica porta dello switch
        \end{itemize}

        \newpage

        \item \textbf{Asincroni (Switch-to-controller)}:
        \begin{itemize}
            \item Messaggi di \textbf{packet-in}, dove viene trasferito un pacchetto al controller
            \item Messaggi di \textbf{flow-removed}, dove lo switch elimina una riga della forwarding table e notifica il controller
            \item Messaggi di \textbf{port-status}, dove lo switch informa il controller della modifica o problematica su una porta
        \end{itemize}

        \item \textbf{Simmetrici (C-to-S \& S-to-C)}
        
        \begin{itemize}
            \item Messaggi di hello, messaggi echo, messaggi di errore, ...
        \end{itemize}
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/openflow_2.png}
    \end{center}

    \quad

    \textbf{Esempio di interazione piano dati/controllo:}

    \begin{enumerate}
        \item All'interno dello switch di rete S1 si verifica un errore sul collegamento verso lo switch di rete S2. Di conseguenza, lo switch S1 invia un messaggio OpenFlow di port-status per informare il controller
        \item Il controller SDN riceve il messaggio OpenFlow, aggiornando le informazioni sullo stato del collegamento
        \item L'applicazione di controllo della rete inerente al calcolo dei percorsi tramite l'algoritmo link-state di Dijkstra viene richiamata
        \item L'applicazione accede alle informazioni sul grafo di rete e alle informazioni sullo stato dei collegamenti, calcolando i nuovi percorsi
        \item L'applicazione di routing interagisce con il componente di calcolo delle forwarding table presente all'interno del controller SDN, calcolando le nuove forwarding table degli switch di rete necessarie
        \item Il controller utilizza il protocollo OpenFlow e le API OpenFlow per installare le nuove tabelle negli switch che devono essere aggiornati
    \end{enumerate}

    \begin{center}
        \includegraphics[scale=0.55]{images/sdn_6.png}
    \end{center}

    \quad

    Per via della sua complessità di gestione, l'utilizzo dei controller SDN è attualmente confinato ai singoli AS, venendo quindi utilizzati come "\textbf{sostituto}" del normale \textbf{routing intra-AS tradizionale}. Gli obiettivi futuri, dunque, prevedono una maggiore scalabilità tramite la sostituzione anche del routing inter-AS, nonché una maggior robustezza ai guasti ed una maggior affidabilità/sicurezza (versioni aggiornate di OpenFlow usano l'autenticazione).

    \quad

    \section{Amministrazione della rete}

    L'\textbf{amministrazione della rete} prevede la gestione dei vari AS distribuiti all'interno di Internet attraverso quattro componenti fondamentali:
    \begin{itemize}
        \item \textbf{Managing server}, ossia un server tipicamente gestito da amministratori della rete
        \item \textbf{Managed device}, ossia un qualsiasi dispositivo della rete con componenti hardware o software configurabili
        \item \textbf{Dati} (es: dati di configurazione dello stato dei dispositivi, dati operativi, statistiche dei dispositivi, ...)
        \item \textbf{Protocollo di network management}, utilizzato dal managing server per interrogare, configurare e gestire i managed device e utilizzato da quest'ultimi per inviare dati o eventi rilevati al server
    \end{itemize}
    
    \begin{frameddefn}{Management Information Base (MIB)}
    Un \textbf{Management Information Base (MIB)} è un database presente all'interno di un managed device memorizzante dati sullo stato e la configurazione del dispositivo stesso attraverso il linguaggio \textbf{Structure of Management Information (SMI)}
    \end{frameddefn}
    
    \begin{center}
        \includegraphics[scale=0.4]{images/mib_udp.png}

        \textit{Esempio di variabili MIB per il protocollo UDP}
    \end{center}

    \quad

    \begin{frameddefn}{Protocollo SNMP}
        Il \textbf{protocollo Simple Network Management Protocol (SNMP)} è un protocollo di gestione della rete utilizzato per interrogare/impostare i dati presenti nei MIB dei dispositivi. Viene implementato tramite il \textbf{protocollo UDP} sulla porta nota 161.
    \end{frameddefn}
    
    \begin{center}
        \includegraphics[scale=0.35]{images/snmp_1.png}
    \end{center}

    I messaggi del protocollo SNMP si differenziano in \textbf{messaggi request/response}, dove il server invia una richiesta al dispositivo e quest'ultimo risponde, e \textbf{messaggi trap}, dove il dispositivo informa il server a seguito di un eccezione.
    
    \begin{center}
        \includegraphics[scale=0.45]{images/snmp_2.png}
    \end{center}

    \quad
    
    \begin{frameddefn}{Protocollo NETCONF}
        Il \textbf{protocollo Network Configuration Protocol (NETCONF)} è un protocollo di gestione della rete utilizzato per gestire/configurare \textbf{attivamente} i dispositivi a livello di rete.

        Il protocollo NETCONF sul \textbf{paradigma di remote procedure call (RPC)}, inviando messaggi NETCONF codificati in linguaggio XML attraverso un protocollo di trasporto sicuro (es: tramite TLS).

        Inoltre, il protocollo NETCONF è in grado di recuperare, modificare, interrogare e attivare configurazioni sui managed devices attraverso dei \textbf{commit atomici} su più dispositivi (ossia un singolo commit in grado di modificare simultaneamente tutti i dispositivi)
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.35]{images/netconf_2.png}
    \end{center}

    \newpage

    \textbf{Esempio:}
    \begin{center}
        \includegraphics[scale=0.45]{images/netconf_3.png}
    \end{center}

    \quad

    Per facilitare la scrittura di messaggi NETCONF RPC, viene utilizzato il \textbf{linguaggio di modellazione YANG}. In particolare, ogni documento XML descrivente il dispositivo e le sue funzionalità può essere generato a partire da una descrizione YANG, esprimendo anche vincoli tra dati che devono essere soddisfatti da una configurazione NETCONF valida.

    \begin{center}
        \includegraphics[scale=0.5]{images/netconf_4.png}
    \end{center}
    
    \newpage

    \chapter{Livello di collegamento}

    Abbiamo visto come il livello di rete si occupi della comunicazione logica tra dispositivi. Per quanto riguarda il \textbf{livello di collegamento}, invece, esso si occupa direttamente del \textbf{trasferimento dei datagrammi} tra due dispositivi fisicamente adiacenti lungo un link, ossia un qualsiasi canale di comunicazione tra i due nodi stessi (cablato o non).

    In particolare, il trasferimento di datagrammi tra più dispositivi \textbf{non richiede} strettamente \textbf{l'uso dello stesso protocollo}. Ad esempio, due dispositivi A e B potrebbero essere collegati da un cavo Ethernet, mentre il dispositivo B potrebbe essere collegato ad un dispositivo C tramite Wi-Fi.

    Ogni protocollo di collegamento fornisce servizi diversi, tra cui:
    \begin{itemize}
        \item \textbf{Framing}, dove il datagramma viene incapsulato in un frame aggiungendo un header ed un trailer
        \item \textbf{Link access}, dove viene fornito accesso al canale di trasmissione tramite un mezzo condiviso. Gli \textbf{indirizzi MAC} nell'header dei frame identificano origine e destinazione (diversi dagli indirizzi IP)
        \item \textbf{Consegna affidabile tra nodi adiacenti}, in modo simile alla consegna affidabile dei dati già vista precedentemente per il livello di trasporto
        \item \textbf{Controllo del flusso}, evitando il sovraccarico dei buffer del nodo di destinazione
        \item \textbf{Rilevamento degli errori}, causati da attenuazione del segnale o da rumore presenti nel mezzo di trasmissione. Alla rilevazione di un errore, il ricevitore può richiedere la trasmissione o scartare direttamente il frame. 
        \item \textbf{Correzione degli errori}, dove il ricevente identifica e corregge automaticamente errori presenti nei bit, senza richiedere la ritrasmissione.
        \item \textbf{Half duplex e Full duplex}, dove con il termine half duplex viene intesa una \textbf{trasmissione bidirezionale ma non contemporanea}, mentre con il termine full duplex viene intesa una \textbf{trasmissione bidirezionale e contemporanea}
    \end{itemize}

    \newpage

    Il livello di collegamento viene implementato in \textbf{ogni singolo dispositivo} attraverso una \textbf{scheda di interfaccia di rete (Network Interface Card - NIC)}, o anche attraverso un semplice chip di rete. La NIC è direttamente collegata ai bus di sistema del dispositivo ed è gestita da una combinazione tra hardware, software e firmware.
    
    Durante una trasmissione, il dispositivo mittente incapsula il datagramma nel frame ed allega ad esso dei \textbf{bit aggiuntivi} utilizzati per i \textbf{servizi} del livello di collegamento (dunque controllo degli errori, trasferimento affidabile, ...), per spedire il frame stesso tramite la propria NIC. Una volta che la NIC del destinatario riceverà il frame, verranno effettuati i controlli necessari (dunque sempre controllo degli errori, trasferimento affidabile, ...) per poi decapsulare il frame estraendo il datagramma e passandolo al livello superiore.

    \begin{center}
        \includegraphics[scale=0.45]{images/nic_2.png}
    \end{center}

    In modo simile al livello di rete, anche il livello di collegamento è diviso in \textbf{due sotto-livelli}:
    \begin{itemize}
        \item Il \textbf{Data Link Control (DLC)} si occupa di tutte le questioni condivise sia dai \textbf{collegamenti point-to-point}, dunque dedicati a due dispositivi, sia da quelli \textbf{broadcast}, dunque condivisi tra più dispositivi.
        
        In particolare, il DLC si occupa di servizi come il framing, il controllo del flusso, il rilevamento di errori e la loro correzione.

        \item Il \textbf{Media Access Control (MAC)} si occupa solo degli aspetti specifici dei \textbf{canali broadcast}, in particolare del controllo dell'accesso al mezzo condiviso
    \end{itemize}

    \newpage

    \section{Rilevamento e correzione degli errori}

    Gli errori presenti nei frame spediti sono dovuti a interferenze che possano cambiare la forma del segnale. La probabilità che avvenga un errore di tipo \textbf{burst (a raffica, ossia in sequenza)} è più elevata rispetto a quella di un singolo errore, in quanto la durata dell'inferenza (detta anche rumore) normalmente è più lunga rispetto alla trasmissione di un singolo bit.

    \begin{center}
        \includegraphics[scale=0.45]{images/burst_error.png}
    \end{center}

    Pertanto, il \textbf{numero di bit coinvolti} nell'errore dipende dalla \textbf{velocità di trasferimento} dei dati e dalla \textbf{durata del rumore} (es: un rate pari a 1 Kb/s con un rumore di 0.01 s può influire su 10 bit).

    Per rilevare errori nella trasmissione vengono utilizzati dei bit di \textbf{error detection and correction (EDC bits)}, i quali vengono allegati ai dati protetti dal controllo (possono includere anche i campi stessi dell'header). Nonostante sia molto raro che non vengano correttamente rilevati gli errori, è necessario sottolineare che tale procedura non è affidabile al 100\%. In particolare, maggiore sarà il numero di EDC bits utilizzati maggiore sarà la capacità di rilevare e correggere l'errore.

    Il primo metodo utilizzato per la rilevazione degli errori è il \textbf{parity checking}:
    \begin{itemize}
        \item Viene utilizzato un singolo EDC detto \textbf{parity bit}, il quale verrà impostato in modo che il \textbf{numero totale di bit impostati ad 1} (incluso il parity bit stesso) sia \textbf{pari} 
        \item Di conseguenza, se il numero di bit impostati ad 1 all'interno del campo dati è dispari, il parity bit verrà impostato ad 1
        \item Viceversa, se il numero di bit impostati ad 1 all'interno del campo dati è pari, il parity bit verrà impostato ad 0
        \item Una volta giunto a \textbf{destinazione}, viene calcolato nuovamente il valore che deve essere assunto dal parity bit. Se tale valore \textbf{non coincide} con il parity bit inserito nel campo EDC, verrà rilevato un errore
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/parity_bit.png}
    \end{center}

    Tuttavia, è necessario sottolineare che tale protocollo permetta solo di \textbf{rilevare un singolo errore} all'interno della trasmissione senza sapere quale sia il bit effettivamente errato, rendendo \textbf{impossibile} la \textbf{correzione automatica} dell'errore.

    Una strategia più avanzata prevede l'uso di \textbf{parity bit bidimensionali}:
    \begin{itemize}
        \item I bit del campo data vengono disposti in una tabella $m \times n$
        \item Per ognuna delle $m$ righe ed ognuna delle $n$ colonne viene calcolato il parity bit
        \item Viene calcolato un parity bit (posto in basso a destra) per tutti gli $m \times n$ bit del dato originale (dunque esclusi gli $m+n$ parity bit appena calcolati)
    \end{itemize} 

    \begin{center}
        \includegraphics[scale=0.475]{images/parity_bit_2.png}
    \end{center}

    In questo modo, gli $m \times n$ bit di parità vengono utilizzati per \textbf{rilevare e correggere i singoli errori}, mentre il parity bit finale calcolato viene utilizzato per assicurarsi che nessuno di tali parity bit sia errato.
    
    \begin{center}
        \includegraphics[scale=0.35]{images/parity_bit_3.png}
    \end{center}
    
    Nonostante la sua buona efficacia vista la sua semplicità, il parity checking con parity bit bidimensionali risulta essere comunque soggetto a molti \textbf{errori di rilevazione} (es: possono verificarsi situazioni in cui vi sono più bit errati ma il conteggio di parità risulta essere comunque corretto).

    Una codifica di rilevamento degli errori (dunque non correzione) più complessa ma di maggior efficacia è il \textbf{Cyclic Redundancy Check (CRC)}, ampiamente utilizzato nella pratica (es: Ethernet, Wi-Fi 802.11):
    \begin{enumerate}
        \item I bit di dati vengono trattati come un numero binario, indicato come $D$
        \item Viene scelto un valore $r$, corrispondente al numero di bit da utilizzare per il campo CRC del frame 
        \item Viene scelto un valore $G$, detto \textbf{generator}, costituito da $r+1$ bit. Il generatore da utilizzare viene scelto dai due endpoint tra una serie di generatori standard, dunque entrambi ne sono a conoscenza.
        \item Il valore assunto dal campo CRC corrisponde ad un \textbf{valore $R$} di $r$ bit. Posto $\text{<D,R>} := (D \cdot 2^r) \oplus R$, il valore $R$ deve essere tale che \textbf{<D,R> sia esattamente divisibile per $G$ in modulo 2}, dunque tale che
        \[\frac{\text{<D,R> }}{G} \equiv 0 \;(\text{mod }2) \iff \frac{(D \cdot 2^r) \oplus R}{G} \equiv 0 \;(\text{mod }2) \iff \]
        \[\iff \exists n \in \mathbb{Z} \mid (D \cdot 2^r) \oplus R \equiv nG \;(\text{mod }2)\]

        \item A questo punto, è necessario sottolineare che nell'algebra modulo 2 (diversa dall'algebra binaria), le operazioni di somma, sottrazione e XOR siano \textbf{algebricamente equivalenti}. Tale dettaglio è di \underline{cruciale importanza}, poiché altrimenti calcolando la divisione in algebra binaria si otterrebbe un \underline{risultato sbagliato}.

        \item Dunque, il valore $R$ corrisponde al \textbf{resto della divisione in modulo 2 di $\frac{D \cdot 2^r}{G}$}.
        \[R \equiv \frac{D \cdot 2^r}{G} \;(\text{mod }2)\]
        
        Inoltre, ricordiamo che $D \cdot 2^r$ equivale ad effettuare su $D$ uno \textbf{shift sinistro di $r$ bit}.

        \item Pertanto, notiamo che i bit del valore <D,R> corrispondono sempre ai bit del valore $D$ a cui vengono accodati i bit del valore $R$. Tale proprietà nasce direttamente dal fatto stesso che <D,R> $=(D \cdot 2^r) \oplus R$, motivo per cui all'interno dei frame il valore CRC venga accodato al campo dati
        
        \item Una volta ricevuto il frame, il destinatario utilizzerà il valore <D,R> ricevuto per verificare se $\frac{\text{<D,R> }}{G} \equiv 0 \;(\text{mod }2)$. Se il resto ottenuto è diverso da 0, verrà rilevato l'errore. In particolare, possono essere rilevati tutti gli errori burst inferiori a $r+1$ bit
    \end{enumerate}

    \quad

    \textbf{Esempio:}
    \begin{itemize}
        \item Vogliamo utilizzare un CRC a 3 bit utilizzando il generatore $G = 1001_2$
        \item Dato $D = 101110_2$ (dunque $D \cdot 2^3 = 101110000_2$), calcoliamo $\frac{D \cdot 2^3}{G}$ in modulo 2 (ricordiamo che in tale modulo lo XOR e la sottrazione sono equivalenti)
        \begin{center}
            \begin{tabular}{c|c}
                \begin{tabular}{cccccccccc}
                      & 1 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\
                    $\oplus$ & 1 & 0 & 0 & 1 &   &   &   &   &  \\
                    \hline
                      &   &   & 1 & 0 & 1 & 0 &   &   &  \\
                      &   & $\oplus$ & 1 & 0 & 0 & 1 &   &   &  \\
                    \hline
                      &   &   &   &   &  1 & 1 & 0 & 0  &  \\
                      &   &   &   & $\oplus$ & 1 & 0 & 0 & 1  &  \\
                    \hline
                      &   &   &   &   &   & 1 & 0 & 1 & 0 \\
                      &   &   &   &   & $\oplus$ & 1 & 0 & 0 & 1 \\
                    \hline
                      &   &   &   &   &   &  &  & 1 & 1\\
                \end{tabular}
                &
                \begin{tabular}{cccccc}
                    1 & 0 & 0 & 1 &   &  \\
                    \hline
                    1 & 0 & 1 & 0 & 1 & 1\\
                    \\\\\\\\\\\\\\
                \end{tabular}
            \end{tabular}
        \end{center}
        
        \quad

        implicando che $R = 011_2$ e dunque che <D,R> $= 101110011_2$ (notare che esso corrisponde all'accodamento del valore $R$ al valore $D$)
    \end{itemize}

    \newpage

    \section{Collegamenti e protocolli MAC}

    Come accennato nella panoramica del livello di collegamento, principalmente vi sono due tipologie di collegamento:
    \begin{itemize}
        \item Collegamento \textbf{point-to-point}, ossia dedicati solo a due dispositivi (es: un cavo Ethernet moderno)
        \item Collegamento \textbf{broadcast}, ossia tramite mezzo condiviso tra dispositivi (es: un cavo condiviso, una radio condivisa, ...)
    \end{itemize}

    Nel caso dei collegamenti broadcast, possono verificarsi \textbf{due o più trasmissioni simultanee} da parte dei nodi, creando \textbf{interferenza} e \textbf{collisioni} nel caso in cui un nodo riceva due o più segnali contemporaneamente.

    Di conseguenza, è necessario utilizzare dei \textbf{protocolli di accesso multiplo}, dunque inerenti al sotto-livello \textbf{Media Access Control (MAC)} accennato precedentemente, ossia algoritmi distribuiti in grado di determinare come i nodi condividono un mezzo di trasmissione, dettando quando ogni nodo possa trasmettere.

    Inoltre, è necessario sottolineare che lo \textbf{scambio di messaggi} relativo al protocollo MAC utilizzato debba \textbf{utilizzare il canale stesso}. Pertanto, dato un canale di accesso multiplo di velocità $R$ b/s, vogliamo (idealmente) che:
    \begin{itemize}
        \item Qualora un nodo voglia trasmettere, esso deve poter trasmettere alla velocità $R$ b/s
        \item Qualora \textbf{$M$ nodi} vogliono trasmettere, ognuno di essi può trasmettere ad una \textbf{velocità media} pari a $\frac{R}{M}$ b/s
        \item Il protocollo deve essere \textbf{decentralizzato}, dunque non deve esserci alcun nodo speciale che coordini la trasmissione e non deve esserci alcuna sincronizzazione di orologi o slot temporali
    \end{itemize}

    \quad

    \subsection{Protocolli MAC a partizionamento del canale}

    La prima macrocategoria di protocolli MAC è composta dai protocolli basati sul \textbf{partizionamento dei canali}, dove il canale viene suddiviso in più parti, allocando ognuna di esse ad un nodo per uso esclusivo:
    \begin{itemize}
        \item \textbf{Time Division Multiple Access (TDMA)}, basato sullo stesso principio del Time Division Multiplexing (TDM) visto nel capitolo 1, dove l'accesso al canale viene effettuato in "round": ogni stazione ottiene uno \textbf{slot di tempo di accesso al canale} fisso in ogni round e ogni slot inutilizzato diventa inattivo
        \begin{center}
            \includegraphics[scale=0.5]{images/tdma.png}

            \textit{LAN a 6 stazioni dove le stazioni 1, 3 e 4 devono inviare \\pacchetti mentre gli slot 2, 5 e 6 sono inattivi}
        \end{center}

        \item \textbf{Frequency Division Multiple Access (FDMA)}, basato sullo stesso principio del Frequency Division Multiplexing (FDM) visto nel capitolo 1, dove lo spettro del canale è suddiviso in bande di frequenza, ciascuna assegnata ad una stazione in modo fisso. Il tempo di trasmissione inutilizzato nelle bande di frequenza diventa inattivo.
        
        \begin{center}
            \includegraphics[scale=0.4]{images/fdma.png}

            \textit{Esempio analogo al precedente ma utilizzando il FDMA invece del TDMA}
        \end{center}

        \quad

        \item \textbf{Code Division Multiple Access (CDMA)}, dove un solo canale occupa l'intera ampiezza di banda e tutte le stazioni possono inviare contemporaneamente (assenza di suddivisione di frequenze e di tempo), utilizzando dei codici personali per effettuare la comunicazione.
        

        I codici scelti all'interno del \textbf{CDMA} si basano sulle \textbf{sequenze ortogonali}, dove ad ogni stazione viene assegnato un codice, corrispondente ad una sequenza di numeri, detti \textbf{chip}.
    \end{itemize}

    \begin{framedprop}{Proprietà delle sequenze ortogonali}
        Le \textbf{sequenze ortogonali} sono basate sull'ortogonalità tra vettori dell'algebra lineare, godendo delle seguenti proprietà:
        \begin{itemize}
            \item Ogni codice è una sequenza composta da $N$ elementi (dove $N$ è il numero di stazioni ed è una potenza di 2)
            \item \textbf{Sommare/moltiplicare due sequenze} significa sommare/moltiplicare l'$i$-esimo elemento della prima sequenza con l'$i$-esimo elemento della seconda sequenza
            \item Tra due sequenze può essere effettuato il \textbf{prodotto scalare}, equivalente a moltiplicare le due sequenze e sommare gli $N$ valori ottenuti
            \item Moltiplicando una sequenza per un \textbf{numero}, ogni elemento della sequenza viene moltiplicato per tale numero
            \item Effettuando il \textbf{prodotto scalare} tra due sequenze \textbf{uguali} il risultato sarà esattamente $N$, mentre se esse sono \textbf{diverse} il risultato sarà esattamente $0$
        \end{itemize}

        Se all'interno della rete CDMA una sola delle seguenti proprietà non viene rispettata, le sequenze ortogonali associate ai dispositivi sono \textbf{incorrette}.
    \end{framedprop}
    
    \newpage

    \textbf{Esempio:}

    \begin{itemize}
        \item Consideriamo le seguenti sequenze ortogonali:
        \begin{itemize}
            \item $c_1 = [+1, +1, +1, +1]$
            \item $c_2 = [+1, -1, +1, -1]$
            \item $c_3 = [+1, +1, -1, -1]$
            \item $c_4 = [+1, -1, -1, +1]$
        \end{itemize}
        \item Verifichiamo se si tratti di sequenze ortogonali valide (verificando quindi le ultime due proprietà):
        
        \begin{itemize}
            \item Moltiplicazione sequenze uguali e somma dei valori:
            \begin{itemize}
                \item $c_1 \cdot c_1 = [+1, +1, +1, +1] \cdot [+1, +1, +1, +1] = [+1, +1, +1, +1] \\\implies 1+1+1+1 = 4$
                \item $c_2 \cdot c_2 = [+1, -1, +1, -1] \cdot [+1, -1, +1, -1] = [+1, +1, +1, +1] \\\implies 1+1+1+1 = 4$ 
                \item $c_3 \cdot c_3 = [+1, +1, -1, -1] \cdot [+1, +1, -1, -1] = [+1, +1, +1, +1] \\\implies 1+1+1+1 = 4$ 
                \item $c_4 \cdot c_4 = [+1, -1, -1, +1] \cdot [+1, -1, -1, +1] = [+1, +1, +1, +1] \\\implies 1+1+1+1 = 4$ 
            \end{itemize}

            \item Moltiplicazione sequenze diverse e somma dei valori:
            \begin{itemize}
                \item $c_1 \cdot c_2 = [+1, +1, +1, +1] \cdot [+1, -1, +1, -1] = [+1, -1, +1, -1] \\\implies 1-1+1-1 = 0$
                \item $c_1 \cdot c_3 = [+1, +1, +1, +1] \cdot [+1, +1, -1, -1] = [+1, +1, -1, -1] \\\implies 1+1-1-1 = 0$
                \item $c_1 \cdot c_4 = [+1, +1, +1, +1] \cdot [+1, -1, -1, +1] = [+1, -1, -1, +1] \\\implies 1-1-1+1 = 0$
                \item $c_2 \cdot c_3 = [+1, -1, +1, -1] \cdot [+1, +1, -1, -1] = [+1, -1, -1, +1] \\\implies 1-1-1+1 = 0$
                \item $c_2 \cdot c_4 = [+1, -1, +1, -1] \cdot [+1, -1, -1, +1] = [+1, +1, -1, -1] \\\implies 1+1-1-1 = 0$
                \item $c_3 \cdot c_4 = [+1, +1, -1, -1] \cdot [+1, -1, -1, +1] = [+1, -1, +1, -1] \\\implies 1-1+1-1 = 0$
            \end{itemize}
        \end{itemize}

        \item Le quattro sequenze sono ortogonali tra loro, implicando che possano essere utilizzate per il CDMA tra quattro stazioni
    \end{itemize}

    \quad

    Tramite l'utilizzo delle \textbf{sequenze ortogonali}, prima di ogni tramissione ogni stazione \textbf{moltiplica} i propri dati per il proprio codice. In tal modo, i dati sul canale corrisponderanno alla \textbf{somma di tali risultati}.

    \begin{center}
        \includegraphics[scale=0.37]{images/cdma_1.png}
    \end{center}

    Qualsiasi stazione voglia ricevere dati da una delle altre stazioni, \textbf{moltiplica} i dati ricevuti per il codice del mittente e divide per il numero di \textbf{stazioni}, ottenendo così i dati originali.
    \[\text{Dati della Staz. 1} = \frac{(d_1 \cdot c_1 + d_2 \cdot c_2 + d_3 \cdot c_3 + d_4 \cdot c_4) \cdot c_1}{4} = \]
    \[=\frac{d_1 \cdot c_1 \cdot c_1 + d_2 \cdot c_2 \cdot c_1 + d_3 \cdot c_3 \cdot c_1 + d_4 \cdot c_4 \cdot c_1}{4} = \]
    \[= \frac{d_1 \cdot 4 + d_2 \cdot 0 + d_3 \cdot 0 + d_4 \cdot 0}{4} = \frac{d_1 \cdot 4}{4} = d_1\]

    Al fine di poter applicare tale calcolo, dunque, è necessario \textbf{codificare i dati} sottoforma di sequenza di $N$ elementi:
    \begin{itemize}
        \item Se il dato $d$ ottenuto dal calcolo è $-1$, tale dato verrà interpretato come un \textbf{bit uguale a 0}
        \item Se il dato $d$ ottenuto dal calcolo è $+1$, tale dato verrà interpretato come un \textbf{bit uguale a 1}
        \item Se il dato $d$ ottenuto dal calcolo è $0$, tale dato verrà interpretato come \textbf{silenzio}
    \end{itemize} 

    \quad

    \textbf{Esempio:}

    \begin{itemize}
        \item Consideriamo le quattro stazioni aventi le seguenti sequenze ortogonali viste precedentemente:
        
        \begin{itemize}
            \item $c_1 = [+1, +1, +1, +1]$
            \item $c_2 = [+1, -1, +1, -1]$
            \item $c_3 = [+1, +1, -1, -1]$
            \item $c_4 = [+1, -1, -1, +1]$
        \end{itemize}

        \item Supponiamo che la sequenza presente sul canale, corrispondente alla somma dei prodotti scalari effettuati, sia $D = [-1, -1, -3, +1]$

        \item Il bit inviato dalla stazione S2 corrisponderà a:
        \[\frac{D \cdot c_2}{4} = \frac{[-1, -1, -3, +1] \cdot [+1, -1, +1, -1]}{4} = \frac{-4}{4} = -1 \implies \text{Bit}_{S2} \; = 0\]

        \begin{center}
            \includegraphics[scale=0.45]{images/cdma_2.png}
        \end{center}
    \end{itemize}

    \quad

    Per \textbf{generare sequenze di chip} viene utilizzata una \textbf{matrice di Walsh}, ossia una matrice $2^n \times 2^n$ per $n \in \mathbb{N}$ e dove le entrate sono solo -1 o +1:
    \begin{itemize}
        \item Ogni riga della matrice è una sequenza di chip
        \item La matrice $W_1$ di dimensione $1 \times 1$ è una sequenza di un chip solo e può assumere (a scelta) il valore +1 o -1
        \[W_1 = (\pm 1)\]
        \item Dato un $N$ qualsiasi, la matrice $W_{2N}$ di dimensione $2N \times 2N$ viene calcolata tramite la matrice $W_N$:
        \[W_{2N} = \left ( \begin{array}{cc}
        W_N & W_N\\
        W_N & \overline{W_N}
        \end{array}\right )\]
        dove $\overline{W_N}$ è la matrice complementare di $W_N$ (ossia avente valori di segno inverito)
    \end{itemize}

    \quad

    \textbf{Esempio:}

    \begin{itemize}
        \item Scelto $W_1 = (+1)$, la matrice $W_2$ corrisponderà a:
        \[W_2 = \left ( \begin{array}{cc}
            W_1 & W_1 \\
            W_1 & \overline{W_1}
        \end{array}\right ) =
        \left ( \begin{array}{cc}
            +1 & +1 \\
            +1 & -1
        \end{array}\right )\]
        \item Una volta ottenuta $W_2$, la matrice $W_4$ corrisponderà a:
        \[W_4 = \left ( \begin{array}{cc}
            W_2 & W_2 \\
            W_2 & \overline{W_2}
        \end{array}\right ) =
        \left ( \begin{array}{cccc}
            +1 & +1 & +1 & +1\\
            +1 & -1 & +1 & -1\\
            +1 & +1 & -1 & -1\\
            +1 & -1 & -1 & +1\\
        \end{array}\right )\]
        \item Le sequenze ortogonali $c_1, c_2, c_3$ e $c_4$ per 4 stazioni saranno quindi date dalle righe della matrice $W_4$
    \end{itemize}

    \newpage

    \subsection{Protocolli MAC ad accesso casuale}

    La seconda magrocategoria di protocolli MAC è composta dai protocolli basati sull'\textbf{accesso casuale}, dove nel momento in cui un nodo deve inviare un pacchetto esso viene direttamente inviato alla massima velocità di trasmissione $R$ del link, per poi \textbf{rilevare e recuperare da eventuali collisioni}, ossia trasmissioni simultanee nel canale.

    \begin{frameddefn}{Protocollo Slotted ALOHA}
        Il \textbf{protocollo Slotted ALOHA} è un protocollo MAC ad accesso casuale, dove:
        \begin{itemize}
            \item Viene \textbf{assunto} che:
            \begin{itemize}
                \item Tutti i \textbf{frame} abbiano la \textbf{stessa dimensione}
                \item Il \textbf{tempo} è diviso in \textbf{slot di uguali dimensioni}, ognuno pari a $T_{fr}$ ossia il \textbf{tempo impiegato per trasmettere un frame}
                \item I nodi iniziano a trasmettere solo all'\textbf{inizio dello slot}. Inoltre, essi sono \textbf{sincronizzati} e, nel caso in cui due o più nodi trasmettono nello stesso slot di tempo, tutti i nodi rilevano la \textbf{collisione}
            \end{itemize}
    
            \item Quando un nodo ottiene un nuovo frame, esso viene trasmesso nello \textbf{slot di tempo successivo}.
            \item Se non viene rilevata alcuna collisione, il nodo può inviare un nuovo frame nello slot successivo
            \item Se invece viene rilevata una collisione, il nodo tenta di ritrasmettere il frame a ogni slot successivo con \textbf{probabilità $p$} (dunque in modo casuale), fermandosi nel caso in cui la ritrasmissione avvenga
        \end{itemize}
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.4]{images/slotted_aloha.png}
    \end{center}

    \textbf{Pro dello Slotted ALOHA:}
    \begin{itemize}
        \item Se un singolo nodo è attivo, esso può trasmettere continuamente alla massima velocità del canale
        \item Solo gli slot dei nodi devono essere sincronizzati (alta decentralizzazione)
    \end{itemize}

    \textbf{Contro dello Slotted ALOHA:}
    \begin{itemize}
        \item Presenza di collisioni, spreco di slot generale e presenza di slot inattivi a seguito di una collisione
        \item Sincronizzazione degli orologi dei nodi
        \item I nodi potrebbero essere in grado di rilevare la collisione in un tempo minore di uno slot di tempo
    \end{itemize}

    Per quanto riguarda l'\textbf{efficienza}, ossia la frazione a lungo termine di slot trasmessi con successo (assumendo molti nodi e molti frame), del protocollo Slotted ALOHA può essere stimata a livello probabilistico:
    \begin{itemize}
        \item Assumiamo $N$ nodi con molti frame da inviare, ognuno trasmette in slot con probabilità $p$
        \item La probabilità che un dato nodo abbia successo in uno slot è $p(1-p)^{N-1}$
        \item La probabilità che tutti i nodi abbiano successo è $Np(1-p)^{N-1}$
        \item Dunque, per $N$ nodi la massima efficienza è sarà data dal valore $p^*$ in grado di massimizzare $Np^*(1-p^*)^{N-1}$ (spesso tale valore massimizzante è $p^* \approx \frac{1}{N}$)
        \item Per molti nodi (dunque per $N \to +\infty$) l'efficienza massima sarà:
        \[\lim_{N \to +\infty} Np^*(1-p^*)^{N-1} \approx \lim_{N \to +\infty} N \frac{1}{N}(1-\frac{1}{N})^{N-1} = \lim_{N \to +\infty} (1-\frac{1}{N})^{N-1} = \frac{1}{e} \approx 0.37\]

        \item Dunque, il canale viene utilizzato per trasmissioni utili circa il $37\%$ delle volte
    \end{itemize}

    \begin{frameddefn}{Protocollo Pure ALOHA}
        Il \textbf{protocollo Pure ALOHA} è una variante del protocollo Slotted ALOHA dove:
        \begin{itemize}
            \item Il tempo non è suddiviso in slot. Pertanto, non vi è alcuna sincronizzazione.
            \item Quando un frame arriva, esso viene trasmesso direttamente.
            \item Il resto rimane invariato rispetto al protocollo Slotted ALOHA
        \end{itemize}
    \end{frameddefn}

    Per via dell'assenza di sincronizzazione, la probabilità di collisione risulta maggiore. Ad esempio, il frame inviato al tempo $t_0$ andrà in collisione con i frame inviati nell'intervallo temporale $[t_0-1, t_0+1]$ (\textbf{tempo di vulnerabilità} pari a $2 \cdot T_{fr}$)

    \begin{center}
        \includegraphics[scale=0.45]{images/pure_aloha.png}
    \end{center}
    
    Pertanto l'efficienza del Pure ALOHA, ossia circa $18\%$ di trasmissioni utili, risulta essere inferiore rispetto all'efficienza dello Slotted ALOHA.

    \begin{frameddefn}{Protocollo CSMA}
        Il \textbf{protocollo Carrier Sense Multiple Access (CSMA)} è un protocollo MAC ad accesso casuale dove:
        \begin{itemize}
            \item Prima di trasmettere, ogni nodo \textbf{ascolta il canale} (\textbf{Carrier Sense})
            \item Se il canale viene rilevato come \textbf{inattivo}, viene trasmesso l'intero frame
            \item Se il canale viene rilevato come \textbf{attivo}, la trasmissione viene ritardata
        \end{itemize}
    \end{frameddefn}

    Nonostante l'invio solo in caso di inattività del canale, all'interno del protocollo CSMA possono ancora verificarsi delle \textbf{collisioni}. Ad esempio, per via del ritardo di propagazione due nodi potrebbero entrambi rilevare il canale come libero in contemporanea, avviando entrambi la trasmissione.
    
    In particolare, dunque, la distanza dei nodi e il ritardo di propagazione giocano un ruolo nel determinare la probabilità di collisione, portando il \textbf{tempo di vulnerabilità} ad essere pari a $D_{p}$ (propagation delay). Inoltre, nel caso di collisione il tempo di trasmissione dell'intero pacchetto viene \textbf{sprecato}.

    \begin{frameddefn}{Protocollo CSMA/CD}
        Il \textbf{protocollo Carrier Sense Multiple Access with Collision Detection} \\\textbf{(CSMA/CD)} è una variante del protocollo CSMA:
        \begin{itemize}
            \item \textbf{Collision Detection}: viene rilevata una collisione se una stazione trasmittente riceve un bit da parte di un'altra stazione, \textbf{interrompendo immediatamente} la trasmissione, inviando un \textbf{segnale di jam} (ossia di avvenuta collisione) ed entrando in una fase di \textbf{back-off}, ossia l'attesa di un determinato quantitativo di tempo prima di riprendere ad ascoltare
            \item Il resto rimane inviariato rispetto al protocollo CSMA (incluso il \textbf{tempo di vulnerabilità})
        \end{itemize}
    \end{frameddefn}


    \begin{center}
        \begin{tabular}{ccc}
            \textbf{Collisione in CSMA} && \textbf{Collisione in CSMA/CD}\\

            \begin{tabular}{c}
                \includegraphics[scale=0.575]{images/csma.png}
            \end{tabular}
            &\qquad\qquad&
            \begin{tabular}{c}
                \includegraphics[scale=0.575]{images/csma_cd.png}
            \end{tabular}
        \end{tabular}
    \end{center}

    \quad

    Una volta che una stazione A invia completamente un frame, essa \textbf{non controlla il mezzo trasmissivo} per rilevare eventuali collisioni con una stazione B. Affinché il Collision Detection funzioni, dunque, la stazione A deve poter \textbf{star ancora trasmettendo} al momento in cui riceverà il segnale di jam inviato dalla stazione B, poiché altrimenti A non sarebbe in grado di rilevare la collisione avvenuta. 

    Per tale motivo, il \textbf{tempo di trasmissione di un frame} deve essere \textbf{almeno due volte il delay di propagazione} (tempo massimo di andata e ritorno tra A e B), dunque $T_{fr} \geq 2 \cdot D_p$, affinchè un nodo possa rilevare tutte le possibili collisioni.
    
    Di conseguenza, per ottenere tale tempo di trasmissione minimo, la \textbf{dimensione di un frame} deve essere pari a:
    \[\text{Dim. frame } = R_t \cdot T_{fr} \geq R_t \cdot 2 \cdot D_p\]
    dove $R_t$ è il rate di trasmissione

    \textbf{Esempio:}
    \begin{itemize}
        \item Una rete che utilizza il CSMA/CD è composta da link cablati con un rate pari a 10 Mb/s. Se il delay di propagazione è 25.6 $\mu s$, la dimensione minima del frame corrisponde a:
        \[\text{Dim. frame } = R_t \cdot T_{fr} \geq R_t \cdot 2 \cdot D_p = 2 \cdot 10 \;\text{Mb/s} \cdot 25.6 \;\mu s = 512 \; b = 64 \; B\]
    \end{itemize}

    Il protocollo CSMA/CD può essere implementato secondo più \textbf{politiche di gestione dell'ascolto del canale}:
    \begin{itemize}
        \item \textbf{Non persistente}:
        \begin{itemize}
            \item Se il canale è libero, la trasmissione avviene subito
            \item Se il canale è occupato, viene atteso un tempo random per poi riascoltare il canale (Carrier Sense ad intervalli)
            \item Se si verifica una collisione la trasmissione viene interrotta, entrando in back-off
        \end{itemize}

        \begin{center}
            \includegraphics[scale=0.4]{images/non_pers.png}
        \end{center}

        \item \textbf{1-persistente}:
        \begin{itemize}
            \item Se il canale è libero, la trasmissione avviene subito
            \item Se il canale è occupato, l'ascolto del canale è continuo  (Carrier Sense continuo)
            \item Se si verifica una collisione la trasmissione viene interrotta, entrando in back-off
        \end{itemize}

        \begin{center}
            \includegraphics[scale=0.4]{images/1_pers.png}
        \end{center}

        \item \textbf{P-persistente (slottizzato)}:
        \begin{itemize}
            \item Se il canale è libero, la trasmissione avviene con probabilità $p$ o viene atteso l'inizio del prossimo slot di tempo con probabilità $1-p$
            \item Se il canale è occupato, viene atteso l'inizio del prossimo slot di tempo
            \item Se si verifica una collisione la trasmissione viene interrotta, entrando in back-off
        \end{itemize}

        \begin{center}
            \includegraphics[scale=0.475]{images/p_pers.png}
        \end{center}
    \end{itemize}

    \quad

    Il protocollo CSMA/CD viene implementato dal \textbf{protocollo Ethernet} tramite il seguente \textbf{algoritmo Ethernet CSMA/CD}:
    \begin{enumerate}
        \item La NIC di un dispositivo riceve un datagramma dal livello di rete e crea il frame
        \item La NIC ascolta il canale: se è inattivo la trasmissione viene avviata, altrimenti viene atteso che il canale sia libero (politica \textbf{1-persistente})
        \item Se durante la trasmissione la NIC rileva un'altra trasmissione in arrivo, la NIC interrompe la trasmissione e invia un \textbf{segnale di jam} (48 bit) per avvisare tutte le altre NIC della collisione
        \item Dopo l'interruzione, la NIC entra in stato di \textbf{back-off esponenziale} dove, dopo l'$n$-esima collisione di fila, la NIC sceglie un valore $K$ casuale tra $\{0, 1, 2, \ldots, 2^{n}-1\}$ attendendo $K$ \textbf{slot di tempo} (uno slot equivale al tempo per trasmettere 512 bit).
    \end{enumerate} 

    Infine, per quanto riguarda l'\textbf{efficienza} del protocollo CSMA/CD, si ha che:
    \[\text{Eff} = \frac{1}{1+\frac{5 \cdot D_p}{D_t}}\]

    Pertanto, l'efficienza massima, ossia pari a 1, viene raggiunta quando $D_p \to 0$ o quando  $D_t \to +\infty$. In condizioni ragionevoli, invece, l'efficienza media risulta essere $0.5$, implicando che il canale venga utilizzato per trasmissioni utili circa il $50\%$ delle volte.

    \subsection{Protocollo MAC a rotazione}

    La terza macrocategoria di protocolli MAC è composta dai protocolli basati sulla \textbf{rotazione}, dove si cerca di ottenere una via intermedia tra le altre due macrocategorie (la prima è efficiente con carico elevato e poco efficiente con basso carico, mentre la seconda è efficiente con basso carico e poco efficiente con molto carico).

    Le due principali tipologie di protocolli appartenenti a tale categoria sono:
    \begin{itemize}
        \item \textbf{Polling}, dove un nodo master "invita" a turno gli altri nodi a trasmettere (se un nodo non ha nulla da trasmettere si passa direttamente al prossimo). Viene tipicamente utilizzato con dispositivi semplici (dumb devices).

        \item \textbf{Token passing}, dove un token di controllo viene passato da un nodo all'altro in sequenza e dove ogni nodo può trasmettere solo se possiede il token.
    \end{itemize}

    \begin{center}
        \begin{tabular}{ccc}
            \textbf{Polling} && \textbf{Token passing}\\

            \begin{tabular}{c}
                \includegraphics[scale=0.4]{images/polling.png}
            \end{tabular}
            &\qquad\qquad&
            \begin{tabular}{c}
                \includegraphics[scale=0.4]{images/token passing.png}
            \end{tabular}
        \end{tabular}
    \end{center}

    Entrambe le tipologie presentano una \textbf{latenza di accesso} (nel primo dovuto all'attesa dell'invito e nel secondo all'attesa del token) ed un \textbf{single point of failure} (l'intero blocco del canale è dovuto nel primo ad un malfunzionamento del master e nel secondo a seguito della possibile perdita del token )

    \quad

    \section{Indirizzamento locale (indirizzo MAC)}

    Abbiamo visto come l'\textbf{indirizzo IP} venga utilizzato come indirizzo dell'interfaccia del livello di rete per effettuare il forwarding. 
    
    L'\textbf{indirizzo MAC} (anche detto indirizzo LAN, fisico o Ethernet), è un indirizzo \textbf{utilizzato localmente} (dunque \underline{solamente all'interno della stessa sottorete locale}) per inviare frame da una NIC ad un'altra NIC \textbf{fisicamente connessa ad essa}.

    Ogni indirizzo MAC è composto da \textbf{48 bit} ed è direttamente \textbf{hardcoded nella NIC}, rendendolo pertanto \textbf{globalmente univoco} (a differenza di IP che è solo localmente univoco). All'interno della stessa LAN, dunque, ogni interfaccia possiede:
    \begin{itemize}
        \item Indirizzo MAC globalmente univoco, paragonabile al codice fiscale dell'interfaccia
        \item Indirizzo IP localmente univoco, paragonabile all'indirizzo postale dell'interfaccia
    \end{itemize}

    rendendo un'interfaccia spostabile da una LAN all'altra.

    Per rappresentare gli indirizzi MAC viene utilizzata una \textbf{notazione esadecimale} composta da 12 caratteri in base 16 separati due a due da un trattino, dove ogni carattere rappresenta 4 bit dell'indirizzo (es: \texttt{1A-2F-BB-76-09-AD}).

    L'allocazione degli indirizzi MAC è gestita dalla IEEE, dove \textbf{ogni azienda produttrice di NIC} acquista un \textbf{Organizational Unique Identifier (OUI)} interno ai primi 12 bit più significativi, acquistando così uno spazio privato di indirizzi MAC al fine di garantire l'unicità.

    \textbf{\textit{Chiarimento}}: ci si potrebbe chiedere se non sia già sufficiente l'indirizzo IP per poter identificare un'interfaccia all'interno della stessa LAN, rendendo superfluo l'indirizzo MAC. Di seguito, vengono elencati alcuni motivi per cui sia \textbf{necessario} utilizzare un indirizzo MAC:
    
    \begin{itemize}
        \item Per struttura stessa dello stack protocollare TCP/IP, il livello di rete e di collegamento sono \textbf{completamente isolati}. Pertanto, il livello di collegamento non ha la minima idea di cosa sia un indirizzo IP
        \item La \textbf{stessa NIC potrebbe essere associata a più indirizzi IP} nel caso in cui essa appartenga a più reti (es: i gateway router che si interpongono come punto di scambio tra due reti). Pertanto, lavorare con più indirizzi può risultare complesso, mentre l'\textbf{unicità assoluta} dell'indirizzo MAC rende il tutto più semplice
        \item L'indirizzo IP spesso è ottenuto \textbf{dinamicamente} tramite il protocollo DHCP. Prima di ottenere tale indirizzo, dunque, gli altri dispositivi della LAN non potrebbero identificare il dispositivo che ha effettuato la richiesta al server DHCP. Inoltre, essendo dinamico, un host potrebbe cambiare il proprio indirizzo IP anche all'interno della stessa LAN (es: a seguito della disconnessione e riconnessione)
        
        \item Le \textbf{forwarding table} di un nodo servono solo a tener traccia del \textbf{flusso di rete}, permettendo ad un dispositivo di sapere su quale porta inviare il pacchetto, mentre l'indirizzo MAC permette di sapere quale dispositivo sia connesso a tale porta.
    \end{itemize}

    \quad

    \subsection{Protocollo ARP}

    \quad

    \begin{frameddefn}{Protocollo ARP}
        Il \textbf{protocollo Address Resolution Protocol (ARP)} è un protocollo di risoluzione degli indirizzi in grado di determinare l'indirizzo MAC di un'interfaccia richiesta tramite il suo indirizzo IP.

        Ogni nodo appartenente alla LAN possiede una propria \textbf{tabella ARP}, formata da mappature nel formato \texttt{< Indirizzo IP, Indirizzo MAC, TTL >}. Allo scadere del TTL (solitamente 20 minuti), una mappatura viene rimossa dalla tabella.
    \end{frameddefn}

    \begin{center}
        \includegraphics[scale=0.5]{images/arp_1.png}
    \end{center}

    All'interno del pacchetto ARP, il campo \textbf{hardware type} indica il protocollo di collegamento utilizzato, mentre il campo \textbf{protocol type} viene utilizzato per il demultiplexing con il livello di rete.

    \begin{center}
        \includegraphics[scale=0.65]{images/arp_5.png}
    \end{center}

    Per acquisire gli indirizzi MAC dei dispositivi connessi alla rete, un dispositivo effettua una \textbf{query ARP broadcast} utilizzando l'indirizzo MAC di destinazione \texttt{FF-FF-FF-FF-FF-FF}, in modo che il frame arrivi a tutti i dispositivi della LAN. Una volta ricevuta la query, il dispositivo il cui indirizzo IP coincide con l'indirizzo IP di destinazione  presente nella query risponderà con il proprio indirizzo MAC.

    \newpage

    \textbf{Esempio:}

    \begin{itemize}
        \item L'host A vuole inviare un datagramma all'host B. Tuttavia, l'indirizzo MAC dell'host B non è nella tabella ARP dell'host A. L'host A trasmette quindi in broadcast una query ARP contenente l'indirizzo IP dell'host B.

        \begin{center}
            \includegraphics[scale=0.26]{images/arp_2.png}
        \end{center}

        \item Una volta ricevuta la query, l'host B invierà una risposta ARP, fornendo il proprio indirizzo MAC
        
        \begin{center}
            \includegraphics[scale=0.26]{images/arp_3.png}
        \end{center}

        \item Una volta ricevuta la risposta, l'host A aggiungerà un'entrata relativa all'IP e al MAC dell'host B nella sua tabella ARP
        
        \begin{center}
            \includegraphics[scale=0.36]{images/arp_4.png}
        \end{center}
    \end{itemize}

    \subsection{Instradamento verso un'altra sottorete}

    Poiché l'indirizzo MAC è utilizzato solo per l'indirizzamento locale, per poter inviare un pacchetto tra due host in due sottoreti diverse è necessario passare per uno o più (a seconda della gerarchia della rete) router di scambio, \textbf{cambiando continuamente l'indirizzo MAC sorgente di destinazione}.
    
    \textbf{Esempio:}

    \begin{enumerate}
        \item L'host A vuole inviare un datagramma verso l'host B appartenente ad un'altra LAN
        
        \begin{center}
            \includegraphics[scale=0.45]{images/mac_1.png}
        \end{center}
        
        \item Tramite la sua \textbf{forwarding table}, l'host A sà di poter raggiungere l'host B passando per il router R.
        
        \item Diamo quindi già per \textbf{assunto} che:
        \begin{itemize}
            \item L'host A conosca l'indirizzo IP dell'host B
            \item L'host A conosca l'indirizzo IP del router R, precedentemente ottenuto tramite DHCP in quanto R è il gateway della sua rete
            \item L'host A conosca l'indirizzo MAC del router R, precedentemente ottenuto tramite query ARP 
        \end{itemize}
        \item Di conseguenza, l'host A crea il \textbf{datagramma} con indirizzo IP sorgente \texttt{111.111.111.\\111} (il suo indirizzo IP) ed indirizzo IP di destinazione \texttt{222.222.222.222} (l'indirizzo IP dell'host B), per poi successivamente, creare un \textbf{frame} contenente il datagramma precedentemente creato, utilizzando \texttt{74-29-9C-EB-FF-55} come indirizzo MAC sorgente (il suo indirizzo MAC) e \texttt{1A-23-F9-CD-06-9B} come indirizzo MAC di destinazione (l'indirizzo MAC del router R), per poi inviarlo
        
        \begin{center}
            \includegraphics[scale=0.45]{images/mac_2.png}
        \end{center}

        \item Una volta ricevuto il frame, il router R \textbf{estrarrà} il datagramma dal frame, inviandolo al livello di rete. Una volta letto l'indirizzo IP di destinazione nell'header del datagramma, il router R determinerà tramite la sua \textbf{forwarding table} l'interfaccia di uscita per poter raggiungere l'host B.
        
        \item Successivamente, il router R creerà un nuovo \textbf{frame} contenente il datagramma ricevuto dall'host A, utilizzando \texttt{1A-23-F9-CD-06-9B} come indirizzo MAC sorgente (il suo indirizzo MAC) e \texttt{49-BD-D2-C7-56-2A} come indirizzo MAC di destinazione (l'indirizzo MAC dell'host B), per poi inviarlo
        
        \begin{center}
            \includegraphics[scale=0.45]{images/mac_3.png}
        \end{center}

        \item Una volta che l'host B avrà ricevuto il frame, esso verrà decapsulato estraendo il datagramma. Una volta letto l'indirizzo IP di destinazione nell'header del datagramma, l'host B noterà che esso coincide con il proprio indirizzo IP, inviando quindi il datagramma al proprio livello di trasporto.
    \end{enumerate}

    \newpage

    \section{LAN cablate}

    \subsection{Standard Ethernet}

    Lo \textbf{standard Ethernet} (o meglio, la famiglia di standard Ethernet) è la principale tecnologia cablata utilizzata all'interno delle LAN. Fino alla metà degli anni '90, veniva utilizzato un \textbf{bus condiviso} (es: un cavo coassiale condiviso) per lo scambio di frame, portando tutti i nodi ad essere in half-duplex e all'interno dello stesso dominio di collisione.
    
    In alternativa al bus condiviso, poteva essere utilizzato anche un \textbf{hub}, ossia un dispositivo di comunicazione \textbf{non intelligente}: se un hub riceve un frame, tale frame viene inviato a tutti i dispositivi connessi all'hub (dunque non effettuando alcuna commutazione), fatta eccezione del mittente (ottenendo dunque lo stesso effetto di un bus condiviso).

    In tempi moderni, invece, vengono utilizzati degli \textbf{switch} all'interno della rete, dove ogni "ramo" dello switch esegue un \textbf{protocollo Ethernet} separato dagli altri rami. In tal modo, i nodi non entrano in collisione tra loro e sono tutti potenzialmente full-duplex.

    \begin{center}
        \includegraphics[scale=0.35]{images/ethernet_1.png}
    \end{center}

    La struttura del frame Ethernet è composta da:
    \begin{itemize}
        \item \textbf{Campo preamble}, utilizzato per la sincronizzazione delle frequenze di clock del mittente e del destinatario. Composto da 7 byte di 10101010 seguiti da un byte 10101011
        \item \textbf{Campi addresses}, formati da 6 byte per l'indirizzo MAC del mittente e 6 byte per l'indirizzo MAC del destinatario. Se l'adattatore Ethernet (ossia una NIC compatibile) riceve un frame con indirizzo MAC di destinazione corrispondente al proprio o all'indirizzo di broadcast, il frame viene passato al protocollo di livello di rete. In caso contrario, il frame viene scartato.
        \item \textbf{Campo type}, utilizzato per il demultiplexing con il livello di rete (principalmente IP, ma anche altri possibili) 
        \item \textbf{Campo data}, avente una lunghezza minima di 64 byte (viene aggiunto del padding se necessario) e una lunghezza massima pari al MTU impostato
        \item \textbf{Campo CRC}, utilizzato per il controllo CRC
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.475]{images/ethernet_2.png}
    \end{center}

    \newpage

    In particolare, lo standard Ethernet non richiede alcun hanshaking tra le NIC dei dispositivi comunicanti (\textbf{connectionless}), rendendo tutta via la comunicazione \textbf{inaffidabile} per l'assenza di messaggi di ACK o NAK, implicando che i frame scartati possano essere recuperati solo se il mittente utilizza un \textbf{protocollo di trasporto affidabile}. Inoltre, lo standard Ethernet prevede l'uso del \textbf{protocollo CDMA/CD} senza slot e con back-off esponenziale per gestire i canali broadcast.

    Nonostante esistano molti \textbf{diversi standard Ethernet}, tutte le versioni hanno in comune il formato del frame e il protocollo MAC utilizzato, variando solo nella velocità garantita (es: da 2 Mb/s fino a 40 Gb/s) e nei supporti fisici utilizzati (es: cavo coassiale o fibra ottica). Lo standard Ethernet principalmente utilizzato è lo \textbf{standard Ethernet 802.3}, con un rate di trasmissione pari a \textbf{10 Mb/s}.

    \quad

    \subsection{Funzionalità dello switch}

    Come già detto più volte, lo \textbf{switch} (in particolare lo \textbf{switch Ethernet} previsto dallo standard Ethernet) è un dispositivo a livello di collegamento che assume più ruoli:
    \begin{itemize}
        \item Garantisce che il segnale rimanga allo stesso livello (amplificatore)
        \item Memorizza e inoltra frame Ethernet
        \item Esamina l'indirizzo MAC del frame in entrata, inoltrandolo \textbf{selettivamente} (a differenza dell'hub) ad uno o più collegamenti in uscita all'interno di un \textbf{segmento di LAN} (ossia un sottoinsieme di nodi della rete connessi ad una porta, può anche corrispondere ad un singolo nodo)
        \item Utilizza il CSMA/CD per accedere ad un segmento di rete
        \item Gli host sono \textbf{ignari} della sua presenza (\textbf{trasparenza})
        \item Non è necessaria la sua configurazione (\textbf{self-learning}) 
    \end{itemize}

    Inizialmente, gli switch Ethernet vennero adottati per aumentare la velocità dello standard, poiché l'uso del CDMA/CD richiedeva la diminuzione della lunghezza del canale per assicurarsi che $T_{fr} \geq 2D_p$ o direttamente l'abbandono del paradigma a bus condiviso.

    Tramite uno switch, invece, gli host dispongono di una \textbf{connessione diretta dedicata} dallo switch. In particolare, la \textbf{commutazione dei pacchetti} tramite un buffer e l'utilizzo di un protocollo Ethernet utilizzato su \textbf{ogni collegamento in entrata}, permette l'uso del \textbf{full-duplex} e la presenza di \textbf{collisioni solo all'interno dello stesso collegamento}.

    \textbf{Esempio:}

    \begin{itemize}
        \item Tramite la commutazione dei pacchetti, la trasmissione A-A' e la trasmissione B-B' possono avvenire simultaneamente, poiché vengono utilizzati collegamenti completamente diversi
        
        \newpage

        \item Tuttavia, le trasmissioni A-A' e C-A' non possono avvenire simultaneamente poiché si verificherebbe una collisione sul collegamento tra A' e lo switch stesso
        
        \begin{center}
            \begin{tabular}{ccc}
                \includegraphics[scale=0.45]{images/switch_1.png}
                &\qquad&
                \includegraphics[scale=0.45]{images/switch_2.png}
            \end{tabular}
        \end{center}
    \end{itemize}

    \quad

    Per effettuare le commutazioni, ogni switch possiede una \textbf{switch table} composta da entrate nel formato \texttt{< Indirizzo MAC, Porta, TTL >} (dunque simile ad una forwarding table).
    
    Poiché è interposto tra i nodi, uno switch è in grado di apprendere automaticamente (\textbf{self-learning}) quali host possano essere raggiunti tramite quali interfacce: quando uno switch interposto tra nodi riceve un frame tramite un'interfaccia, lo switch memorizza automaticamente la posizione del mittente, ossia il suo \textbf{segmento LAN di appartenenza}, leggendo il suo indirizzo MAC tramite il frame stesso e salvando l'entrata relativa nella switch table.

    \begin{center}
        \includegraphics[scale=0.35]{images/switch_3.png}
    \end{center}

    L'\textbf{algoritmo di commutazione} utilizzato dagli switch è pertanto molto semplice:
    \begin{enumerate}
        \item Quando un frame viene ricevuto, registra il link di entrata e l'indirizzo MAC dell'host mittente
        \item Cerca nella switch table l'entrata contenente l'esatto indirizzo MAC del destinatario (\textbf{exact matching})
        \item Se \textbf{esiste} un'entrata corretta nella switch table e il dispositivo di destinazione si trova nello \textbf{stesso segmento di LAN del mittente}, allora il frame viene scartato
        \item Se \textbf{esiste} un'entrata corretta nella switch table e il dispositivo di destinazione si trova in un \textbf{diverso segmento di LAN del mittente}, allora il frame viene inoltrato sull'interfaccia descritta dall'entrata
        \item Se invece \textbf{non esiste} un'entrata corretta nella switch table, il frame viene inviato in modalità flooding (dunque inviato a tutte le interfacce tranne quella del mittente)
    \end{enumerate}


    Il concetto di \textbf{segmento di LAN} diventa particolarmente rilevante nel caso in cui vi siano \textbf{più switch interconnessi}. Difatti, tramite il self-learning è possibile tranquillamente interconnettere più switch tra loro, ottenendo lo stesso effetto di un "unico grande switch".

    Nella seguente immagine, ad esempio, per lo switch $S_4$, gli host A, B e C appartengono allo stesso segmento di LAN, inoltrando verso lo switch $S_1$ qualsiasi pacchetto avente uno di essi come destinazione.

    \begin{center}
        \includegraphics[scale=0.5]{images/switch_4.png}
    \end{center}

    \quad

    \subsection{Virtual LAN (VLAN)}

    \quad

    \begin{frameddefn}{Virtual LAN}
        Una \textbf{virtual LAN (VLAN)} è un \textbf{partizionamento logico} di una LAN connessa a livello fisico in più \textbf{LAN virtuali}. Ogni VLAN definita sulla stessa infrastruttura fisica viene interpretata dai dispositivi come una LAN completamente separata dalle altre.
    \end{frameddefn}

    L'utilizzo delle VLAN permette una gestione più efficiente del traffico interno ad una LAN di grandi dimensioni. Ad esempio, senza il partizionamento logico fornito dalle VLAN, le \textbf{trasmissioni broadcast} verrebbero propagate all'interno dell'intera LAN, generando una grande quantità di traffico.
    
    L'utilizzo delle VLAN fornisce una \textbf{maggiore sicurezza} all'interno della stessa LAN tramite la possibilità di impedire a due VLAN interne alla stessa LAN di poter comunicare tra di loro, nonostante in realtà esse siano fisicamente collegate.

    Inoltre, in tal modo un dispositivo può connettersi in qualsiasi punto della LAN, potendo tuttavia accedere sempre e solo alla VLAN di appartenenza.

    \newpage

    \textbf{Esempio:}

    \begin{itemize}
        \item Un host appartenente alla VLAN definita per il dipartimento di Computer Science può connettersi in un qualsiasi punto della LAN, potendo accedere sempre e solo alla VLAN del dipartimento
        
        \begin{center}
            \includegraphics[scale=0.33]{images/vlan_1.png}
        \end{center}
    \end{itemize}

    Il partizionamento in VLAN può essere effettuato tramite molti criteri (es: anche in base al protocollo di un pacchetto). Il criterio più semplice e più utilizzato è il \textbf{port-based VLAN}, dove le porte di uno switch vengono \textbf{raggruppate} a livello logico, dunque tramite software di configurazione, in modo che il singolo switch operi in realtà come se fosse composto da più \textbf{switch virtuali}. Le porte possono inoltre essere assegnate dinamicamente tra le varie VLAN (\textbf{membership dinamica}).

    \begin{center}
        \begin{tabular}{ccc}
            \begin{tabular}{c}
                \includegraphics[scale=0.425]{images/vlan_2.png}
            \end{tabular}
            &$\to$&
            \begin{tabular}{c}
                \includegraphics[scale=0.425]{images/vlan_3.png}
            \end{tabular}
        \end{tabular}
    \end{center}

    Tramite il port-based VLAN, dunque, è possibile \textbf{isolare il traffico}, (es. riprendendo l'immagine precedente: permettendo ai frame da/verso le porte 1-8 di raggiungere solo le porte 1-8). Per tale motivo, due VLAN definite all'interno dello stesso switch \textbf{non possono comunicare direttamente tra di loro} attraverso lo switch stesso, richiedendo l'uso di un \textbf{router} (o un altro switch) collegato ad entrambe le VLAN.

    \begin{center}
        \includegraphics[scale=0.4]{images/vlan_4.png}
    \end{center}

    Alcuni switch sono inoltre dotati di una \textbf{porta trunk}, tramite cui possono essere trasportati frame tra VLAN definite su più switch fisici (\textbf{VLAN trunking}).

    \begin{center}
        \includegraphics[scale=0.5]{images/vlan_5.png}
    \end{center}
    
    Tali frame, tuttavia, non possono essere frame definiti secondo il formato standard. Bensì, essi richiedono un \textbf{campo ID VLAN} aggiuntivo per poter identificare le VLAN di appartenenza (standard 802.1q)

    \quad

    \subsection{Reti point-to-point e protocollo PPP}

    Come già accennato, una \textbf{rete point-to-point} è composta da un collegamento dedicato solo a due dispositivi. Esse non utilizzano il controllo di accesso al mezzo condiviso (dunque funzionalità del sotto-livello MAC), bensì utilizzano protocolli dedicati, come il \textbf{Point-to-Point Protocol (PPP)}, sviluppato come protocollo per definire uno standard per la gestione della trasmissione dati per più di una rete sullo stesso collegamento seriale 
    indipendentemente dal produttore dei dispositivi di rete.

    \begin{center}
        \includegraphics[scale=0.44]{images/ppp.png}
    \end{center}

    Trattandosi di un collegamento con \textbf{solo un mittente e solo un destinatario}, il protocollo PPP non richiede l'uso di un protocollo MAC e degli indirizzi MAC. Durante la trasmissione, il protocollo PPP utilizzato deve essere in grado di rilevare la presenza di eventuali \textbf{guasti} nel collegamento in modo da segnalare l'errore a livello di rete e rilevare la presenza di \textbf{errori} nella trasmissione (non necessariamente la correzione di essi).

    \begin{center}
        \includegraphics[scale=0.34]{images/ppp_2.png}
    \end{center}

    \addtocontents{toc}{\protect\newpage}
    \section{LAN wireless (WLAN)}

    \subsection{Caratteristiche ed architettura di reti wireless}

    A differenza delle LAN cablate, le \textbf{wireless LAN (WLAN)} utilizzano l'aria come mezzo trasmissivo tramite l'uso di onde radio. Per natura stessa della trasmissione, dunque, il mezzo di trasmissione (dunque l'aria) è condiviso da tutti gli host della rete, implicando che le trasmissioni avvengano sempre ed unicamente in modalità \textbf{broadcast}. Pertanto, esse richiedono una gestione più elaborata rispetto alle reti cablate.

    Ogni \textbf{host wireless} non è fisicamente connesso alla rete, potendosi dunque muovere liberamente al suo interno. Gli host wireless comunicano tra di loro inviando e ricevendo segnali da una stazione base detta \textbf{Access Point (AP)} (es: stazione radio, satellite, modem ADSL), il quale è solitamente connesso con una parte cablata della rete. L'access point è dunque responsabile dello scambio di pacchetti tra dispositivi appartenenti alla parte wireless di una LAN e la parte cablata di una LAN.
    
    \begin{center}
        \includegraphics[scale=0.4]{images/wlan.png}
    \end{center}

    A livello infrastrutturale, dunque, un access point può essere visto come uno "switch wireless". Difatti, per migrare da un ambiente cablato ad un ambiente wireless è sufficiente sostituire la NIC (cambiando di conseguenza anche gli indirizzi MAC) dei vari dispositivi con delle \textbf{NIC wireless} e sostituire lo switch a cui esse sono connesse con un semplice access point.

    Le WLAN connesse anche ad una parte cablata vengono dette \textbf{reti con infrastruttura}. Le WLAN possono anche essere composte da un insieme di host che si auto-organizzano per formare e gestire la rete (\textbf{reti ad hoc}), implicando che ogni host debba eseguire tutte le funzionalità di rete (network setup, routing, forwarding, ...).

    \begin{center}
        \begin{tabular}{ccc}
            
            \includegraphics[scale=0.36]{images/wlan_2.png}
            &\qquad\qquad&
            \includegraphics[scale=0.36]{images/wlan_3.png}
        \end{tabular}
    \end{center}

    \newpage

    Per via dell'uso dell'aria come mezzo trasmissivo, la trasmissione all'interno delle reti wireless possiede alcune \textbf{caratteristiche sfavorevoli}:
    \begin{itemize}
        \item \textbf{Attenuazione del segnale}, dovuta alla rapida diminuzione della forza dei segnali radio all'aumentare della distanza dal trasmettitore per via della dispersione del segnale in ogni direzione
        
        \begin{center}
            \includegraphics[scale=0.35]{images/wlan_4.png}
        \end{center}

        \item \textbf{Propagazione multi-path}, dovuta alla riflessione delle onde radio al contatto con un ostacolo (con aggiunta di perdita di potenza). Pertanto, un segnale può arrivare tramite una successione di riflessi a raggiungere una stazione o un AP attraverso percorsi multipli
        
        \begin{center}
            \includegraphics[scale=0.4]{images/wlan_5.png}
        \end{center}

        \item \textbf{Interferenze}, dovute all'uso della stessa banda di frequenza da parte di più trasmettitori (es: più tipologie di trasmissioni wireless utilizzano una banda a 2.4 GHz, come il Bluetooth e il Wi-Fi). Inoltre, anche la presenza dei multi-path può generare interferenza
        
        \begin{center}
            \includegraphics[scale=0.45]{images/wlan_6.png}
        \end{center}
    \end{itemize}

    Per gestire gli errori generati da tali casistiche viene utilizzato un \textbf{Signal to Noise Ratio (SNR)}, dove se il segnale in arrivo è più forte del rumore allora esso viene accettato e convertito in dati reali, venendo scartato in caso contrario.

    \newpage

    L'IEEE ha definito all'interno dello standard 802.11 le specifiche inerenti ai livelli di collegamento e fisico delle WLAN. In particolare, il \textbf{Wireless Fidelity (Wi-Fi)} è una tipologia di WLAN certificata dalla Wi-Fi Alliance, associazione no-profit composta da circa 300 aziende che si occupa di promuovere la crescita delle WLAN.

    All'interno dello standard viene definita la seguente gerarchia per il wireless:
    \begin{itemize}
        \item \textbf{Basic Service Set (BSS)}, costituito da uno o più host wireless connessi (con l'aggiunta di un AP nel caso delle BSS con infrastruttura). Le  \textbf{celle} delle \textbf{reti cellulare}, dunque, corrispondono ad una BSS con infrastruttura dove l'AP è il ripetitore cellulare.
        
        \begin{center}
            \begin{tabular}{ccc}
                
                \includegraphics[scale=0.36]{images/bss_1.png}
                &\qquad\qquad&
                \includegraphics[scale=0.36]{images/bss_2.png}
            \end{tabular}
        \end{center}

        \item \textbf{Extended Service Set (ESS)}, costituito da due o più BSS con infrastruttura, i quali sono collegati tramite un sistema di distribuzione (ossia una rete cablata o wireless)
        
        \begin{center}
            \includegraphics[scale=0.475]{images/ess.png}
        \end{center}
    \end{itemize}

    Lo spettro di frequenze dai 2.4 GHz ai 2.485 GHz è diviso in \textbf{11 canali} parzialmente sovrapposti. All'interno di una WLAN, l'amministratore dell'AP sceglie \textbf{uno o più canali} da utilizzare per le trasmissioni, rendendo possibili le interferenze con altri AP nel caso in cui vengano utilizzati gli stessi canali. 
    
    Tuttavia, i canali non interferiscono tra di loro nel caso in cui siano a \textbf{4 o più canali di distanza}, portando il numero massimo di canali utilizzabili da AP diversi per non ottenere interferenze pari a \textbf{tre canali} (es: utilizzando i canali 1, 6 e 11).

    Inoltre, lo standard 802.11 prevede che una singola stazione wireless sia sempre \textbf{associata ad un AP} (e di conseguenza ad un BSS) per poter accedere ad Internet. Di conseguenza, per associarsi ad un BSS è necessario conoscere gli AP disponibili al suo interno, richiedendo quindi l'uso di un \textbf{protocollo di associazione}:
    \begin{itemize}
        \item L'AP invia segnali periodici, detti segnali di beacon, che includono l'identificatore univoco dell'AP, ossia il \textbf{Service Set Identifier (SSID)},e il proprio indirizzo MAC
        \item La stazione wireless che vuole entrare all'interno di un BSS scandisce gli 11 canali trasmissivi alla ricerca di un frame beacon (\textbf{passive scanning})
        \item Alla fine della scansione, la stazione sceglierà l'AP da cui ha ricevuto un \textbf{beacon con maggiore potenza di segnale}, inviandogli un frame con una richiesta di associazione
        \item L'AP accetterà la richiesta con un frame di risposta di associazione (a meno che non sia richiesta un'autenticazione), permettendo all'host entrante di inviare successivamente una richiesta DHCP per ottenere un indirizzo IP
    \end{itemize}

    Nonostante sembri un problema apparentemente difficile, l'uso di \textbf{celle} (dunque di BSS) all'interno della stessa rete cellulare permette il passaggio da una cella all'altra tramite le associazioni agli AP senza alcun problema.

    \textbf{Esempio:}

    \begin{itemize}
        \item L'host H1 si sta spostando tra due celle della stessa rete cellulare
        \begin{center}
            \includegraphics[scale=0.375]{images/wlan_9.png}
        \end{center}
        \item L'host H1 sente che il segnale dall'access point AP1 si stia \textbf{affievolendo} ed avvia una scansione per cercare un segnale più forte, ossia AP2, disassociandosi da AP1 ed associandosi a quest'ultimo, mantenendo lo \textbf{stesso indirizzo IP} e le \textbf{stesse sessioni TCP aperte}
        \item Lo switch apprende la nuova porta su cui inoltrare i pacchetti con MAC address H1
    \end{itemize}

    \quad

    \subsection{Gestione delle collisioni nel wireless}

    Essendo l'unico mezzo trasmissivo condiviso tra tutti i dispositivi, vi è una stretta necessità di controllare l'accesso a tale mezzo per evitare le \textbf{collisioni}.  Come per la gestione cablata, per rilevare una collisione un host deve poter \textbf{trasmettere e ricevere contemporaneamente}. Tuttavia, poiché la \textbf{potenza del segnale ricevuto} è molto \textbf{inferiore} a quella del segnale trasmesso, sarebbe troppo costoso utilizzare un adattatore di rete in grado di rilevare collisioni (\textbf{no collision detection}).

    Inoltre, per via delle caratteristiche sfavorevoli del wireless, un host potrebbe \textbf{non accorgersi} che un altro host stia trasmettendo e dunque che sia impossibilitato a rilevare la collisione (\textbf{hidden terminal problem})

    \begin{center}
        \begin{tabular}{ccc}
            \includegraphics[scale=0.425]{images/wlan_7.png}
            &\qquad&
            \includegraphics[scale=0.425]{images/wlan_8.png}
        \end{tabular}
    \end{center}

    Per accedere al mezzo di comunicazione, dunque, nello standard 802.11 vengono definiti vari \textbf{protocolli MAC wireless}, ricadenti principalmente in due tecniche di accesso:
    \begin{itemize}
        \item \textbf{Distributed Coordination Function (DCF)}, dove i nodi si contendono l'accesso al canale
        \item \textbf{Point Coordination Function (PCF)}, dove l'AP coordina gli accessi al canale, rimuovendo la contesa
    \end{itemize}

    Per quanto riguarda i protocolli DCF, l'idea principale consiste nel riutilizzare il \textbf{protocollo CSMA/CD} previsto dallo standard Ethernet. Tuttavia, per via dell'hidden terminal problem e del no collision detection, l'uso del CSMA/CD risulta \textbf{impossibile} nelle reti wireless.
    
    \begin{frameddefn}{Protocollo CSMA/CA}
        Il \textbf{protocollo Carrier Sense Multiple Access with Collision Avoidance} \\\textbf{(CSMA/CA)} è una variante del protocollo CSMA dove:
        \begin{itemize}
            \item \textbf{Non vi è collision detection}
            \item Viene utilizzato un riscontro (\textbf{messaggio di ACK}) per capire se una trasmissione sia andata a buon fine senza alcuna collisione
            \item Viene utilizzato un \textbf{doppio ascolto} sul canale, uno per i dati ed uno per l'ACK
            \item La collisione può avvenire anche per gli ACK
        \end{itemize}
    \end{frameddefn}

    Per tentare di evitare collisioni con le stazioni che hanno già iniziato a trasmettere, le stazioni ascoltano il canale per un determinato periodo di tempo, detto \textbf{interframe space (IFS)}. Gli IFS si suddividono in \textbf{Short IFS (SIFS)}, utilizzato per l'alta priorità, e \textbf{DCF IFS (DIFS)}, utilizzato per la bassa priorità.
    
    In particolare, prima di inviare un frame, la stazione mittente ascolta il canale e avvia la tramissione se e solo se esso è libero per un tempo pari ad un \textbf{DIFS}. Una volta ricevuto il frame senza alcuna collisione, il ricevente invia un \textbf{ACK} dopo un tempo pari ad un \textbf{SIFS}. Viene utilizzato un tempo di DIFS maggiore rispetto ad un tempo di SIFS, in modo da dare priorità alle comunicazioni già iniziate (priorità agli ACK).

    \begin{center}
        \includegraphics[scale=0.5]{images/csma_ca.png}
    \end{center}

    Dopo aver atteso un tempo pari ad un DIFS, se il canale è ancora inattivo la stazione attenderà un ulteriore \textbf{finestra di contesa (contention window)}, ossia un lasso di tempo di back-off per cui viene ascoltato il canale prima di trasmettere (il tempo è suddiviso in slot e ad ogni slot viene eseguito l'ascolto del canale):
    \begin{itemize}
        \item Viene scelto un valore $k$ casuale nell'intervallo $[0, CW]$, dove $CW$ varia a seconda del numero di collisioni precedenti
        \item Finché $k > 0$, viene ascoltato il canale per uno slot di tempo. Se il canale è libero per la durata dello slot, allora il valore $k$ viene decrementato di uno. In caso contrario, viene atteso nuovamente che il canale si liberi per poi ripetere nuovamente la procedura di back-off
        \item Nel caso in cui il valore $k$ raggiunga 0, viene inviato il frame
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.55]{images/csma_ca_2.png}
    \end{center}

    Per risolvere il problema dell'hidden terminal, tuttavia, è necessario anche un meccanismo di \textbf{prenotazione del canale} tramite dei messaggi di \textbf{request-to-send (RTS)} e \textbf{clear-to-send (CTS)}:
    \begin{enumerate}
        \item Il mittente attende un DIFS, seguito dalla finestra di contesa
        \item Successivamente, viene inviato un RTS da parte del mittente, richiedendo di poter trasmettere i dati
        \item Una volta ricevuta la richiesta, il destinatario attende un SIFS per poi inviare un messaggio di CTS
        \item Dopo aver atteso un SIFS, il mittente invia i dati.
        \item Infine, dopo aver atteso un ulteriore SIFS, il destinatario invia un ACK per la corretta ricezione dei dati 
    \end{enumerate}

    Affinché le \textbf{altre stazioni} che non sono coinvolte nella comunicazione ma sono nel \textbf{raggio di trasmissione della destinazione} sappiano quanto tempo devono astenersi dal trasmettere, all'invio del RTS viene inclusa la \textbf{durata di tempo} per cui verrà occupato il canale per trasmettere il frame e ricevere l'ACK, la quale, inoltre, viene inclusa anche nel CTS inviato dal destinatario.

    Le stazioni influenzate da tale trasmissione avviano un timer, detto \textbf{Network Allocation Vector (NAV)}, indicante il tempo di attesa prima di poter ascoltare nuovamente il canale. Se il mittente di una trasmissione non riceve il messaggio di CTS, esso assumerà che si sia verificata una collisione, ritrasmittendo dopo un \textbf{tempo di back-off}.
    
    \begin{center}
        \includegraphics[scale=0.54]{images/csma_ca_3.png}
    \end{center}

    L'utilizzo di RTS/CTS, tuttavia, porta anche a situazioni sfavorevoli. Ad esempio, una stazione potrebbe astenersi dall'usare il canale nonostante possa trasmettere (\textbf{exposed terminal problem}). 

    \begin{center}
        \includegraphics[scale=0.45]{images/csma_ca_4.png}
    \end{center}

    Il frame utilizzato all'interno delle WLAN pertanto segue una struttura molto diversa dal frame Ethernet:
    \begin{itemize}
        \item \textbf{Campo Frame Control (FC)}, indicante la tipologia di frame (sotto-campo Type, 2 bit) e alcune informazioni di controllo
        \begin{itemize}
            \item \textbf{Type 00 - Frame di gestione}, usati per le comunicazioni iniziali tra stazioni e AP
            \item \textbf{Type 01 - Frame di controllo}, usato per accedere e dare riscontro assieme al sotto-campo Subtype (Subtype 1011: RTS, Subtype 1100: CTS, Subtype 1101: ACK)
            \item \textbf{Type 10 - Frame di dati}, vengono usati per trasportare i dati
        \end{itemize}

        \item \textbf{Campo Duration}, indica la durata della trasmissione successiva (corrispondente al tempo NAV di attesa prima di riascoltare)
        \item \textbf{Campo Sequence Control}, utilizzato per il numero di sequenza dei frammenti (gestione dei frame e degli ACK come nel livello di trasporto)
        \item \textbf{Campo Frame Check Sequence}, utilizzato per il CRC a 32 bit
        \item \textbf{4 Campi Indirizzi}, utilizzati per l'indirizzamento tra sistemi di distribuzione assieme ai sotto-campi To DS e From DS del campo FC
        
        \begin{center}
            \includegraphics[scale=0.6]{images/wlan_frame.png}
        \end{center}
    \end{itemize}

    In particolare, l'indirizzamento tra sistemi di distribuzione attraverso i campi del frame ricade nei seguenti quattro casi:
    
    \begin{center}
        \includegraphics[scale=0.5]{images/wlan_frame_2.png}

        \includegraphics[scale=0.5]{images/wlan_frame_3.png}
    \end{center}

    \quad
    
    \subsection{Bluetooth ed RFID}

    Il \textbf{Bluetooth} è una tecnologia LAN wireless progettata per connettere pochi dispositivi con diverse funzioni senza necessità di una stazione base (una LAN Bluetooth è una \textbf{rete ad hoc} di piccole dimensioni).

    All'interno del Bluetooth vengono definite due tipologie di reti:
    \begin{itemize}
        \item \textbf{Piconet}, ossia una rete composta da al massimo 8 dispositivi, tra cui \textbf{una stazione primaria e 7 stazioni secondarie} sintonizzate con la prima. Se vi sono altre stazioni secondarie sintonizzate con la primaria, esse vengono messe in stato di \textbf{parked}, rimanendo in attesa che una stazione attiva venga spostata in stato di parked o lasci la rete
        \item \textbf{Scatternet}, ossia una combinazione di piconet. Una stazione può essere anche secondaria all'interno di una piconet e primaria all'interno di un'altra piconet
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/bluetooth_1.png}
    \end{center}

    La tecnologia Bluetooth prevede l'uso di un trasmettitore radio di breve portata (massimo 10 metri) con un rate pari a 1 Mb/s e un'ampiezza di banda pari a 2.4 GHz. Pertanto, esse possono \textbf{interferire} con reti WLAN IEEE 802.11b, necessitando di un protocollo per minimizzare tale interferenza. Inoltre, la tecnologia Bluetooth definisce un \textbf{diverso stack protocollare} rispetto a quello TCP/IP.

    \begin{center}
        \includegraphics[scale=0.4]{images/bluetooth_2.png}
    \end{center}

    Per via delle sue caratteristiche fisiche, la tecnologia non può utilizzare efficientemente il protocollo MAC CSMA/CA. Pertanto, al suo interno viene utilizzato il \textbf{protocollo MAC TDMA}:
    \begin{itemize}
        \item Vengono utilizzati slot temporali di 625 $\mu$s
        \item La comunicazione tra primaria e secondarie è \textbf{half duplex} (dunque non contemporanea)
        \item La stazione primaria utilizza slot \textbf{pari}, mentre le secondarie utilizzano slot \textbf{dispari}
        \item Se vi sono più stazioni secondarie, ad ogni slot utilizzato dalla stazione primaria viene specificata quale sia la prossima secondaria a trasmettere
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.5]{images/bluetooth_4.png}
    \end{center}

    \quad

    Un'altra tecnologia molto utilizzata nell'ambito wireless è il sistema \textbf{Radio Frequency Identification (RFID)}, dove viene utilizzata una trasmissione wireless per ottenere identificazione, tracciamento automatico o contabilità.
    
    Vengono utilizzati dei chip radiotrasmittenti di piccole dimensioni detti \textbf{tag}. Il segnale emesso da tali tag viene letto da un dispositivo \textbf{reader}, il quale leggerà l'ID contenuto in tale segnale.

    In particolare, i tag possono essere \textbf{attivi}, ossia in grado di generare direttamente il segnale (richiedendo energia elettrica), o \textbf{passivi}, ossia in grado di riflettere il segnale inviato dal reader (\textbf{back-scattering}) alterandolo leggermente in modo da inserire il proprio ID (non richiedendo energia). 

    Esempi tipici della tecnologia RFID sono l'utilizzo di tessere (corrispondente ad un semplice tag passivo) per l'identificazione e l'autorizzazione all'accesso ad un luogo o servizio e l'utilizzo di sensori per il tracciamento di oggetti, come un bagaglio all'interno di un aeroporto.

    La tipologia di comunicazione RFID più utilizzata prevede la presenza di un solo reader e più tag passivi (\textbf{single-reader with passive tags}), dove il primo invia un segnale di interrogazione e i vari tag rispondono con il loro ID.
    
    Tale comunicazione, tuttavia, prevede la presenza di \textbf{collisioni} a seguito della risposta simultanea di più tag. Inoltre, essendo passive, i tag non possono ascoltare il canale, rendendo impossibile l'uso del carrier sense e del collision detection. Di conseguenza, è necessario che sia il \textbf{reader} stesso a gestire gli accessi al canale. Uno dei protocolli MAC più utilizzati nella tecnologia RFID è il \textbf{Tree Slotted Aloha (TSA)}, dove ad ogni slot di collisione viene generato un nuovo frame figlio e solo i tag rispondenti allo stesso slot partecipano alla trasmissione.
    
    \chapter{Sicurezza della rete}

    La \textbf{sicurezza della rete} consiste nell'applicazione di una serie di operazioni di protezione dei dati, applicazioni, dispositivi e sistemi connessi alla rete. In particolare, in essa possiamo individuare \textbf{quattro principi} ricadenti all'interno della più generica \textbf{triade CIA (Confidentiality, Integrity and Availability)} utilizzata nella \textbf{sicurezza informatica}:
    \begin{itemize}
        \item \textbf{Riservatezza}: soli ed unicamente il mittente e il destinatario previsti da una comunicazione devono essere in grado di poter accedere il contenuto di un messaggio.
        
        Alla base di tale principio vi è l'uso della \textbf{crittografia}, dove il mittente cifra un messaggio e il destinatario decifra il messaggio una volta ricevuto.

        \item \textbf{Autenticazione}: il mittente e il destinatario devono essere in grado di confermare l'identità l'uno dell'altro
        
        \item \textbf{Integrità del messaggio}: il mittente e il destinatario devono poter accertarsi che il messaggio non sia stato manomesso
        \item \textbf{Accesso e disponibilità}: i servizi devono essere accessibili e disponibili per gli utenti
    \end{itemize}

    Per via della natura stessa di Internet, senza l'utilizzo di operazioni inerenti alla sicurezza di rete, un qualsiasi intruso può intercettare, cancellare, aggiungere o modificare i messaggi in transito tra mittente e destinatario. In particolare, le principali forme di \textbf{attacco} da parte di un soggetto esterno ricadono in:
    \begin{itemize}
        \item \textbf{Eavesdropping} (tradotto: \textit{origliare}), ossia l'intercettazione di un messaggio (problema di \textbf{riservatezza})
        \item \textbf{Fabrication}, dove vengono attivamente inseriti messaggi nella comunicazione (problema di \textbf{autenticazione})
        \item \textbf{Impersonation}, dove viene falsificato l'indirizzo di origine del pacchetto, come l'\textbf{IP Spoofing} (problema di \textbf{autenticazione})
        \item \textbf{Hijacking}, dove un soggetto esterno prende controllo della comunicazione, sostituendosi al mittente o al destinatario all'insaputa dell'altro lato della comunicazione (problema di \textbf{autenticazione} e \textbf{riservatezza})
        \item \textbf{Denial of Service (DoS)}, dove viene impedito che il servizio venga correttamente utilizzato, ad esempio sovraccaricando le risorse (problema di \textbf{accesso e disponibilità})
    \end{itemize}


    \quad

    \section{Principi di crittografia}

    Nelle successive sezioni faremo uso del classico \href{https://en.wikipedia.org/wiki/Alice_and_Bob}{\textbf{modello Alice \& Bob}} per trattare esempi di trasmissione sicura ed insicura, dove (solitamente) Alice è il \textbf{mittente} e Bob il \textbf{destinatario}. Ad esempio, consideriamo il seguente schema di crittografia:

    \begin{center}
        \includegraphics[scale=0.4]{images/cypher_1.png}
    \end{center}

    \begin{enumerate}
        \item Alice vuole inviare il messaggio $m$ verso Bob 
        \item Invece di inviare il \textbf{messaggio in chiaro} (ossia non cifrato, dunque il messaggio $m$), Alice applica, tramite un algoritmo di crittografia, la propria \textbf{chiave di cifratura} $K_A$ sul messaggio $m$, inviando a Bob il \textbf{ciphertext (testo cifrato)} $K_A(m)$
        \item Durante la trasmissione del testo cifrato, l'intruso Trudy intercetta il messaggio. Tuttavia, essendo cifrato, essa non è un grado di poterlo comprendere, rendendo inutile l'intercettazione
        \item Una volta raggiunto Bob, quest'ultimo applicherà la propria \textbf{chiave di decifratura} $K_B$ per poter accedere al messaggio di Alice (dunque si ha che $K_B(K_A(m)) = m$)
    \end{enumerate}

    Sebbene tale sistema generale sembra apparentemente sicuro, la vera sicurezza del sistema dipende interamente dalle \textbf{chiavi e l'algoritmo di cifratura} utilizzate:
    \begin{itemize}
        \item \textbf{Attacco con solo testo cifrato}: una volta ottenuto il testo cifrato, Trudy può provare \textbf{tutte le chiavi di decifratura possibili}, richiedendo una quantità di tempo in base alla complessità della chiave e dell'algoritmo, o effettuare un'\textbf{analisi statistica}, riducendo il numero di tentativi necessari
        \item \textbf{Attacco con testo in chiaro noto}: Trudy conosce alcune corrispondenze tra il testo in chiaro e testo cifrato, riuscendo a ricostruire il messaggio originale
        
        (es: ottenendo una buona parte di corrispondenze, è facile capire quali siano le lettere mancanti per ottenere la parola originale)

        \item \textbf{Attacco con testo in chiaro selezionato}: osservando molti testi cifrati generati dallo stesso algoritmo utilizzato, Trudy riesce a ricostruire il messaggio originale
        
        (es: in modo analogo a come il team di Alan Turing riuscì a decifrare il codice nazista generato dalla macchina Enigma)
    \end{itemize}

    \begin{frameddefn}{Crittografia a chiave simmetrica}
        Uno schema crittografico viene detto a \textbf{chiave simmetrica} se la stessa chiave è utilizzata sia per la cifratura che per la decifratura.
    \end{frameddefn}

    Tra i principali schemi crittografici a chiave simmetrica troviamo:
    \begin{itemize}
        \item \textbf{Cifrario per sostituzione}, dove parti del messaggio vengono sostituite tramite una mappatura biettiva. Esempi tipici sono il \textbf{cifrario monoalfabetico}, dove ogni lettera viene univocamente associata ad un'altra (es: la lettera A viene mappata alla lettera K), o il \textbf{cifrario di Cesare}, dove ogni lettera viene trasposta di un determinato numero di posizioni (es: se viene scelto il numero 3 come numero di trasposizioni, le lettere A, B, C, ... verranno mappate alle lettere D, E, F, ...)
        
        \begin{center}
            \includegraphics[scale=0.35]{images/monoalf.png}

            \textit{Esempio di crittografia con cifrario monoalfabetico}
        \end{center}

        \item \textbf{Cifrario per trasposizione}, dove parti del messaggio vengono trasposte secondo una regola invertibile (es: disporre il messaggio per una tabella e scambiare la quarta riga con la prima, la seconda con la settima, ...)
        
        \begin{center}
            \includegraphics[scale=0.5]{images/transp.png}
        \end{center}

        \item \textbf{Cifrario a blocchi}, dove il messaggio viene suddiviso in blocchi e vengono utilizzate tabelle di corrispondenza tra blocchi in chiaro e blocchi cifrati, spesso ripetendo il procedimento più volte.
        
        Esempio tipico è il \textbf{Data Encryption Standard (DES)}, utilizzante una chiave simmetrica a 56 bit ed un input di testo in chiaro a 64 bit ed ua cifratura a blocchi con concatenazione di blocchi di cifratura. 

        \begin{center}
            \includegraphics[scale=0.5]{images/des.png}
        \end{center}

        Tuttavia, la chiave a 56 bit utilizzata dal DES risulta essere troppo debole, richiedendo meno di un giorno per essere decifrata tramite bruteforce. Per rendere il DES più sicuro, in passato veniva utilizzato il \textbf{Triple DES (3DES)}, applicando 3 chiavi DES sul testo cifrato, mentre attualmente viene utilizzato l'\textbf{Advanced Encryption Standard (AES)}, basato su blocchi a 128 bit ed una chiave a 128, 192 o 256 bit, richiedendo circa 149 trilioni di anni per la decifratura.
    \end{itemize}

    \begin{frameddefn}{Crittografia a chiave asimmetrica}
        Uno schema crittografico viene detto a \textbf{chiave asimmetrica (o a chiave pubblica)} se la chiave di cifratura è diversa dalla chiave di decifratura.

        In particolare, a differenza della crittografia a chiave simmetrica, dove è richiesto che il mittente e il destinatario conoscano la chiave condivisa, viene utilizzato un approccio radicalmente differente:
        \begin{itemize}
            \item La chiave di cifratura è \textbf{pubblica e nota a tutti}. Per tale motivo, essa viene anche detta \textbf{chiave pubblica}
            \item La chiave di decifratura è \textbf{nota solo al destinatario}. Per tale motivo, essa viene anche detta \textbf{chiave privata}
            \item La chiave pubblica e la chiave privata sono \textbf{l'una l'inversa dell'altra}.
        \end{itemize}
    \end{frameddefn}

    Per via della loro natura, ogni \textbf{coppia di chiavi} può essere utilizzata per comunicare solo in una direzione:
    \begin{itemize}
        \item Se Alice e Bob vogliono comunicare usando una crittografia asimmetrica, sarà necessario generare \textbf{due coppie di chiavi}, dove la prima chiave pubblica e la seconda chiave privata andranno ad Alice, mentre la prima chiave privata e la seconda chiave pubblica andranno a Bob
        \item Tutti i mittenti che vogliono inviare un messaggio cifrato a Bob possono usare la \textbf{stessa chiave pubblica}, permettendo a Bob di decifrare ogni messaggio con la chiave privata associata a tale chiave pubblica
        
        \begin{center}
            \includegraphics[scale=0.45]{images/asimm_1.png}
        \end{center}

    \end{itemize}

    Essendo più complessa della crittografia simmetrica, la crittografia asimmetrica viene solitamente utilizzata per cifrare/decifrare quantità limitate di informazioni (es: un breve messaggio o la chiave di un cifrario simmetrico, in modo che non venga intercettata durante la trasmissione).

    Inoltre, in linea generale, si ha che:
    \begin{itemize}
        \item Il testo in chiaro $m$ e il testo cifrato $c$ vengono considerati \textbf{numeri interi}
        \item La cifratura e decifratura avviene tramite \textbf{due funzioni matematiche inverse tra loro} 
        \item Il testo cifrato può essere inteso come $c = K_{pub}(m)$, mentre il testo in chiaro può essere inteso come $m = K_{priv}(c)$
    \end{itemize}

    \quad

    \subsection{Crittosistema RSA}

    Il crittosistema a chiave asimmetrica più diffuso è il \textbf{crittosistema RSA} (nome dato dai suoi inventori: Rivest, Shamir e Adleman), basato interamente sull'algebra modulare e lo studio dei numeri primi:
    \begin{enumerate}
        \item Vengono scelti \textbf{due numeri primi} $p, q \in \mathbb{P}$ molto elevati (es: 1024 bit ciascuno)
        \item Vengono calcolati $n := p \cdot q$ e $\phi = (p-1)(q-1)$
        \item Viene scelto un valore $e$ (con $e < n$) tale che esso sia \textbf{coprimo con $\phi$} (ossia non abbia fattori in comune con esso)
        \item Viene scelto $d$ tale che $e \cdot d  \equiv 1 (\text{mod } \phi)$, ossia tale che $d \equiv e^{-1} (\text{mod } \phi)$ 
        \item La \textbf{chiave pubblica} corrisponderà alla coppia $K_{pub} := (e,n)$, mentre la \textbf{chiave privata} corrisponderà a $K_{priv} := (d,n)$
        \item Per la cifratura si ha che \[m^e \equiv c (\text{mod }n)\]
        mentre per la decifratura si ha che 
        \[c^d \equiv m (\text{mod }n)\]
        implicando quindi che 
        \[(m^e)^d \equiv m (\text{mod }n)\]
        \item Poiché vengono richiesti calcoli di potenze molto elevate, vengono utilizzate molte proprietà dell'algebra modulare per velocizzare il calcolo
    \end{enumerate}

    \quad

    \textbf{Esempio:}

    \begin{itemize}
        \item Bob vuole generare la propria coppia di chiavi, in modo che chiunque possa comunicare in modo sicuro con lui cifrando un messaggio tramite la chiave pubblica generata
        \begin{enumerate}
            \item Bob sceglie $p = 5$ e $q = 13$, implicando che $n = 5 \cdot 13 = 65$ e che $\phi = 4 \cdot 12 = 48$
            \item Bob sceglie il primo valore coprimo con $\phi = 48$, ossia $e = 5$.
            \item Viene scelto $d = 29$, poiché $d \equiv e^{-1}(\text{mod } \phi) \implies 29 \equiv 5^{-1} (\text{mod }48)$
            \item Le chiavi generate sono $K_{pub} = (5,65)$ e $K_{priv} = (29,65)$
        \end{enumerate}
        \item Una volta generate le chiavi e diffusa la chiave pubblica, Alice vuole inviare un messaggio a Bob.
        
        Ad esempio, supponiamo che il messaggio sia $m := 12$, corrispondente alla lettera "L". Il testo cifrato ottenuto sarà:
        \[12^{5} \equiv c (\text{mod }65) \implies 17 \equiv c (\text{mod }65)\]
        
        Per decifrarlo, dunque, sarà sufficiente applicare la chiave privata sul testo cifrato:
        \[17^{29} \equiv m (\text{mod }65) \implies 12 \equiv c (\text{mod }65)\]
    \end{itemize}

    Tuttavia, le chiavi generate da Bob risultano essere \textbf{estremamente deboli}. Per trovare le chiavi, è sufficiente trovare i valori $p$ e $q$ tramite cui sono state generate:
        \begin{enumerate}
            \item Poiché la chiave pubblica $K_{pub} = (e,n)$ contiene anche il valore $n$ (è necessario che sia pubblico per effettuare la cifratura e la decifratura), è sufficiente trovare i due fattori che lo compongono
            \item Poiché nel nostro esempio si ha che $n = 65$, è sufficiente provare a dividere $n$ per i primi 3 numeri primi (ossia 2, 3 e 5), ottenendo che $\frac{65}{5} = 13$ e dunque che $p = 5$ e $q = 13$
            \item Successivamente, tramite $p$ e $q$ sarà facilmente calcolabile il valore $\phi$ e il valore $d \equiv e^{-1} (\text{mod } \phi)$ componente la chiave privata
        \end{enumerate}

    Come già accennato, il funzionamento dell'algoritmo RSA deriva direttamente dalle proprietà dell'\textbf{algebra modulare}:

    \begin{itemize}
        \item È dimostrabile che dati $p,q \in \mathbb{P}$ si ha che
        \[x^y \equiv x^{y (\text{mod} (p-1)(q-1))} (\text{mod pq})\]
        da cui otteniamo che
        \[(m^e)^d \equiv m^{ed} \equiv m^{ed (\text{mod} (p-1)(q-1))} \equiv m^{1 (\text{mod} (p-1)(q-1))} \equiv m (\text{mod n}) \]
        \item Inoltre, poiché
        \[m \equiv (m^e)^d \equiv (m^d)^e (\text{mod n})\]
        è possibile applicare le due chiavi in un \textbf{qualsiasi ordine}
    \end{itemize}

    La \textbf{sicurezza dell'algoritmo RSA}, dunque, è determinata esclusivamente dai due valori $p$ e $q$ scelti, poiché numeri di grandi dimensioni sono molto \textbf{difficili da fattorizzare}.
    
    Inoltre, poiché è richiesta una grande quantità di calcoli per l'uso dell'algoritmo RSA e poiché gli algoritmi DES e AES sono estremamente più veloci di RSA, la crittografia a chiave pubblica viene utilizzata per stabilire un canale sicuro tra i due interlocutori, per poi scambiare una seconda chiave, detta \textbf{chiave simmetrica di sessione}, da utilizzare durante lo scambio di messaggi.

    \quad

    \section{Autenticazione ed Integrità del messaggio}

    Per poter autenticare correttamente un utente sulla rete, è necessario l'utilizzo di un \textbf{authentication protocol (ap)} in grado di impedire che un soggetto di terze parti possa impersonare un utente.
    
    \begin{itemize}
        \item Bob vuole che Alice sia in grado di dimostrargli la sua identità prima di concederle l'accesso ad un dato sensibile
        \item \textbf{Protocollo ap1.0}:
        
        \begin{itemize}
            \item Alice invia a Bob un messaggio \textit{"I am Alice"} in cui afferma di essere Alice
            \item Poiché all'interno di una rete Bob non ha alcun modo per sapere chi sia Alice, Trudy può semplicemente fingere di essere Alice, inviando a Bob lo stesso messaggio \textit{"I am Alice"}
            
        \end{itemize}
        \begin{center}
            \begin{tabular}{ccc}
                \includegraphics[scale=0.35]{images/aut_1.png}
                &\qquad&
                \includegraphics[scale=0.35]{images/aut_2.png}
            \end{tabular}
        \end{center}

        \item \textbf{Protocollo ap2.0}:
        
        \begin{itemize}
            \item Oltre al messaggio "I am Alice", Alice inserisce anche il proprio indirizzo IP all'interno del pacchetto da inviare a Bob
            \item Tramite l'\textbf{IP spoofing} (ossia la falsificazione dell'indirizzo IP del mittente di un datagramma), Trudy può inserire l'indirizzo IP di Alice nel campo sorgente, fingendosi essa
        \end{itemize}
        
    \end{itemize}
    \begin{center}
        \begin{tabular}{ccc}
            \includegraphics[scale=0.35]{images/aut_3.png}
            &\qquad&
            \includegraphics[scale=0.35]{images/aut_4.png}
        \end{tabular}
    \end{center}

    \begin{itemize}
        \item \textbf{Protocollo ap3.0}:
        
        \begin{itemize}
            \item Oltre al messaggio "I am Alice" e al proprio indirizzo IP, Alice inserisce anche una password segreta precedentemente accordata con Bob
            \item Trudy può intercettare il pacchetto inviato da Alice e registrarlo, per poi inviarlo in un secondo momento a Bob, fingendosi Alice (\textbf{replay attack})
        \end{itemize}
        
    \end{itemize}
    \begin{center}
        \begin{tabular}{ccc}
            \includegraphics[scale=0.325]{images/aut_5.png}
            &\qquad&
            \includegraphics[scale=0.325]{images/aut_6.png}
        \end{tabular}
    \end{center}

    \begin{itemize}
        \item \textbf{Protocollo ap3.1 }:
        
        \begin{itemize}
            \item Oltre al messaggio "I am Alice" e al proprio indirizzo IP, Alice inserisce anche una password segreta \textbf{crittografata} precedentemente accordata con Bob
            \item Il replay attack effettuato da Trudy funziona ancora
        \end{itemize}
        
    \end{itemize}
    \begin{center}
        \begin{tabular}{c}
            \includegraphics[scale=0.325]{images/aut_7.png}
        \end{tabular}
    \end{center}

    
    \begin{itemize}
        \item \textbf{Protocollo ap4.0 }:
        
        \begin{itemize}
            \item Dopo aver ricevuto il pacchetto di autenticazione da Alice, Bob invia un \textbf{nonce} $R$ ad Alice, ossia un \textbf{numero usato once-in-a-lifetime}.
            \item Successivamente, Bob rimarrà in attesa che Alice invii il nonce $R$ cifrato con una \textbf{chiave simmetrica segreta}, in modo da potersi accertare che Alice sia "live" in quanto solo Alice è a conoscenza della chiave
            \item Per utilizzare tale protocollo, tuttavia, è necessario stabilire in anticipo un canale sicuro per potersi scambiare preventivamente la chiave simmetrica
        \end{itemize}
        
    \end{itemize}
    \begin{center}
        \begin{tabular}{c}
            \includegraphics[scale=0.35]{images/aut_8.png}
        \end{tabular}
    \end{center}

    \begin{itemize}
        \item \textbf{Protocollo ap5.0 }:
        
        \begin{itemize}
            \item Alice cifra con la sua \textbf{chiave privata} il nonce ricevuto da Bob, per poi inviarlo
            \item Successivamente, Bob chiede ad Alice di inviargli la propria chiave pubblica, in modo da poter decifrare il nonce ricevuto
            
            \begin{center}
                \begin{tabular}{c}
                    \includegraphics[scale=0.325]{images/aut_9.png}
                \end{tabular}
            \end{center}

            \item Trudy può immettersi nella conversazione, impersonando Alice quando comunica con Bob e impersonando Bob quando comunica con Alice (\textbf{man in the middle attack})
        \end{itemize}
    \end{itemize}
    
    \begin{center}
        \begin{tabular}{c}
            \includegraphics[scale=0.3]{images/aut_10.png}
        \end{tabular}
    \end{center}

    \quad

    \subsection{Firma digitale e Message digest}

    \quad

    \begin{frameddefn}{Firma digitale}
        La \textbf{firma digitale} è un metodo matematico/crittografico utilizzato per dimostrare l'\textbf{autenticità di un documento digitale} autenticando l'autore di tale documento ed accertandosi dell'integrità del documento, ossia che non sia stato manipolato.

        La \textbf{firma digitale} viene riconosciuta dalle varie nazioni come \textbf{strumento legale valido} e può essere utilizzata in \textbf{sede giuridica} per dimostrare l'avvenuta firma da parte di un soggetto.
    \end{frameddefn}

    Poiché l'\textbf{ordine di applicazione} di chiave pubblica e privata non è importante per ottenere il messaggio originale e poiché la chiave privata viene \textbf{posseduta solo ed esclusivamente da un soggetto}, per autenticare il soggetto stesso è sufficiente applicare la sua chiave pubblica su un \textbf{documento firmato tramite la sua chiave privata}, dunque $K_{pub}(K_{priv}(m)) = m$

    \newpage

    \textbf{Esempio:}

    \begin{itemize}
        \item Supponiamo che Alice riceva da Bob il messaggio $m$ firmato con la chiave privata $K_{B}^-$ di Bob (dunque riceve $K_B^-(m)$)
        \item Per verificare che sia stato effettivamente firmato da Bob, Alice applica la chiave pubblica di Bob sul messaggio firmato
        \item Se $K_B^+(K_B^-(m)) = m$, allora chiunque abbia firmato il messaggio $m$ deve aver utilizzato la chiave privata di Bob. Inoltre, poiché $K_B^+(K_B^-(m)) = m$, Alice può assicurarsi che il messaggio non sia stato alterato 
        \item Qualora qualcuno si impossessasse della chiave privata di Bob, tale soggetto potrebbe \textbf{legalmente firmare digitalmente documenti al posto di Bob}, rendendo quindi fondamentale che Bob conservi in modo sicuro la sua chiave privata
    \end{itemize}

    \begin{frameddefn}{Message digest}
        Un \textbf{message digest} è l'output ottenuto applicando una \textbf{funzione di hash ottimale} su un messaggio. La funzione di hash utilizzata deve rispettare le seguenti proprietà:
        \begin{itemize}
            \item Il digest prodotto deve essere di \textbf{dimensioni fisse}
            \item Deve essere \textbf{computazionalmente impossibile} ricostruire il messaggio originale tramite un suo digest
            \item Applicando la funzione sullo stesso messaggio il digest ottenuto sarà sempre lo stesso (dunque il digest deve essere \textbf{invariante nel tempo})
            \item Alterando leggermente il messaggio il digest ottenuto deve essere \textbf{radicalmente diverso}
            \item Il numero di \textbf{collisioni hash}, ossia parole aventi lo stesso digest, deve essere il minimo possibile
        \end{itemize}
    \end{frameddefn}

    Poiché risulta essere computazionalmente costoso cifrare e decifrare messaggi lunghi con chiave pubblica o privata, il \textbf{message digest} viene utilizzato per ridurre l'\textbf{impronta digitale} di un messaggio crittografato, ossia la quantità di calcoli necessaria per processarlo.

    Poiché la funzione hash ottimale deve essere \textbf{invariante}, se Bob invia ad Alice il messaggio $m$ e il digest $H(m)$, Alice può verificare l'\textbf{integrità del messaggio} applicando la stessa funzione di hash sul messaggio $m$ ricevuto, verificando se i due digest \textbf{coincidono}.

    Di conseguenza, per ridurre l'impronta digitale della firma digitale, Bob applica la sua chiave privata $K_{B}^-$ sul digest $H(m)$ del messaggio che vuole inviare ad Alice, per poi \textbf{accodare $K_{B}^-(H(m))$ al messaggio originale}. 
    
    In tal modo, una volta ricevuto il pacchetto, Alice è in grado di applicare la chiave pubblica sul digest crittografato, per poi calcolare il digest dei messaggio $m$ ricevuto e verificare se esso \textbf{coincida} con quello decifrato, verificando così sia l'\textbf{autenticità} del documento sia la sua \textbf{integrità}.

    \begin{center}
        \includegraphics[scale=0.375]{images/hash.png}
    \end{center}

    Le funzioni hash più utilizzate sono:
    \begin{itemize}
        \item \textbf{Message-Digest 5 (MD5)}, una funzione hash ampiamente utilizzata anche all'interno del documento RFC 1321. Il messaggio viene convertito in un digest di 128 bit tramite un processo a 4 fasi
        \item \textbf{Secure Hash Algorithm 1 (SHA-1)}, una funzione standard prevista da molti standard. Il digest prodotto è di 160 bit. 
    \end{itemize}
    Nonostante la loro efficacia, entrambe le funzioni hash precedentemente citate vengono considerate \textbf{insicure}, poiché non computazionalmente laboriose per i computer moderni, richiedendo massimo un giorno tramite un approccio bruteforce. Altre loro varianti, come MD6 e SHA-2 vengono utilizzate al loro posto.

    \quad

    \subsection{Certification Authorities (CA)}

    \quad

    \begin{frameddefn}{Certification Authority (CA)}
        Una \textbf{certification authority (CA)} è un'organizzazione o ente certificato atto all'associazione di chiavi pubbliche ad una particolare entità.

        L'entità, la quale può essere una persona, un sito web o un router, \textbf{registra la propria chiave pubblica} fornendo una prova d'identità alla CA, la quale successivamente creerà un \textbf{certificato digitale} che attesta l'associazione tra l'entità e tale chiave pubblica.

        La chiave pubblica inserita nel certificato viene \textbf{firmata con la chiave privata della CA}, al fine di garantirne l'autenticità, per poi pubblicizzare il certificato affermando che tale chiave pubblica appartenga all'entità certificata.
    \end{frameddefn}

    \textbf{Esempio:}

    \begin{enumerate}
        \item Bob vuole certificare la propria chiave pubblica
        \item Bob invia in modo sicuro (ad esempio utilizzando la chiave pubblica della CA) la propria chiave pubblica e la propria prova d'identità
        \item Una volta verificata l'identità di Bob, la CA firmerà con la propria chiave privata la chiave pubblica di Bob, per poi inserire la firma e la chiave pubblica nel certificato 
        
        \begin{center}
            \includegraphics[scale=0.45]{images/ca.png}
        \end{center}
    \end{enumerate}

    \quad

    I \textbf{certificati digitali} seguono la seguente struttura:
    \begin{itemize}
        \item Informazioni:
        \begin{itemize}
            \item Versione
        	\item Numero seriale
        	\item ID dell'algoritmo
        	\item Ente emittente
        	\item Validità
        	\item Non prima
        	\item Non dopo
        	\item Soggetto
        	\item Informazioni sulla chiave pubblica del soggetto
        	\item Algoritmo per l'utilizzo della chiave pubblica
        	\item Chiave pubblica
        	\item Codice identificativo univoco dell'emittente (facoltativo)
        	\item Codice identificativo univoco del soggetto (facoltativo)
        	\item Estensioni (facoltativo)
        	\item ...
        \end{itemize}
        \item Algoritmo di firma del certificato
        \item Firma del certificato
    \end{itemize}

    \quad

    Tramite l'uso dei certificati digitali è possibile \textbf{validare l'autenticità della chiave pubblica di un soggetto}, risolvendo completamente il \textbf{man in the middle attack} (a meno che la CA stessa non venga compromessa):
    \begin{itemize}
        \item Quando Alice vuole la chiave pubblica di Bob, richiede il suo certificato direttamente a Bob o ad un ente esterno
        \item Alice applica la chiave pubblica della CA sulla firma presente nel certificato, confrontandola con la chiave pubblica presente nel certificato
        \item Se le due chiavi coincidono, Alice potrà assicurarsi che la chiave pubblica sia effettivamente di Bob, impedendo a Trudy di immettersi nella comunicazione impersonando Bob
    \end{itemize}

    \begin{center}
        \includegraphics[scale=0.4]{images/ca_2.png}
    \end{center}

    \newpage

    \section{Sicurezza della posta elettronica}

    Tramite l'uso di chiavi pubbliche e private, è possibile ottenere \textbf{riservatezza}, \textbf{autenticità} e \textbf{integrità} in varie tipologie di applicazioni di rete:

    \begin{itemize}
        \item Alice desidera scambiare email a Bob in modo \textbf{riservato}.
        \begin{itemize}
            \item Alice genera una chiave simmetrica $K_S$
            \item Alice crittografa l'email $m$ con $K_S$ (per maggiore efficienza), per poi crittografare la chiave $K_S$ con la chiave pubblica di Bob
            \item Alice invia sia $K_S(m)$ sia $K_B^+(K_S)$ a Bob
            \item Bob usa la propria chiave privata $K_B^-$ per decifrare $K_B^+(K_S)$, in modo da ottenere $K_S$, per poi utilizzarla per decifrare l'email 
            \item Bob e Alice possono accordarsi per continuare ad utilizzare la chiave simmetrica $K_S$ in futuro, senza richiedere che ne venga nuovamente generata un'altra
            
            \begin{center}
                \includegraphics[scale=0.4]{images/email_res.png}
            \end{center}
        \end{itemize}

        \item Alice desidera inviare un'email a Bob assicurando a quest'ultimo l'\textbf{autenticità} e l'\textbf{integrità} dell'email stessa (non è interessata alla riservatezza)
        
        \begin{itemize}
            \item Alice calcola il digest della sua email $m$ e firma digitalmente tale digest
            \item Alice invia a Bob $K_A^-(H(M))+m$, ossia un messaggio composto da $K_A^-(H(M))$ e $m$
            \item Una volta ricevuto il messaggio, Bob recupererà la chiave pubblica di Alice tramite il suo certificato digitale, per poi decifrare il digest
            \item Successivamente, Bob calcolerà il digest del messaggio ricevuto e lo comparerà con quello decifrato
            
            \begin{center}
                \includegraphics[scale=0.4]{images/email_aut.png}
            \end{center}
        \end{itemize}

        \newpage

        \item Alice desidera inviare un'email a Bob garantendo \textbf{riservatezza}, \textbf{autenticità} e \textbf{integrità} dell'email
        
        \begin{itemize}
            \item Alice calcola il digest della sua email $m$ e firma digitalmente tale digest
            \item Alice genera una chiave simmetrica $K_S$
            \item Alice crittografa il messaggio $K_A^-(H(m))+m$ con $K_S$ (per maggiore efficienza), per poi crittografare la chiave $K_S$ con la chiave pubblica di Bob
            \item Alice invia sia $K_S(K_A^-(H(m))+m)$ sia $K_B^+(K_S)$ a Bob
            \item Bob usa la propria chiave privata $K_B^-$ per decifrare $K_B^+(K_S)$, in modo da ottenere $K_S$, per poi utilizzarla per decifrare $K_S(K_A^-(H(m))+m)$
            \item Una volta ottenuto il messaggio $K_A^-(H(m))+m$, Bob recupererà la chiave pubblica di Alice tramite il suo certificato digitale, per poi decifrare $K_A^-(H(m))$
            \item Successivamente, Bob calcolerà il digest del messaggio ricevuto e lo comparerà con quello decifrato
            
            \begin{center}
                \includegraphics[scale=0.425]{images/email_res_aut.png}
            \end{center}
        \end{itemize}
    \end{itemize}

    Il software più utilizzato per gestire tale tipologia di comunicazioni è il software \textbf{Pretty Good Privacy (PGP)} (attualmente esiste anche una versione open source, ossia OpenPGP).

    \quad

    \section{Sicurezza a livello di trasporto (TLS)}

    Come già accennato nel capitolo inerente al livello di trasporto, alcuni protocolli di tale livello sprovvisti di sicurezza utilizzano spesso il \textbf{Transport Layer Security (TLS)}, un protocollo di sicurezza ampiamente diffuso situato "al di sopra" del livello di trasporto (tra applicativo e trasporto).

    Ad esempio, la versione del protocollo HTTP facente uso del TLS è l'HTTPS (HTTP Secure, porta TCP/443).

    Il TLS fornisce \textbf{riservatezza} tramite crittografia simmetrica, \textbf{autenticazione} tramite crittografia a chiave asimmetrica e \textbf{integrità} tramite hashing crittografico. Inizialmente fu implementato tramite socket sicuri (\textbf{Secure Socket Layer - SSL}), per poi venir deprecato del 2015 e sostituito con il protocollo \textbf{TLS 1.3}.

    Prima di discutere dell'implementazione effettiva del TLS 1.3, analizziamo la costruzione di un \underline{protocollo TLS "giocattolo"}, il quale chiameremo \textbf{Toy-TLS (T-TLS)}. In particolare, abbiamo già visto precedentemente tutte le parti necessarie:
    \begin{itemize}
        \item \textbf{Handshake}, dove Alice e Bob usano i loro certificati e le loro chiavi pubbliche per autenticarsi a vicenda e scambiarsi uno \textbf{shared secret}, ossia una "master key" da utilizzare per generare \textbf{chiavi simmetriche di sessione}
        \item \textbf{Key derivation}, Alice e Bob usano lo shared secret per generare le chiavi di sessione
        \item \textbf{Data transfer}, dove i dati trasferiti vengono visti come una serie di record di dati e non più come un unico bytestream, richiedendo di tenere traccia dello stato della connessione
        \item \textbf{Chiusura della connessione}, tramite messaggi speciali 
    \end{itemize}

    \quad

    Vediamo quindi una possibile implementazione del nostro T-TLS handshake:
    \begin{enumerate}
        \item Bob stabilisce una connessione TCP con Alice, effettuando quindi il normale handshake a 3 vie
        \item Bob invia un messaggio di "T-TLS hello", chiedendo ad Alice il suo certificato 
        \item Una volta verificata l'identità di Alice, Bob cifra il Master Secret (MS), ossia la chiave principale utilizzata per generare tutte le altre chiavi durante la sessione TLS
        
        \begin{center}
            \includegraphics[scale=0.475]{images/ttls_handshake.png}
        \end{center}
    \end{enumerate}
    Nella sua semplicità, tale implementazione proposta richiede ben 3 RTT prima che Bob possa iniziare a ricevere i dati da Alice, risultando quindi un'implementazione poco efficiente, ma comunque efficace.

    Passiamo ora quindi alla generazione delle chiavi. Per effettuare un trasferimento sicuro dei dati, è necessario utilizzare un crittografia per un \textbf{message authentication code (MAC)} e una crittografia per il messaggio stesso. Tuttavia, in generale è considerato \textbf{insicuro} utilizzare la stessa chiave per più di una funzione crittografica.

    Di conseguenza, necessitiamo di \textbf{quattro chiavi simmetriche}:
    \begin{itemize}
        \item $K_C$, ossia la chiave di cifratura per i dati inviati dal client al server
        \item $K_S$, ossia la chiave di cifratura per i dati inviati dal server al client
        \item $M_C$, ossia la chiave MAC per autenticare i dati inviati dal client al server
        \item $M_S$, ossia la chiave MAC per autenticare i dati inviati dal server al client
    \end{itemize}

    Tali chiavi vengono derivate da una \textbf{Key Derivation Function (KDF)}, la quale utilizza il MS e alcuni dati casuali aggiuntivi per generare le chiavi.

    Una volta generate le chiavi, è necessario considerare il modo in cui esse verranno applicate sui dati. In particolare, sappiamo che il TCP fornisce un bytestream per l'astrazione del flusso dati.
    
    Tuttavia, non è possibile crittografare i dati man mano che essi arrivano al socket TCP, poiché altrimenti non sapremmo \textbf{quando inviare il MAC} . Ad esempio, se la firma MAC venisse inviata alla fine del bytestream, potremmo garantire l'integrità del messaggio solo una volta che esso è stato completamente ricevuto, rendendo inutile l'intera trasmissione nel caso in cui il messaggio sia stato alterato.

    Di conseguenza, è necessario suddividere il bytestream in una serie di \textbf{record}, dove ogni record client-server contiene un MAC creato utilizzando $M_C$ e dove ogni record server-client contiene un MAC creato utilizzando $M_S$. In tal modo, il ricevitore può agire su ogni record man mano che essi arrivano. Infine, possiamo applicare la chiave $K_C$ (o $K_S$, a seconda del mittente) sull'intero record, per poi passarlo al layer di trasporto.

    \begin{center}
        \includegraphics[scale=0.35]{images/ttls_2.png}
    \end{center}
    
    Tuttavia, poiché il layer di trasporto è posto \textbf{al di sotto del TLS}, l'header TCP non è cifrato. Di conseguenza, è possibile effettuare alcuni \textbf{attacchi al bytestream}:
    \begin{itemize}
        \item \textbf{Reordering attack}: tramite un man in the middle attack vengono intercettati i segmenti TCP e riordinati, manipolando i numeri di sequenza nell'intestazione TCP non crittografata
        \item \textbf{Replay attack}: viene salvato il bytestream per riutilizzarlo successivamente
    \end{itemize}

    Per risolvere tali problematiche, possiamo utilizzare dei \textbf{numeri di sequenza TLS} incorporati nel MAC (rendendo il riordinamento inefficace), un \textbf{nonce} dove la chiave MAC cambia ad ogni record (rendendo il replay attack inefficace). A questo punto, inoltre, non è più necessario che il MAC venga cifrato anche con $K_C$ (o $K_S$).

    \begin{center}
        \includegraphics[scale=0.35]{images/ttls_3.png}
    \end{center}
    
    Rimane tuttavia un possibile \textbf{attacco alla chiusura della connessione}:
    \begin{itemize}
        \item \textbf{Truncation attack}: poiché l'header TCP non è cifrato, l'attaccante potrebbe falsificare il segmento di chiusura della connessione, portando una o entrambe le parti a terminare immediatamente la connessione
    \end{itemize}

    La soluzione a tale problema risulta molto semplice: è sufficiente aggiungere un \textbf{campo type} nel record il quale verrà impostato a 0 se la trasmissione riguarda i dati o ad 1 se la trasmissione deve essere chiusa (ricordiamo che il record verrà poi cifrato). Inoltre, in tal modo il MAC sarà calcolato utilizzando il campo data, il campo type e il numero di sequenza del record

    \begin{center}
        \includegraphics[scale=0.335]{images/ttls_4.png}
    \end{center}

    \quad

    \subsection{Protocollo TLS 1.3}

    \quad

    \begin{framedprop}{TLS 1.3 e Cipher suite}
        Ogni versione del protocollo TLS è dotata di varie \textbf{cipher suite}, ossia vari insiemi di diverse combinazioni di algoritmi utilizzabili per la generazione delle chiavi, per la cifratura, per il MAC e per la firma digitale (es: la suite \texttt{TLS\_AES\_128\_GCM\_SHA256})

        In particolare, per il protocollo TLS 1.3 si ha che:
        \begin{itemize}
            \item La quantità di scelte possibili rispetto al TLS 1.2 passa da 37 a solamente 5
            \item Viene utilizzato l'algoritmo \textbf{Diffie-Hellman (DH)} per lo scambio delle chiavi al posto di RSA
            \item Viene unita la crittografia all' algoritmo di autenticazione (una sorta di "crittografia autenticata" basata sull'algoritmo AES) per i dati invece dell'uso di una cifratura seriale assieme all'autenticazione tramite MAC
            \item Viene utilizzato un \textbf{Hash-based MAC (HMAC)}, corrispondente al digest del record calcolato tramite SHA-2 (256 bit o 284 bit)
        \end{itemize}
    \end{framedprop}

    L'implementazione dell'handshake TLS 1.3 si suddivide in due tipologie:
    \begin{itemize}
        \item \textbf{TLS 1.3 handshake ad 1 RTT}, la quale, come da nome, richiede 1 RTT per stabilire la connessione TLS prima di poter inviare gli effettivi dati:
        \begin{enumerate}
            \item Il client invia un messaggio di TLS client hello, \textbf{indicando} al server le cipher suite supportate e \textbf{proponendo} un protocollo di scambio chiavi e parametri
            \item Il server risponde con un messaggio di TLS server hello, scegliendo la suite di cifratura, scegliendo il protocollo di scambio chiavi e parametri e inviando il proprio certificato firmato
            \item Il client controlla il certificato del server e genera la master key che verrà utilizzata per la sessione
            
            \begin{center}
                \includegraphics[scale=0.425]{images/tls_hand.png}
            \end{center}
        \end{enumerate}
        
        \item \textbf{TLS 1.3 handshake a 0 RTT}, richiedente 0 RTT per stabilire la connessione TLS prima di poter inviare gli effettivi dati:
        \begin{itemize}
            \item Il messaggio TLS client hello contiene già dati cifrati tramite l'uso della master key della sessione precedente ("ripresa" della connessione) 
            \item Essendo vulnerabile ai replay attack, viene utilizzata solo per richieste che non modificano lo stato del server (es: ottenere un documento)
            
            \begin{center}
                \includegraphics[scale=0.425]{images/tls_hand_2.png}
            \end{center}
        \end{itemize}
    \end{itemize}

    \newpage

    \section{Sicurezza a livello di rete (IPsec)}

    La suite di protocolli \textbf{IPsec} fornisce crittografia, autenticazione e integrità a livello di datagramma, sia per il traffico utente che per il traffico di controllo. Tali protocolli possono essere implementati in due modalità:
    \begin{itemize}
        \item \textbf{Modalità di trasporto}, dove soltanto il payload del datagramma è cifrato e autenticato
        \item \textbf{Modalità tunnel}, dove:
        \begin{itemize}
            \item L'intero datagramma è cifrato e autenticato
            \item Il datagramma cifrato viene incapsulato in un nuovo datagramma con una nuova intestazione IP ed inviato verso la destinazione
            \item Chi osserva il traffico vede solo il traffico cifrato tra client e server, senza poter sapere la sorgente iniziale e la destinazione finale del pacchetto incapsulato
        \end{itemize}
    \end{itemize}

    \begin{center}
        \begin{tabular}{ccc}
            \textbf{Modalità di trasporto} && \textbf{Modalità tunnel (VPN)}\\
            \includegraphics[scale=0.45]{images/ipsec_1.png}
            &\qquad&
            \includegraphics[scale=0.45]{images/ipsec_2.png}
        \end{tabular}
    \end{center}

    In particolare, all'interno della suite IPsec troviamo il protocollo \textbf{Authentication Header (AH)}, il quale fornisce autenticazione del mittente e integrità dei dati ma non la loro riservatezza, e il protocollo \textbf{Encapsulation Security Protocol (ESP)}, il quale fornisce anche riservatezza (ed è pertanto più utilizzato di AH).

    Prima dell'invio dei dati, viene stabilita una \textbf{security association (SA)}, ossia un insieme di regole utilizzate per stabilire un percorso sicuro da effettuare dall'entità di invio a quella ricevente. Dunque, i due router devono memorizzare le informazioni sullo stato della SA. Inoltre, per via della necessità di scambio di chiavi ed altre operazioni, IPsec è \textbf{orientato alla connessione}, mentre IP no, richiedendo una gestione diversa.

    \textbf{Esempio:}

    \begin{itemize}
        \item Consideriamo la seguente SA tra due router
        
        \begin{center}
            \includegraphics[scale=0.5]{images/sa.png}
        \end{center}

        \item Il router R1 dovrà memorizzare:
        \begin{itemize}
            \item Identificatore a 32 bit per la SA, ossia un \textbf{Security Parameter Index (SPI)}
            \item Interfaccia di origine della SA, ossia \texttt{200.168.1.100}
            \item Interfaccia di destinazione della SA, ossia \texttt{193.68.2.23}
            \item Tipo di crittografia utilizzato e chiave crittografica
            \item Tipo di controllo di integrità utilizzato e chiave di autenticazione
        \end{itemize}
    \end{itemize}
    
    \quad

    \subsection{Protocollo ESP}

    Il \textbf{protocollo ESP} viene principalmente utilizzato in \textbf{tunnel mode} creando un canale crittografico riservato ed autenticato tramite una SA, venendo impiegato anche per la realizzazione di \textbf{Virtual Private Network (VPN)}, ossia una rete privata realizzata tramite un "canale virtuale" (nome derivato dalla presenza di un canale crittografato "invisibile" agli altri utenti sulla rete fisica)

    \begin{center}
        \includegraphics[scale=0.45]{images/esp.png}
    \end{center}

    \textbf{Esempio:}

    \begin{itemize}
        \item Un router vuole inviare un datagramma all'interno di un tunnel ESP, costruendo il datagramma ESP contenente il datagramma originale nel seguente modo:
        
        \begin{enumerate}
            \item Viene aggiunto un trailer ESP alla fine del datagramma originale
            \item Viene cifrato il risultato ottenuto utilizzato l'algoritmo e la chiave specificati nella SA
            \item Viene aggiunge un header ESP davanti alla parte cifrata
            \item Viene creata l'autenticazione MAC utilizzando l'algoritmo e la chiave specificati nella SA, per poi aggiungerlo alla fine del nuovo datagramma
            \item Viene creato un header aggiuntivo contenente gli endpoint del tunnel
            \item Viene spedito il datagramma ESP
        \end{enumerate}
    \end{itemize}

    Per evitare la presenza di replay attack, vengono utilizzati \textbf{numeri di sequenza}:
    \begin{itemize}
        \item Alla creazione di una SA, il mittente inizializza il numero di sequenza a 0
        \item Ogni volta che viene inviato un datagramma viene incrementato il numero di sequenza, inserendo il nuovo valore all'interno del campo Seq \# dell'header (il quale verrà anche autenticato)
    \end{itemize}
\end{document}
